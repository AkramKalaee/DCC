On the RACE benchmark, our model outperforms DFN (DynamicFusion Networks) by 1.5%-6% without using any recurrent or convolution layers.Similarly, we achieve competitive performance relative to AMANDA on theSearchQA benchmark and BiDAF on the NarrativeQA benchmark without using anyLSTM/GRU layers.