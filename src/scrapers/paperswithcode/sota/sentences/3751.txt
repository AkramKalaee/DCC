Several machine learning models, including neural networks, consistentlymisclassify adversarial examples---inputs formed by applying small butintentionally worst-case perturbations to examples from the dataset, such thatthe perturbed input results in the model outputting an incorrect answer withhigh confidence.