By replacing dilated
convolutions with the proposed JPU module, our method achieves the
state-of-the-art performance in Pascal Context dataset (mIoU of 53.13%) and
ADE20K dataset (final score of 0.5584) while running 3 times faster.