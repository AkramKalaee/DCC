Based on this observation, we propose an extremely simple modification
to VAE training to reduce inference lag: depending on the model's current
mutual information between latent variable and observation, we aggressively
optimize the inference network before performing each model update.