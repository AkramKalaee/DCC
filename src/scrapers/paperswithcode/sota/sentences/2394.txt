Unlike the previous works, our neural network model requires lesspre-defined hyper-parameters and uses an elegant architecture for modeling.Experimental results show that the proposed attention-over-attention modelsignificantly outperforms various state-of-the-art systems by a large margin inpublic datasets, such as CNN and Children's Book Test datasets.