Inparticular, Bidirectional LSTMs are at the heart of several neural modelsachieving state-of-the-art performance in a wide variety of tasks in NLP.However, BiLSTMs are known to suffer from sequential bias - the contextualrepresentation of a token is heavily influenced by tokens close to it in asentence.