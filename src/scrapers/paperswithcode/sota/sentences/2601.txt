Sequence labeling architectures use word embeddings for capturing similarity,
but suffer when handling previously unseen or rare words.