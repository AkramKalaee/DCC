We introduce a new language representation model called BERT, which standsfor Bidirectional Encoder Representations from Transformers.