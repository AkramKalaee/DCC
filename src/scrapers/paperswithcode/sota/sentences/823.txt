Our implementation, inspired by the self-attention approach, consists of two
steps: (i) compute the similarities between each pixel and all the pixels,
forming a so-called object context map for each pixel served as a surrogate for
the true object context, and (ii) represent the pixel by aggregating the
features of all the pixels weighted by the similarities.