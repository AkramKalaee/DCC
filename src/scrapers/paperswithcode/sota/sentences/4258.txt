Although ReLU can ease thenetwork training to an extent, the character of blocking negative values maysuppress the propagation of useful information and leads to the difficulty ofoptimizing very deep Convolutional Neural Networks (CNNs).