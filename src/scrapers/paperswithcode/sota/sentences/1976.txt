We present a probabilistic variant of the recently introduced maxout unit.The success of deep neural networks utilizing maxout can partly be attributedto favorable performance under dropout, when compared to rectified linearunits.