First, we identify several key
modeling and training techniques, and apply them to the RNN architecture,
yielding a new RNMT+ model that outperforms all of the three fundamental
architectures on the benchmark WMT'14 English to French and English to German
tasks.