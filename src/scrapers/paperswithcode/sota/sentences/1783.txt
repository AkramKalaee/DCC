The models proposed for unsupervised NMT often use only one shared
encoder to map the pairs of sentences from different languages to a
shared-latent space, which is weak in keeping the unique and internal
characteristics of each language, such as the style, terminology, and sentence
structure.