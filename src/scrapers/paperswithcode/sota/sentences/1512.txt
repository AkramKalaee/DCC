Self-attention is a useful mechanism to build generative models for languageand images.