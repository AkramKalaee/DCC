All models perform significantly worse on our balanced dataset,suggesting that these models have indeed learned to exploit language priors.This finding provides the first concrete empirical evidence for what seems tobe a qualitative sense among practitioners.Finally, our data collection protocol for identifying complementary imagesenables us to develop a novel interpretable model, which in addition toproviding an answer to the given (image, question) pair, also provides acounter-example based explanation.