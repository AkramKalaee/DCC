All models perform significantly worse on our balanced dataset, suggesting that these models have indeed learned to exploit language priors.