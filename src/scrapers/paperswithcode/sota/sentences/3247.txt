We further demonstrate how proper activation scaling stabilizes the training of very wide residual Inception networks.