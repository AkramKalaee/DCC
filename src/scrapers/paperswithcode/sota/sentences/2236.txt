Recurrent neural network models with an attention mechanism have proven to beextremely effective on a wide variety of sequence-to-sequence problems.However, the fact that soft attention mechanisms perform a pass over the entireinput sequence when producing each element in the output sequence precludestheir use in online settings and results in a quadratic time complexity.