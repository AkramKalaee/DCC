State-of-the-art results on neural machine translation often use attentional sequence-to-sequence models with some form of convolution or recursion.