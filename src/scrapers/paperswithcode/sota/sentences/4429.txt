Some of the techniques that were foundbeneficial are: maxout networks with annealed dropout rates; networks with avery large number of outputs trained on 2000 hours of data; joint modeling ofpartially unfolded recurrent neural networks and convolutional nets bycombining the bottleneck and output layers and retraining the resulting model;and lastly, sophisticated language model rescoring with exponential and neuralnetwork LMs.