Motivated bythat the label of a pixel is the category of the object that the pixel belongsto, we introduce an \emph{object context pooling (OCP)} scheme, whichrepresents each pixel by exploiting the set of pixels that belong to the sameobject category with such a pixel, and we call the set of pixels as objectcontext.Our implementation, inspired by the self-attention approach, consists of twosteps: (i) compute the similarities between each pixel and all the pixels,forming a so-called object context map for each pixel served as a surrogate forthe true object context, and (ii) represent the pixel by aggregating thefeatures of all the pixels weighted by the similarities.