Deploying neural NLP models to mobile devices requires compressingthe word embeddings without any significant sacrifices in performance.