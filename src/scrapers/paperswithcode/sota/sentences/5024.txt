In this paper, we present a new state-of-the-art result, achievingthe accuracy of 88.6% on the Stanford Natural Language Inference Dataset.Unlike the previous top models that use very complicated network architectures,we first demonstrate that carefully designing sequential inference models basedon chain LSTMs can outperform all previous models.