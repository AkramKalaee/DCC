We show that, for models trained from scratch as well aspretrained ones, using a variant of the triplet loss to perform end-to-end deepmetric learning outperforms most other published methods by a large margin.