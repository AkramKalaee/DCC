Second,
we show that representation learning (or pre-training) still holds a lot of
promise.