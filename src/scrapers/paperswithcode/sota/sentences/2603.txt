By using an attention mechanism, the model is able to dynamically decide how much information to use from a wordor character-level component.