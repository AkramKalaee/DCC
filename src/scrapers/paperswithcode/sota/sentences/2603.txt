By using an attention mechanism,
the model is able to dynamically decide how much information to use from a
word- or character-level component.