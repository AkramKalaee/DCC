In this work, we generalizea recently proposed model architecture based on self-attention, theTransformer, to a sequence modeling formulation of image generation with atractable likelihood.