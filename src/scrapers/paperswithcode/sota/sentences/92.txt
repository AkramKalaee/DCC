Using TPUmeshes of up to 512 cores, we train Transformer models with up to 5 billionparameters, surpassing state of the art results on WMT'14 English-to-Frenchtranslation task and the one-billion-word language modeling benchmark.Mesh-Tensorflow is available at this https URL .