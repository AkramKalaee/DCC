To solve this problem, we first propose order-Kdense connectivity to trim off long-distance shortcuts; then, we use amemory-efficient implementation to significantly boost the training efficiencyand investigate an iterative refinement that may slice the model size in half.Finally, to reduce the memory consumption and high precision operations both intraining and testing, we further quantize weights, inputs, and gradients of ourlocalization network to low bit-width numbers.