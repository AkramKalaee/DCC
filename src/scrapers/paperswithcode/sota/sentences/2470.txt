We further introduce an attention mechanism that aligns node embeddings and the decoding sequence to better cope with large graphs.