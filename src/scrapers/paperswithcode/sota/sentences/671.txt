We introduce a new language representation model called BERT, which stands
for Bidirectional Encoder Representations from Transformers.