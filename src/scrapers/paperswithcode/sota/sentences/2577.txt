In this paper, we integrate both soft and hard attention into onecontext fusion model, "reinforced self-attention (ReSA)", for the mutualbenefit of each other.