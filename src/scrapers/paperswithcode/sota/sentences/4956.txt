UTs combine theparallelizability and global receptive field of feed-forward sequence modelslike the Transformer with the recurrent inductive bias of RNNs.