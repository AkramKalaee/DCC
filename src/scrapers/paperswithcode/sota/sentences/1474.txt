By shallow fusion,we report up to 27% relative improvements in WER over the attention baselinewithout a language model.