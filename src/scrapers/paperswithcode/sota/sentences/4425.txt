Our method profits from the modular
architecture of SMT: we first induce a phrase table from monolingual corpora
through cross-lingual embedding mappings, combine it with an n-gram language
model, and fine-tune hyperparameters through an unsupervised MERT variant.