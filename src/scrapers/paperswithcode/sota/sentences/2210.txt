In model training, LMs are learned with layer-wise dropouts for better robustness.