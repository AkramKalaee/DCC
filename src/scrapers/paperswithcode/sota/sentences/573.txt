In this paper we introduce a simple approach for exploration in reinforcementlearning (RL) that allows us to develop theoretically justified algorithms inthe tabular case but that is also extendable to settings where functionapproximation is required.