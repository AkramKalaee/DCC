Our experiments show thatUTs outperform standard Transformers on a wide range of algorithmic andlanguage understanding tasks, including the challenging LAMBADA languagemodeling task where UTs achieve a new state of the art, and machine translationwhere UTs achieve a 0.9 BLEU improvement over Transformers on the WMT14 En-Dedataset.