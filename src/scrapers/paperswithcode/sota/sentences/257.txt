We propose a twotime-scale update rule (TTUR) for training GANs with stochastic gradientdescent on arbitrary GAN loss functions.