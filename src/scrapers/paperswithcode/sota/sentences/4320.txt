We present a novel architecture, the "stacked what-where auto-encoders"
(SWWAE), which integrates discriminative and generative pathways and provides a
unified approach to supervised, semi-supervised and unsupervised learning
without relying on sampling during training.