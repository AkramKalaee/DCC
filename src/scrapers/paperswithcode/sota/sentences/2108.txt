To mitigate the monotonic alignment requirement of SWAN, weintroduce a new layer to perform (soft) local reordering of input sequences.Different from existing neural machine translation (NMT) approaches, NPMT doesnot use attention-based decoding mechanisms.