Knowledge graphs are large graph-structured databases of facts, which
typically suffer from incompleteness. Link prediction is the task of inferring
missing relations (links) between entities (nodes) in a knowledge graph. We
approach this task using a hypernetwork architecture to generate convolutional
layer filters specific to each relation and apply those filters to the subject
entity embeddings. This architecture enables a trade-off between non-linear
expressiveness and the number of parameters to learn. Our model simplifies the
entity and relation embedding interactions introduced by the predecessor
convolutional model, while outperforming all previous approaches to link
prediction across all standard link prediction datasets.