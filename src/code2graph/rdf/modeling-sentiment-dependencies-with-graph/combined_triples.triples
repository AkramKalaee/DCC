Saver	call	global_variables
preprocess	call	word2id_2
split	followed_by	range
FileWriter	followed_by	trainable_variables
run	followed_by	batch_iter
get__whichtarget	followed_by	get_position
zeros	followed_by	range
word2id	call	split
word2id_2	followed_by	word2id_2
scalar	followed_by	scalar
train	call	scalar
reverse	followed_by	range
preprocess	call	get_position
eval(use_model)	followed_by	FileWriter
word2id_2	followed_by	get__whichtarget
preprocess	call	load_targets
get_relation	call	eye
eye	followed_by	zeros
get_relation	call	range
get_position	call	range
get_position_2	followed_by	get_relation
preprocess	followed_by	train
max	followed_by	load_targets
train	call	Saver
get_relation	followed_by	get_relation
ConfigProto	followed_by	Session
get_position	call	List
load_data_and_labels	call	List
preprocess	call	load_data_and_labels
ConfigProto	has_log_device_placement	FLAGS.log_device_placement
f1_score	has_average	macro
word2id	followed_by	word2id
max	call	split
List	followed_by	reverse
preprocess	call	word2id
get_relation	call	zeros
load_data_and_labels	followed_by	load_data_and_labels
preprocess	call	get_relation
preprocess	call	get_position_2
merge	followed_by	FileWriter
range	followed_by	zeros
test_step	call	f1_score
zeros	has_arg0	(max_target_num, max_target_num)
List	call	range
batch_iter	call	range
preprocess	call	max
Variable	followed_by	AdamOptimizer
max	followed_by	word2id
FileWriter	has_arg0	logs/LSTM_GCN3
.run_glove	call	preprocess
get_position	followed_by	get_position
train	call	AdamOptimizer
Saver	followed_by	run
max	followed_by	max
get__whichtarget	call	zeros
train	call	List
eval(use_model)	has_l2_reg_lambda	FLAGS.l2_reg_lambda
word2id_2	call	split
range	followed_by	range
batch_iter	call	min
load_data_and_labels	followed_by	load_w2v
zeros	has_arg0	(targets_num.shape[0], max_target_num)
get_position_2	followed_by	get_position_2
scalar	has_arg0	loss
preprocess	call	load_w2v
train_step	followed_by	global_step
get_position	call	reverse
range	followed_by	min
get_position	followed_by	get_position_2
get_relation	call	ones
Saver	has_max_to_keep	FLAGS.num_checkpoints
train	call	batch_iter
scalar	has_arg0	accuracy
List	followed_by	List
train	call	merge
Session	followed_by	eval(use_model)
histogram	followed_by	scalar
List	followed_by	train_step
FileWriter	followed_by	merge
split	followed_by	shape
batch_iter	followed_by	List
trainable_variables	followed_by	Variable
word2id	followed_by	word2id_2
load_targets	followed_by	load_targets
merge	followed_by	scalar
load_targets	followed_by	max
run	followed_by	f1_score
train	call	run
train	call	Variable
train	call	Session
load_w2v	call	shape
global_step	followed_by	test_step
load_w2v	call	split
eval(use_model)	call	eval
preprocess	call	get__whichtarget
ones	followed_by	range
zeros	followed_by	eye
train	call	ConfigProto
train	call	trainable_variables
train_step	call	run
train	call	FileWriter
test_step	call	run
train	call	histogram
range	has_arg0	1
word2id_2	call	range
range	followed_by	List
AdamOptimizer	followed_by	histogram
train	call	global_step
get__whichtarget	followed_by	get__whichtarget
train	call	test_step
zeros	followed_by	zeros
scalar	followed_by	merge
split	has_arg0	 
load_w2v	followed_by	max
load_targets	call	List
train	call	train_step
FileWriter	followed_by	Saver
train	call	eval(use_model)
Variable	has_arg0	0
eye	followed_by	ones
.run_glove	call	train
reshape	call	cast
cast	followed_by	reduce_max
att_layer.mlp_attention_layer	call	shape
att_layer.mlp_attention_layer	call	softmax_with_len
cast	followed_by	shape
att_layer.mlp_attention_layer	call	tanh
softmax_with_len	call	reshape
reshape	followed_by	reduce_sum
att_layer.mlp_attention_layer	call	reshape
reshape	call	matmul
softmax_with_len	call	reduce_max
cast	call	sequence_mask
get_variable	followed_by	get_variable
softmax_with_len	call	cast
reshape	call	shape
reshape	followed_by	tanh
exp	followed_by	reshape
shape	followed_by	get_variable
softmax_with_len	call	exp
softmax_with_len	call	reduce_sum
att_layer.mlp_attention_layer	call	get_variable
tanh	call	matmul
shape	followed_by	shape
reshape	followed_by	reshape
reshape	followed_by	softmax_with_len
get_variable	followed_by	reshape
reduce_max	followed_by	exp
tanh	followed_by	reshape
load	has_arg0	data/data_lap/bert_embedding/Lap_Test_targets_Embedding.npy
get__whichtarget	followed_by	get__whichtarget
split	followed_by	range
get_position	followed_by	get_position_2
load	has_arg0	data/data_res/bert_embedding/Res_Train_Embedding.npy
load_w2v	followed_by	max
load	has_arg0	data/data_res/bert_embedding/Res_Train_target_Embedding.npy
split	has_arg0	 
eval(use_model)	has_l2_reg_lambda	FLAGS.l2_reg_lambda
load	has_arg0	data/data_lap/bert_embedding/Lap_Test_Embedding.npy
Session	followed_by	eval(use_model)
eye	followed_by	ones
train	call	test_step
run	followed_by	batch_iter
scalar	has_arg0	loss
range	followed_by	min
FileWriter	followed_by	merge
eval(use_model)	followed_by	FileWriter
get__whichtarget	call	zeros
train	call	Variable
train	call	histogram
max	followed_by	max
f1_score	has_average	macro
get_position_2	followed_by	load
preprocess	call	word2id
trainable_variables	followed_by	Variable
load_targets	followed_by	max
Variable	has_arg0	0
load	has_arg0	data/data_res/bert_embedding/Res_Test_Embedding.npy
train	call	scalar
batch_iter2	followed_by	List
preprocess	followed_by	train
preprocess	call	load_w2v
preprocess	call	word2id_2
eye	followed_by	zeros
eval(use_model)	call	eval
train	call	FileWriter
scalar	followed_by	merge
split	followed_by	shape
load	has_arg0	data/data_lap/bert_embedding/Lap_Train_Embedding.npy
FileWriter	followed_by	trainable_variables
preprocess	call	max
batch_iter	call	min
word2id	call	split
get_position	call	range
zeros	has_arg0	(max_target_num, max_target_num)
load	followed_by	get_relation
FileWriter	has_arg0	logs/LSTM_GCN3
AdamOptimizer	followed_by	histogram
get__whichtarget	followed_by	get_position
get_position	followed_by	get_position
zeros	has_arg0	(targets_num.shape[0], max_target_num)
get_relation	call	ones
max	followed_by	word2id
train	call	List
range	followed_by	List
get_relation	call	range
preprocess	call	get_position
List	followed_by	train_step
get_position_2	followed_by	get_position_2
load_data_and_labels	call	List
train	call	merge
merge	followed_by	FileWriter
ConfigProto	has_log_device_placement	FLAGS.log_device_placement
train	call	batch_iter
load_w2v	call	split
word2id_2	call	split
List	followed_by	test_step
preprocess	call	get_relation
word2id_2	followed_by	word2id_2
load	followed_by	load
range	followed_by	zeros
train	call	trainable_variables
batch_iter	call	range
FileWriter	followed_by	Saver
List	followed_by	reverse
train	call	batch_iter2
max	call	split
train	call	eval(use_model)
train	call	f1_score
.run_BERT	call	train
load	has_arg0	data/data_lap/bert_embedding/Lap_Train_targets_Embedding.npy
Saver	has_max_to_keep	FLAGS.num_checkpoints
load	has_arg0	data/data_lap/bert_embedding/Lap_Train_target_Embedding.npy
load	has_arg0	data/data_res/bert_embedding/Res_Train_targets_Embedding.npy
reverse	followed_by	range
preprocess	call	load_data_and_labels
max	followed_by	load_targets
Saver	call	global_variables
List	followed_by	List
List	call	range
preprocess	call	get__whichtarget
preprocess	call	get_position_2
get_relation	call	eye
Saver	followed_by	run
load_targets	followed_by	load_targets
zeros	followed_by	zeros
train	call	Saver
load	has_arg0	data/data_lap/bert_embedding/Lap_Test_target_Embedding.npy
load_targets	call	List
train	call	global_step
preprocess	call	load_targets
test_step	call	run
word2id_2	call	range
batch_iter2	call	range
train	call	run
scalar	has_arg0	accuracy
zeros	followed_by	eye
word2id	followed_by	word2id_2
train	call	Session
word2id	followed_by	word2id
batch_iter	followed_by	List
merge	followed_by	scalar
preprocess	call	load
load_data_and_labels	followed_by	load_w2v
Variable	followed_by	AdamOptimizer
word2id_2	followed_by	get__whichtarget
train	call	ConfigProto
train	call	train_step
test_step	followed_by	f1_score
load	has_arg0	data/data_res/bert_embedding/Res_Test_targets_Embedding.npy
scalar	followed_by	scalar
batch_iter2	call	min
range	followed_by	range
ConfigProto	followed_by	Session
load_w2v	call	shape
train_step	followed_by	global_step
histogram	followed_by	scalar
global_step	followed_by	batch_iter2
load	has_arg0	data/data_res/bert_embedding/Res_Test_target_Embedding.npy
.run_BERT	call	preprocess
load_data_and_labels	followed_by	load_data_and_labels
get_position	call	List
ones	followed_by	range
get_relation	call	zeros
range	has_arg0	1
get_relation	followed_by	get_relation
train_step	call	run
zeros	followed_by	range
train	call	AdamOptimizer
get_position	call	reverse
max	followed_by	create_bert_embedding
load_data_and_labels	followed_by	load_data_and_labels
max	call	split
split	has_arg0	 
zeros	has_arg0	768
max	followed_by	max
save_BERT_embeddinf	followed_by	load_data_and_labels
.creat_BERT_embedding	call	max
.creat_BERT_embedding	call	save_BERT_embeddinf
create_bert_embedding	followed_by	create_bert_embedding
save_BERT_embeddinf	followed_by	save_BERT_embeddinf
.creat_BERT_embedding	call	load_data_and_labels
create_bert_embedding	call	zeros
create_bert_embedding	followed_by	save_BERT_embeddinf
.creat_BERT_embedding	call	create_bert_embedding
load_data_and_labels	call	List
load_data_and_labels	followed_by	max
range	followed_by	gather
concat	has_arg0	2
reduce_sum	has_arg0	1
nn_layer.bi_dynamic_rnn	call	reverse_sequence
reduce_mean_with_len	call	cast
gather	followed_by	reduce_mean_with_len
range	has_arg0	0
nn_layer.bi_dynamic_rnn	call	reduce_mean_with_len
cast	followed_by	reduce_sum
reverse_sequence	has_seq_dim	1
concat	followed_by	shape
bidirectional_dynamic_rnn	followed_by	reverse_sequence
reduce_mean_with_len	call	reduce_sum
concat	followed_by	concat
reverse_sequence	call	cast
shape	followed_by	range
nn_layer.bi_dynamic_rnn	call	gather
cast	call	reshape
gather	call	reshape
reverse_sequence	followed_by	concat
nn_layer.bi_dynamic_rnn	call	concat
nn_layer.bi_dynamic_rnn	call	shape
nn_layer.bi_dynamic_rnn	call	bidirectional_dynamic_rnn
nn_layer.bi_dynamic_rnn	call	range
transpose	call	tanh
softmax_with_len	call	exp
reduce_max	followed_by	exp
softmax_with_len	call	reduce_max
reshape	call	shape
tanh	call	matmul
reshape	followed_by	reshape
att_layer.Mlp_attention_layer	call	softmax_with_len
cast	followed_by	reduce_max
cast	followed_by	shape
reshape	followed_by	reduce_sum
get_variable	call	sqrt
softmax_with_len	call	reduce_sum
softmax_with_len	call	reshape
shape	followed_by	shape
reshape	call	cast
get_variable	followed_by	get_variable
att_layer.Mlp_attention_layer	call	transpose
att_layer.Mlp_attention_layer	call	shape
softmax_with_len	call	cast
transpose	followed_by	transpose
reshape	call	matmul
reshape	followed_by	softmax_with_len
transpose	call	reshape
get_variable	followed_by	transpose
exp	followed_by	reshape
transpose	followed_by	reshape
cast	call	sequence_mask
att_layer.Mlp_attention_layer	call	get_variable
att_layer.Mlp_attention_layer	call	reshape
shape	followed_by	get_variable
att_layer.dot_produce_attention_layer	call	get_variable
get_variable	call	sqrt
att_layer.dot_produce_attention_layer	call	reshape
softmax_with_len	call	cast
reshape	call	cast
cast	call	sequence_mask
cast	followed_by	shape
softmax_with_len	call	exp
reshape	followed_by	reshape
reshape	followed_by	reduce_sum
softmax_with_len	call	reduce_max
softmax_with_len	call	reduce_sum
reshape	call	shape
exp	followed_by	reshape
softmax_with_len	call	reshape
reduce_max	followed_by	exp
att_layer.dot_produce_attention_layer	call	softmax_with_len
shape	followed_by	get_variable
cast	followed_by	reduce_max
reshape	followed_by	softmax_with_len
att_layer.dot_produce_attention_layer	call	shape
shape	followed_by	shape
reshape	call	matmul
get_variable	followed_by	reshape
reshape	call	cast
cast	call	sequence_mask
reshape	followed_by	expand_dims
expand_dims	followed_by	reshape
shape	followed_by	get_variable
softmax_with_len	call	reshape
shape	followed_by	shape
softmax_with_len	call	cast
cast	followed_by	reduce_max
reshape	call	shape
reshape	call	matmul
reshape	followed_by	softmax_with_len
softmax_with_len	call	exp
reshape	followed_by	reshape
att_layer.bilinear_attention_layer	call	reshape
cast	followed_by	shape
reduce_max	followed_by	exp
exp	followed_by	reshape
softmax_with_len	call	reduce_sum
att_layer.bilinear_attention_layer	call	shape
att_layer.bilinear_attention_layer	call	get_variable
att_layer.bilinear_attention_layer	call	expand_dims
softmax_with_len	call	reduce_max
get_variable	followed_by	reshape
expand_dims	has_arg0	2
reshape	followed_by	reduce_sum
att_layer.bilinear_attention_layer	call	softmax_with_len
reverse_sequence	followed_by	concat
split	has_arg1	2
reverse_sequence	has_seq_dim	1
nn_layer.stack_bi_dynamic_rnn	call	reverse_sequence
cast	followed_by	reduce_sum
split	has_arg0	2
reduce_mean_with_len	call	reduce_sum
nn_layer.stack_bi_dynamic_rnn	call	shape
gather	followed_by	reduce_mean_with_len
nn_layer.stack_bi_dynamic_rnn	call	concat
range	has_arg0	0
split	followed_by	reverse_sequence
reverse_sequence	call	cast
shape	followed_by	range
gather	call	reshape
nn_layer.stack_bi_dynamic_rnn	call	reduce_mean_with_len
cast	call	reshape
concat	followed_by	shape
nn_layer.stack_bi_dynamic_rnn	call	range
nn_layer.stack_bi_dynamic_rnn	call	split
reduce_mean_with_len	call	cast
nn_layer.stack_bi_dynamic_rnn	call	gather
reduce_sum	has_arg0	1
range	followed_by	gather
concat	has_arg0	2
dynamic_rnn	call	range
gather	call	reshape
shape	followed_by	range
cast	followed_by	reduce_sum
nn_layer.bi_dynamic_rnn_diff	call	shape
name_scope	has_arg0	backward_lstm
name_scope	followed_by	dynamic_rnn
gather	followed_by	reduce_mean_with_len
gather	followed_by	concat
dynamic_rnn	followed_by	shape
cast	call	reshape
name_scope	has_arg0	forward_lstm
nn_layer.bi_dynamic_rnn_diff	call	dynamic_rnn
dynamic_rnn	call	dynamic_rnn
nn_layer.bi_dynamic_rnn_diff	call	gather
nn_layer.bi_dynamic_rnn_diff	call	name_scope
reduce_mean_with_len	call	cast
dynamic_rnn	call	shape
nn_layer.bi_dynamic_rnn_diff	call	range
range	followed_by	gather
nn_layer.bi_dynamic_rnn_diff	call	concat
concat	has_arg0	1
reduce_mean_with_len	call	reduce_sum
range	has_arg0	0
dynamic_rnn	call	reduce_mean_with_len
reduce_sum	has_arg0	1
dynamic_rnn	call	gather
gather	followed_by	name_scope
