commons.measure.PadRotateProjectWithTheta.measure	call	pad
reduce_sum	has_axis	2
commons.measure.PadRotateProjectWithTheta.measure	call	range
get_default_graph	followed_by	py_func
reduce_sum	followed_by	reshape
py_func	call	get_default_graph
project	call	reshape
tf_image_rotate	call	name_scope
pad	call	pad
py_func	call	py_func
pad	has_arg0	CONSTANT
pad	followed_by	range
tf_image_rotate	call	py_func
tf_image_rotate	followed_by	reshape
project	followed_by	concat
rotate	call	reshape
project	call	reduce_sum
name_scope	has_arg0	image_rotate
name_scope	followed_by	py_func
concat	has_arg0	1
tf.RegisterGradient(rnd_name)	followed_by	get_default_graph
commons.measure.PadRotateProjectWithTheta.measure	call	rotate
tf.RegisterGradient(rnd_name)	call	RegisterGradient
get_padding_prp	followed_by	pad
concat	call	concat
pad	call	get_padding_prp
rotate	call	tf_image_rotate
py_func	call	tf.RegisterGradient(rnd_name)
rotate	followed_by	project
range	followed_by	rotate
commons.measure.PadRotateProjectWithTheta.measure	call	project
concat	call	reshape
concat	followed_by	concat
reshape	followed_by	concat
commons.measure.PadRotateProjectWithTheta.measure	call	concat
amb_measure.DropMaskType1.sample_theta	call	get_noise_shape
uniform	followed_by	ones
get_noise_shape	followed_by	uniform
amb_measure.DropMaskType1.sample_theta	call	uniform
amb_measure.DropMaskType1.sample_theta	call	ones
uniform	followed_by	uniform
ones	has_shape	self.batch_dims
get_expt_dir	call	get_mode_dir
.gan_cifar_resnet	call	mean
reduce_mean	followed_by	add_n
Batchnorm	call	zeros
name_scope	followed_by	sqrt
Normalize	call	Batchnorm
reshape	followed_by	reshape
constant	followed_by	constant
.gan_cifar_resnet	call	amb_setup
mnist_generator	call	zeros
load	call	load
OptimizedResBlockDisc1	followed_by	ResidualBlock
amb_setup	call	get_hparams
run	followed_by	range
device	followed_by	cast
reshape	has_arg0	(100, 3, 32, 32)
constant	has_arg0	0.0
reshape	call	sqrt
maximum	followed_by	device
amb_setup	call	setup_dirs
Layernorm	call	zeros
generate_image	call	reshape
.gan_cifar_resnet	call	get_mdevice
Linear	call	uniform
Layernorm	call	param
uniform	followed_by	sqrt
embedding_lookup	followed_by	batch_normalization
run	followed_by	Saver
nonlinearity	followed_by	Normalize
.gan_cifar_resnet	call	constant
.gan_cifar_resnet	call	concat
OptimizedResBlockDisc1	call	nonlinearity
ResidualBlock	followed_by	nonlinearity
get_inception_score	call	run
Generator	call	Normalize
ones	followed_by	embedding_lookup
AdamOptimizer	has_beta2	0.9
amb_get_lossy	followed_by	device
maximum	call	cast
get_variable	has_arg0	biases
flush	call	mean
maximum	has_arg0	0.0
amb_get_lossy	call	NHWC_to_NCHW
zeros	has_arg0	(h * size[0], w * size[1], 3)
reshape	followed_by	matmul
flush	followed_by	tick
split	followed_by	amb_get_lossy
uniform	followed_by	uniform
cast	call	random_uniform
.gan_cifar_resnet	call	sqrt
get_inception_score	call	range
Linear	call	bias_add
.gan_cifar_resnet	call	print_model_settings
get_hparams	followed_by	setup_vals
cast	call	equal
flatten	followed_by	sqrt
NHWC_to_NCHW	call	transpose
save_images	call	merge
cifar_generator	followed_by	cifar_generator
conv2d	call	variable_scope
reshape	followed_by	bias_add
get_mdevice	followed_by	range
conv2d	followed_by	conv2d
Linear	call	name_scope
get_expt_dir	call	get_task_dir
reshape	has_arg0	(X.shape[0], int(np.sqrt(X.shape[1])), int(np.sqrt(X.shape[1])))
argmax	has_dimension	1
tick	followed_by	get_inception_score
bias_add	call	zeros
Linear	call	param
zeros	has_arg0	(h * nh, w * nw)
save_images	call	sqrt
normal	has_arg0	0.0
amb_get_lossy	call	NCHW_to_flat
transpose	has_arg0	0
ones	followed_by	_fused_batch_norm_training
add_n	followed_by	constant
plot	followed_by	flush
transpose	has_arg3	1
ResidualBlock	call	Normalize
.gan_cifar_resnet	call	params_with_name
gradients	followed_by	sqrt
get_mdevice	call	BlurAddNoise.__init__
Linear	followed_by	reshape
range	followed_by	Session
transpose	has_arg1	2
shuffle	followed_by	zeros
param	followed_by	sqrt
get_ckpt_path	call	get_checkpoint_state
ones	followed_by	reshape
reshape	followed_by	OptimizedResBlockDisc1
plot	followed_by	save_x_lossy
Batchnorm	call	ones
.gan_cifar_resnet	call	Session
sample	call	svd
reshape	call	bias_add
reduce_sum	call	square
try_restore	followed_by	load
save_x_lossy	call	range
sqrt	followed_by	name_scope
params_with_name	followed_by	maximum
Batchnorm	call	embedding_lookup
zeros	followed_by	zeros
get_inception_score	call	get_inception_score
AdamOptimizer	followed_by	AdamOptimizer
conv2d	call	get_variable
.gan_cifar_resnet	call	get_inception_score
Normalize	followed_by	nonlinearity
.gan_cifar_resnet	call	tick
save_x_lossy	call	run
run	call	initialize_all_variables
amb_setup	call	print_hparams
amb_measure_unmeasure_np	call	NHWC_to_NCHW
reshape	followed_by	batch_normalization
Linear	followed_by	Linear
Discriminator	call	nonlinearity
make_generator	followed_by	make_generator
Batchnorm	call	moments
Conv2D	call	sqrt
.gan_cifar_resnet	call	gradients
merge	call	zeros
generate_image	call	run
BlurAddNoise.__init__	call	__init__
amb_measure_unmeasure_np	followed_by	range
conv2d	call	conv2d
name_scope	has_arg0	filter_mask
save_images	followed_by	reshape
Generator	call	ResidualBlock
Conv2D	call	bias_add
range	followed_by	print_model_settings
save_images	call	flatten
Discriminator	call	OptimizedResBlockDisc1
unpickle	call	load
amb_measure_unmeasure_np	call	NCHW_to_flat
Conv2D	followed_by	Conv2D
sqrt	followed_by	uniform
Discriminator	call	Linear
generate_image	followed_by	flush
sqrt	followed_by	reshape
add_n	followed_by	add_n
Conv2D	call	name_scope
amb_get_lossy	followed_by	reshape
reduce_mean	call	cast
to_int32	call	argmax
setup_vals	followed_by	setup_dirs
mnist_generator	followed_by	mnist_generator
random_uniform	followed_by	split
plot	followed_by	mean
.gan_cifar_resnet	call	load
save_images	call	zeros
cifar_generator	call	unpickle
save_images	call	transpose
get_variable	followed_by	conv2d
Batchnorm	call	expand_dims
NCHW_to_NHWC	followed_by	flat_to_NCHW
Linear	call	sqrt
mean	followed_by	sort
zeros	has_arg0	(h * nh, w * nw, 3)
.gan_cifar_resnet	call	AdamOptimizer
sample	followed_by	param
print_hparams	followed_by	save_hparams
Normalize	call	Layernorm
batch_normalization	has_arg0	1e-05
load	call	cifar_generator
concat	followed_by	random_uniform
flat_to_NCHW	call	reshape
save_x_lossy	call	reshape
.gan_cifar_resnet	call	placeholder
Layernorm	followed_by	Batchnorm
Generator	followed_by	cast
shuffle	followed_by	shuffle
Discriminator	call	reduce_mean
Linear	call	matmul
_fused_batch_norm_training	call	fused_batch_norm
param	followed_by	zeros
concat	followed_by	Discriminator
param	followed_by	name_scope
set_up_dir	followed_by	set_up_dir
.gan_cifar_resnet	call	amb_get_lossy
.gan_cifar_resnet	call	split
ResidualBlock	call	nonlinearity
run	followed_by	run
sqrt	followed_by	matmul
.gan_cifar_resnet	call	Discriminator
amb_get_lossy	call	flat_to_NCHW
plot	followed_by	plot
NCHW_to_flat	followed_by	NHWC_to_NCHW
name_scope	followed_by	ones
NCHW_to_NHWC	call	transpose
Linear	call	reshape
reshape	followed_by	Linear
.gan_cifar_resnet	call	Generator
constant	followed_by	params_with_name
concat	followed_by	concat
.gan_cifar_resnet	call	reduce_mean
nonlinearity	followed_by	reduce_mean
inf_train_gen	followed_by	range
sqrt	call	square
moments	followed_by	param
run	followed_by	save_images
sqrt	followed_by	sqrt
Saver	followed_by	try_restore
.gan_cifar_resnet	call	try_restore
ResidualBlock	followed_by	ResidualBlock
flush	call	sort
amb_get_lossy	call	NCHW_to_NHWC
Generator	call	random_normal
load	followed_by	inf_train_gen
ones	followed_by	sqrt
split	followed_by	device
svd	followed_by	reshape
.gan_cifar_resnet	call	save_x_lossy
bias_add	has_data_format	NCHW
conv2d	call	reshape
mnist_generator	call	shuffle
amb_measure_unmeasure_np	call	flat_to_NCHW
Generator	call	tanh
ones	followed_by	param
try_restore	call	get_ckpt_path
equal	call	to_int32
Batchnorm	call	cond
Batchnorm	call	batch_normalization
run	followed_by	plot
name_scope	has_arg0	weightnorm
zeros	has_dtype	float32
amb_get_lossy	followed_by	Discriminator
get_variable	followed_by	reshape
get_inception_score	followed_by	List
Batchnorm	call	_fused_batch_norm_training
uniform	followed_by	param
zeros	has_dtype	int32
.gan_cifar_resnet	call	inf_train_gen
get_task_dir	followed_by	get_mode_dir
get_inception_score	followed_by	get_inception_score
range	followed_by	range
random_uniform	has_maxval	1.0
Generator	call	Conv2D
variable_scope	followed_by	get_variable
name_scope	followed_by	conv2d
reshape	followed_by	transpose
Layernorm	call	batch_normalization
fused_batch_norm	has_data_format	NCHW
NCHW_to_flat	call	reshape
load	call	mnist_generator
sample	call	reshape
device	followed_by	concat
nonlinearity	followed_by	Conv2D
Layernorm	call	reshape
.gan_cifar_resnet	call	amb_measure_unmeasure_np
Linear	call	sample
mean	followed_by	generate_image
amb_setup	followed_by	get_mdevice
embedding_lookup	followed_by	embedding_lookup
Generator	followed_by	amb_get_lossy
range	followed_by	run
reshape	followed_by	random_uniform
run	followed_by	get_inception_score
expand_dims	followed_by	param
random_normal	followed_by	Linear
split	has_axis	0
zeros	has_arg0	(output_dim,)
params_with_name	followed_by	constant
sample	call	normal
.gan_cifar_resnet	call	cast
placeholder	followed_by	split
reduce_mean	followed_by	device
device	followed_by	Generator
constant	followed_by	Generator
.gan_cifar_resnet	call	reshape
ones	has_dtype	float32
conv2d	followed_by	get_variable
Conv2D	call	conv2d
get_variable	has_arg0	w
placeholder	followed_by	placeholder
save_images	followed_by	save_images
save_x_lossy	followed_by	range
Saver	has_max_to_keep	AMB_HPARAMS.max_checkpoints
reshape	has_arg0	(64, 3, 32, 32)
print_model_settings	followed_by	amb_setup
save_x_lossy	call	save_images
cond	followed_by	cond
Layernorm	call	ones
zeros	followed_by	bias_add
transpose	followed_by	zeros
expand_dims	has_arg0	3
reshape	has_arg0	(batch_size, 3072)
param	followed_by	ones
.gan_cifar_resnet	call	flush
save_images	call	reshape
nonlinearity	call	relu
Discriminator	call	reshape
get_inception_score	followed_by	plot
transpose	has_arg2	3
.gan_cifar_resnet	call	add_n
normal	has_arg1	1.0
Generator	call	Linear
sqrt	followed_by	param
.gan_cifar_resnet	call	generate_image
_fused_batch_norm_training	followed_by	cond
Generator	call	nonlinearity
random_uniform	followed_by	gradients
zeros	followed_by	param
reshape	has_arg0	(batch_size, 3, 32, 32)
Layernorm	call	moments
cast	followed_by	Generator
Generator	followed_by	load
.gan_cifar_resnet	call	plot
sqrt	followed_by	sample
conv2d	followed_by	param
Conv2D	call	zeros
setup_dirs	followed_by	print_hparams
amb_setup	call	save_hparams
Generator	call	reshape
amb_setup	call	setup_vals
reshape	call	shape
Conv2D	call	ones
generate_image	call	save_images
add_n	followed_by	AdamOptimizer
Conv2D	call	param
tanh	followed_by	reshape
plot	followed_by	get_inception_score
Discriminator	followed_by	reduce_mean
ResidualBlock	followed_by	Normalize
reduce_mean	followed_by	reduce_mean
amb_measure_unmeasure_np	call	NCHW_to_NHWC
.gan_cifar_resnet	call	Saver
.gan_cifar_resnet	call	maximum
Conv2D	call	uniform
reshape	call	cast
load	followed_by	load
ones	has_arg0	(filter_size, filter_size, input_dim, output_dim)
load	followed_by	mnist_generator
Conv2D	followed_by	tanh
load	followed_by	run
reduce_mean	call	sparse_softmax_cross_entropy_with_logits
.gan_cifar_resnet	call	range
setup_dirs	call	set_up_dir
.gan_cifar_resnet	call	device
setup_vals	call	get_expt_dir
name_scope	followed_by	uniform
param	call	Variable
get_inception_score	call	List
.gan_cifar_resnet	call	run
.gan_cifar_resnet	call	random_uniform
ones	followed_by	batch_normalization
concat	has_axis	0
normal	followed_by	svd
Batchnorm	call	param
reshape	followed_by	ResidualBlock
Batchnorm	followed_by	Batchnorm
Discriminator	call	ResidualBlock
AdamOptimizer	followed_by	params_with_name
sqrt	followed_by	reduce_mean
reduce_mean	followed_by	Linear
flat_to_NCHW	followed_by	NCHW_to_flat
load	call	make_generator
sqrt	call	reduce_sum
range	followed_by	amb_measure_unmeasure_np
Session	followed_by	placeholder
cond	followed_by	moments
matmul	followed_by	reshape
mnist.gen.gan_def.discriminator_fc	call	linear
linear	call	variable_scope
variable_scope	followed_by	get_variable
get_variable	has_arg0	bias
lrelu	call	maximum
batch_norm.__init__	call	variable_scope
get_variable	has_arg0	Matrix
mnist.gen.gan_def.discriminator_fc	call	batch_norm.__init__
mnist.gen.gan_def.discriminator_fc	call	lrelu
get_variable	followed_by	get_variable
lrelu	followed_by	batch_norm.__init__
linear	call	get_variable
batch_norm.__init__	followed_by	linear
variable_scope	followed_by	batch_norm.__init__
get_variable	followed_by	matmul
linear	followed_by	lrelu
linear	call	matmul
lrelu	followed_by	linear
matmul	followed_by	matmul
mnist.gen.gan_def.discriminator_fc	call	variable_scope
Linear	call	reshape
svd	followed_by	reshape
reshape	followed_by	Linear
normal	has_arg1	1.0
variable_scope	followed_by	get_variable
zeros	has_dtype	float32
name_scope	followed_by	uniform
Conv2D	call	ones
NHWC_to_NCHW	followed_by	Conv2D
LeakyReLU	followed_by	Conv2D
sqrt	followed_by	sample
mnist.gen.gan_def.discriminator_wgangp	call	NHWC_to_NCHW
NHWC_to_NCHW	call	transpose
reshape	followed_by	matmul
get_variable	has_arg0	biases
Conv2D	call	bias_add
param	followed_by	zeros
sample	call	svd
Conv2D	followed_by	LeakyReLU
uniform	followed_by	sqrt
sample	call	reshape
sqrt	followed_by	uniform
ones	has_arg0	(filter_size, filter_size, input_dim, output_dim)
conv2d	followed_by	get_variable
get_variable	followed_by	reshape
bias_add	has_data_format	NCHW
param	followed_by	sqrt
matmul	followed_by	reshape
Conv2D	call	uniform
name_scope	followed_by	ones
name_scope	followed_by	sqrt
sqrt	followed_by	name_scope
sqrt	followed_by	matmul
name_scope	has_arg0	weightnorm
sqrt	call	reduce_sum
name_scope	has_arg0	filter_mask
conv2d	call	reshape
ones	followed_by	sqrt
sqrt	call	square
Conv2D	call	name_scope
Linear	call	uniform
variable_scope	followed_by	NHWC_to_NCHW
get_variable	has_arg0	w
param	followed_by	name_scope
normal	has_arg0	0.0
uniform	followed_by	param
mnist.gen.gan_def.discriminator_wgangp	call	variable_scope
mnist.gen.gan_def.discriminator_wgangp	call	Conv2D
sqrt	followed_by	sqrt
Linear	call	bias_add
param	call	Variable
Conv2D	call	param
Linear	followed_by	reshape
reshape	followed_by	bias_add
get_variable	followed_by	conv2d
sample	call	normal
reshape	call	shape
sample	followed_by	param
Linear	call	sample
Conv2D	call	sqrt
ones	has_dtype	float32
sqrt	followed_by	param
Conv2D	call	zeros
name_scope	followed_by	conv2d
reshape	call	bias_add
zeros	followed_by	bias_add
transpose	has_name	NHWC_to_NCHW
bias_add	call	zeros
conv2d	followed_by	param
conv2d	followed_by	conv2d
Linear	call	name_scope
Conv2D	call	conv2d
LeakyReLU	followed_by	reshape
mnist.gen.gan_def.discriminator_wgangp	call	Linear
mnist.gen.gan_def.discriminator_wgangp	call	LeakyReLU
Linear	call	sqrt
conv2d	call	get_variable
mnist.gen.gan_def.discriminator_wgangp	call	reshape
Linear	call	param
conv2d	call	conv2d
zeros	has_arg0	(output_dim,)
LeakyReLU	call	maximum
uniform	followed_by	uniform
Linear	call	matmul
normal	followed_by	svd
conv2d	call	variable_scope
reduce_sum	call	square
Linear	followed_by	relu
relu	followed_by	reshape
sqrt	followed_by	sample
Deconv2D	call	shape
bias_add	call	zeros
uniform	followed_by	sqrt
expand_dims	has_arg0	1
sqrt	followed_by	sqrt
reshape	followed_by	Deconv2D
param	followed_by	name_scope
variable_scope	followed_by	Linear
reshape	call	shape
normal	has_arg0	0.0
sqrt	followed_by	matmul
Linear	call	name_scope
reshape	followed_by	bias_add
param	followed_by	zeros
mnist.gen.gan_def.generator_wgangp	call	NCHW_to_NHWC
sample	call	svd
Linear	call	uniform
sqrt	call	reduce_sum
Deconv2D	call	transpose
svd	followed_by	reshape
matmul	followed_by	reshape
Deconv2D	call	bias_add
conv2d_transpose	has_padding	SAME
stack	followed_by	conv2d_transpose
name_scope	followed_by	sqrt
uniform	followed_by	param
mnist.gen.gan_def.generator_wgangp	call	Linear
zeros	has_dtype	float32
Deconv2D	call	zeros
transpose	has_name	NCHW_to_NHWC
normal	has_arg1	1.0
sqrt	followed_by	expand_dims
sqrt	followed_by	param
mnist.gen.gan_def.generator_wgangp	call	relu
Deconv2D	call	expand_dims
Deconv2D	call	param
bias_add	followed_by	transpose
sample	call	reshape
transpose	has_name	NHWC_to_NCHW
NCHW_to_NHWC	call	transpose
sample	call	normal
Deconv2D	call	conv2d_transpose
zeros	followed_by	bias_add
mnist.gen.gan_def.generator_wgangp	call	reshape
sqrt	followed_by	uniform
normal	followed_by	svd
sqrt	call	square
conv2d_transpose	followed_by	param
shape	followed_by	stack
Deconv2D	call	sqrt
param	call	Variable
Linear	call	sample
Deconv2D	followed_by	NCHW_to_NHWC
Deconv2D	call	name_scope
Linear	call	sqrt
param	followed_by	sqrt
Linear	call	matmul
name_scope	has_arg0	weightnorm
mnist.gen.gan_def.generator_wgangp	call	Deconv2D
relu	followed_by	Deconv2D
sample	followed_by	param
reshape	followed_by	matmul
uniform	followed_by	uniform
Deconv2D	call	stack
reduce_sum	call	square
Deconv2D	followed_by	relu
expand_dims	followed_by	transpose
Deconv2D	call	uniform
NCHW_to_NHWC	followed_by	reshape
Linear	call	bias_add
zeros	has_arg0	(output_dim,)
Linear	call	reshape
Linear	call	param
name_scope	followed_by	uniform
mnist.gen.gan_def.generator_wgangp	call	variable_scope
transpose	followed_by	shape
mnist.gen.gan_def.discriminator_dcgan	call	variable_scope
mnist.gen.gan_def.discriminator_dcgan	call	reshape
conv2d	call	get_variable
lrelu	call	maximum
mnist.gen.gan_def.discriminator_dcgan	call	concat
reshape	followed_by	conv_cond_concat
conv2d	call	variable_scope
conv2d	call	reshape
conv2d	followed_by	get_variable
lrelu	followed_by	conv2d
batch_norm.__init__	followed_by	conv2d
linear	followed_by	lrelu
conv2d	followed_by	conv_cond_concat
linear	call	variable_scope
variable_scope	followed_by	get_variable
concat	followed_by	batch_norm.__init__
reshape	followed_by	concat
conv_cond_concat	followed_by	lrelu
linear	call	get_variable
concat	has_arg0	1
variable_scope	followed_by	reshape
mnist.gen.gan_def.discriminator_dcgan	call	batch_norm.__init__
get_variable	has_arg0	w
concat	has_arg0	3
mnist.gen.gan_def.discriminator_dcgan	call	conv_cond_concat
batch_norm.__init__	call	variable_scope
batch_norm.__init__	followed_by	linear
get_variable	followed_by	matmul
get_variable	followed_by	reshape
matmul	followed_by	matmul
conv_cond_concat	call	concat
get_variable	followed_by	get_variable
conv2d	followed_by	conv2d
reshape	call	bias_add
get_variable	followed_by	conv2d
conv_cond_concat	followed_by	batch_norm.__init__
get_variable	has_arg0	biases
mnist.gen.gan_def.discriminator_dcgan	call	linear
linear	call	matmul
lrelu	followed_by	reshape
mnist.gen.gan_def.discriminator_dcgan	call	lrelu
concat	followed_by	linear
get_variable	has_arg0	bias
conv2d	followed_by	lrelu
get_variable	has_arg0	Matrix
mnist.gen.gan_def.discriminator_dcgan	call	conv2d
concat	call	ones
lrelu	followed_by	concat
conv2d	call	conv2d
tflib.ops.conv1d.Conv1D	call	zeros
tflib.ops.conv1d.Conv1D	call	param
param	call	Variable
tflib.ops.conv1d.Conv1D	call	bias_add
tflib.ops.conv1d.Conv1D	call	name_scope
name_scope	has_arg0	filter_mask
bias_add	followed_by	squeeze
tflib.ops.conv1d.Conv1D	call	sqrt
name_scope	followed_by	conv1d
ones	has_arg0	(filter_size, input_dim, output_dim)
tflib.ops.conv1d.Conv1D	call	ones
sqrt	call	reduce_sum
tflib.ops.conv1d.Conv1D	call	conv1d
ones	followed_by	sqrt
param	followed_by	zeros
name_scope	followed_by	ones
reduce_sum	call	square
tflib.ops.conv1d.Conv1D	call	uniform
zeros	has_dtype	float32
name_scope	has_arg0	weightnorm
sqrt	followed_by	param
expand_dims	followed_by	bias_add
conv1d	followed_by	param
sqrt	call	square
param	followed_by	sqrt
uniform	followed_by	param
sqrt	followed_by	name_scope
tflib.ops.conv1d.Conv1D	call	expand_dims
name_scope	followed_by	sqrt
conv1d	has_data_format	NCHW
expand_dims	has_arg0	3
bias_add	has_data_format	NCHW
sqrt	followed_by	sqrt
ones	has_dtype	float32
param	followed_by	name_scope
tflib.ops.conv1d.Conv1D	call	squeeze
sqrt	followed_by	uniform
zeros	followed_by	expand_dims
commons.measure.DropDevice.unmeasure_np	call	zeros_like
get_blur_func	followed_by	zeros_like
get_inpaint_func_opencv	followed_by	get_inpaint_func_tv
commons.measure.DropDevice.unmeasure_np	call	get_inpaint_func_tv
get_inpaint_func_opencv	followed_by	get_inpaint_func_opencv
zeros_like	followed_by	range
commons.measure.DropDevice.unmeasure_np	call	get_inpaint_func_opencv
commons.measure.DropDevice.unmeasure_np	call	get_blur_func
get_inpaint_func_tv	followed_by	get_blur_func
commons.measure.DropDevice.unmeasure_np	call	range
matmul	followed_by	matmul
mnist.gen.gan_def.discriminator_fc_cond	call	linear
variable_scope	followed_by	get_variable
variable_scope	followed_by	concat
concat	followed_by	linear
mnist.gen.gan_def.discriminator_fc_cond	call	concat
linear	followed_by	lrelu
mnist.gen.gan_def.discriminator_fc_cond	call	lrelu
get_variable	has_arg0	bias
concat	has_arg0	1
mnist.gen.gan_def.discriminator_fc_cond	call	batch_norm.__init__
linear	call	get_variable
mnist.gen.gan_def.discriminator_fc_cond	call	variable_scope
get_variable	followed_by	matmul
lrelu	followed_by	concat
get_variable	followed_by	get_variable
get_variable	has_arg0	Matrix
lrelu	call	maximum
batch_norm.__init__	followed_by	linear
concat	followed_by	batch_norm.__init__
linear	call	matmul
batch_norm.__init__	call	variable_scope
linear	call	variable_scope
get_gaussian_filter	followed_by	zeros_like
zeros_like	followed_by	range
unmeasure_func	call	range
amb_measure.DropDevice.unmeasure_np	call	zeros_like
amb_measure.DropDevice.unmeasure_np	call	unmeasure_func
unmeasure_func	call	zeros_like
amb_measure.DropDevice.unmeasure_np	call	range
get_gaussian_filter	call	exp
amb_measure.DropDevice.unmeasure_np	call	get_gaussian_filter
range	followed_by	unmeasure_func
commons.measure.DropDevice.__init__	call	__init__
commons.measure.KeepPatch.sample_theta	call	patch_mask
ones	followed_by	range
patch_mask	call	range
patch_mask	call	ones
loss_auxcond	call	reduce_mean
GradientDescentOptimizer	followed_by	MomentumOptimizer
loss_gradient_penalty	call	range
loss_gradient_penalty	call	gradients
sqrt	followed_by	reduce_mean
get_trainable_vars	call	get_collection
loss_wasserstein	followed_by	loss_wasserstein
reduce_mean	followed_by	reduce_mean
gradients	followed_by	range
get_optimizer	call	AdagradOptimizer
get_loss	followed_by	get_train_ops
reduce_mean	call	sigmoid_cross_entropy_with_logits
get_optimizer	call	MomentumOptimizer
MomentumOptimizer	followed_by	RMSPropOptimizer
get_trainable_vars	followed_by	get_trainable_vars
maximum	call	cast
get_loss	call	reduce_mean
AdamOptimizer	has_beta2	hparams.opt_param2
maximum	followed_by	get_optimizer
reduce_sum	call	square
get_train_ops	call	maximum
get_optimizer	call	RMSPropOptimizer
loss_vanilla	followed_by	loss_wasserstein
get_lossy	followed_by	get_loss
loss_vanilla	call	reduce_mean
get_trainable_vars	followed_by	placeholder
get_train_ops	call	placeholder
loss_gradient_penalty	followed_by	reduce_mean
commons.arch.model_fn_auxcond	call	get_train_ops
get_optimizer	call	GradientDescentOptimizer
commons.arch.model_fn_auxcond	call	get_lossy
sigmoid_cross_entropy_with_logits	call	zeros_like
get_optimizer	call	AdamOptimizer
placeholder	followed_by	maximum
get_loss	call	loss_vanilla
commons.arch.model_fn_auxcond	call	get_loss
RMSPropOptimizer	has_decay	hparams.opt_param1
range	has_arg0	1
reduce_mean	followed_by	loss_gradient_penalty
RMSPropOptimizer	followed_by	AdamOptimizer
loss_wasserstein	followed_by	loss_gradient_penalty
random_uniform	has_maxval	1.0
get_loss	call	loss_gradient_penalty
maximum	has_arg0	0.0
loss_gradient_penalty	followed_by	loss_auxcond
range	followed_by	sqrt
AdamOptimizer	followed_by	AdagradOptimizer
get_loss	call	loss_wasserstein
get_loss	call	loss_auxcond
sigmoid_cross_entropy_with_logits	call	ones_like
range	followed_by	random_uniform
sqrt	call	reduce_sum
loss_gradient_penalty	call	reduce_mean
get_optimizer	followed_by	get_optimizer
get_train_ops	call	get_trainable_vars
loss_gradient_penalty	call	sqrt
loss_wasserstein	call	reduce_mean
random_uniform	followed_by	gradients
loss_gradient_penalty	call	random_uniform
get_train_ops	call	get_optimizer
main	call	create_scripts
create_scripts	call	get_filename
get_useful_lines	followed_by	split
get_filename	followed_by	write_script
.create_scripts	call	main
create_scripts	call	get_script_text
get_filename	call	get_short_name
create_scripts	call	write_script
get_script_text	followed_by	get_filename
parse_grid_spec	call	get_useful_lines
get_script_text	call	find_overlap_idx
parse_grid_spec	followed_by	create_scripts
parse_grid_spec	call	split
get_short_name	call	split
main	call	parse_grid_spec
split	has_arg0	-
make_generator	followed_by	make_generator
load	call	make_generator
.tflib.small_imagenet	call	load
mnist.inf.utils.setup	call	get_expt_dir
mnist.inf.utils.setup	call	set_up_dir
get_expt_dir	followed_by	set_up_dir
amb_measure.DropDevice.__init__	call	__init__
batch_norm.__init__	followed_by	linear
get_variable	has_arg0	bias
concat	call	ones
concat	has_arg0	3
concat	has_arg0	1
variable_scope	followed_by	get_variable
batch_norm.__init__	followed_by	deconv2d
mnist.gen.gan_def.generator_dcgan	call	reshape
conv_cond_concat	call	concat
mnist.gen.gan_def.generator_dcgan	call	conv_cond_concat
concat	followed_by	batch_norm.__init__
get_variable	followed_by	conv2d_transpose
mnist.gen.gan_def.generator_dcgan	call	variable_scope
linear	call	variable_scope
mnist.gen.gan_def.generator_dcgan	call	linear
deconv2d	call	variable_scope
get_variable	has_arg0	biases
get_variable	followed_by	matmul
reshape	call	bias_add
get_variable	has_arg0	Matrix
deconv2d	call	get_variable
get_variable	has_arg0	w
variable_scope	followed_by	reshape
relu	followed_by	reshape
mnist.gen.gan_def.generator_dcgan	call	concat
reshape	followed_by	concat
matmul	followed_by	matmul
mnist.gen.gan_def.generator_dcgan	call	deconv2d
get_variable	followed_by	reshape
mnist.gen.gan_def.generator_dcgan	call	batch_norm.__init__
linear	followed_by	relu
deconv2d	call	conv2d_transpose
mnist.gen.gan_def.generator_dcgan	call	relu
linear	call	matmul
relu	followed_by	conv_cond_concat
deconv2d	call	reshape
conv_cond_concat	followed_by	deconv2d
reshape	followed_by	conv_cond_concat
conv_cond_concat	followed_by	batch_norm.__init__
relu	followed_by	concat
conv2d_transpose	followed_by	get_variable
deconv2d	followed_by	relu
linear	call	get_variable
get_variable	followed_by	get_variable
batch_norm.__init__	call	variable_scope
wiener_deconv	call	minimum
wiener_deconv	call	zeros_like
wiener_deconv	call	conj
zeros_like	followed_by	range
get_gaussian_filter	call	exp
real	followed_by	minimum
minimum	call	maximum
get_gaussian_filter	followed_by	conj
wiener_deconv	call	range
wiener_deconv	call	get_gaussian_filter
range	followed_by	range
range	followed_by	real
conj	followed_by	zeros_like
commons.measure.BlurAddNoise.unmeasure_np	call	wiener_deconv
wiener_deconv	call	real
blur	call	get_gaussian_filter
conv2d	followed_by	conv2d
blur	call	concat
reshape	call	bias_add
commons.measure.BlurAddNoise.measure	call	blur
conv2d	call	conv2d
concat	has_axis	3
blur	call	reshape
get_variable	has_arg0	biases
conv2d	call	variable_scope
get_gaussian_filter	followed_by	reshape
get_variable	has_arg0	w
range	followed_by	conv2d
get_gaussian_filter	call	exp
conv2d	call	get_variable
conv2d	call	reshape
commons.measure.BlurAddNoise.measure	call	add
conv2d	followed_by	concat
conv2d	followed_by	get_variable
blur	call	range
add	has_name	x_measured
blur	followed_by	add
variable_scope	followed_by	get_variable
get_variable	followed_by	conv2d
reshape	followed_by	range
blur	call	conv2d
get_variable	followed_by	reshape
blur_np	call	get_gaussian_filter
blur_np	call	reshape
get_gaussian_filter	followed_by	reshape
get_gaussian_filter	call	exp
commons.measure.BlurAddNoise.measure_np	call	blur_np
blur_np	call	constant
reshape	followed_by	constant
InferenceNetwork.__init__	call	global_variables
infer	call	weight_variable
variable_scope	followed_by	name_scope
infer	call	matmul
truncated_normal	followed_by	get_variable
constant	followed_by	get_variable
name_scope	followed_by	placeholder
weight_variable	followed_by	bias_variable
latest_checkpoint	has_arg0	./src/mnist/inf/ckpt/bs64_lr0.0001/
infer	call	softmax
placeholder	followed_by	dropout
relu	call	matmul
infer	followed_by	inf_restore_vars
main	call	equal
bias_variable	call	get_variable
name_scope	has_arg0	conv1
infer	call	dropout
bias_variable	followed_by	reshape
max_pool	has_padding	SAME
weight_variable	call	truncated_normal
equal	call	argmax
main	call	InferenceNetwork.__init__
infer	call	reshape
name_scope	has_arg0	pool1
matmul	followed_by	softmax
global_variables	followed_by	Saver
InferenceNetwork.__init__	followed_by	placeholder
infer	call	bias_variable
bias_variable	call	constant
equal	followed_by	reduce_mean
name_scope	followed_by	weight_variable
argmax	has_arg0	1
infer	call	placeholder
Saver	followed_by	latest_checkpoint
infer	call	relu
bias_variable	followed_by	relu
relu	call	conv2d
InferenceNetwork.__init__	call	Saver
InferenceNetwork.__init__	call	placeholder
placeholder	followed_by	infer
name_scope	has_arg0	fc2
argmax	followed_by	argmax
reshape	followed_by	name_scope
truncated_normal	has_stddev	0.1
InferenceNetwork.__init__	call	infer
name_scope	has_arg0	conv2
InferenceNetwork.__init__	call	Session
reshape	followed_by	relu
name_scope	has_arg0	fc1
name_scope	followed_by	reshape
name_scope	has_arg0	pool2
infer	call	name_scope
reduce_mean	call	cast
infer	call	max_pool_2x2
constant	has_arg0	0.1
Session	followed_by	placeholder
InferenceNetwork.__init__	call	latest_checkpoint
placeholder	followed_by	equal
relu	followed_by	name_scope
bias_variable	followed_by	matmul
reduce_mean	followed_by	reshape
max_pool_2x2	followed_by	name_scope
InferenceNetwork.__init__	call	inf_restore_vars
main	call	placeholder
weight_variable	call	get_variable
name_scope	followed_by	max_pool_2x2
main	call	reshape
infer	call	variable_scope
placeholder	has_name	x_ph
.mnist.inf.test_inf_net	call	main
max_pool_2x2	call	max_pool
name_scope	has_arg0	dropout
main	call	reduce_mean
dropout	followed_by	name_scope
name_scope	has_arg0	reshape
inf_restore_vars	followed_by	global_variables
main	call	get_pkl_filepaths
get_metrics	followed_by	get_df
read_hparams	call	load
get_df	followed_by	save_to_pickle
load_if_pickled	call	load
read_hparams	followed_by	get_metrics
main	call	get_metrics
get_pkl_filepaths	followed_by	read_hparams
main	call	save_to_pickle
.aggregator_cifar	call	main
main	call	read_hparams
get_metrics	call	load_if_pickled
main	call	get_df
sample_theta	call	uniform
ones	has_shape	self.batch_dims
commons.measure.DropRowCol.sample_theta	call	sample_theta
get_noise_shape	followed_by	uniform
uniform	followed_by	uniform
sample_theta	call	get_noise_shape
uniform	followed_by	ones
sample_theta	followed_by	sample_theta
sample_theta	call	ones
celebA.gen.wgan_utils.weight_variable_xavier_initialized	call	sqrt
celebA.gen.wgan_utils.weight_variable_xavier_initialized	call	weight_variable
weight_variable	call	get_variable
truncated_normal	followed_by	Variable
sqrt	followed_by	weight_variable
Variable	followed_by	get_variable
weight_variable	call	truncated_normal
weight_variable	call	Variable
get_variable	has_arg0	w
celebA.gen.wgan_utils.conv2d_basic	call	conv2d
get_variable	followed_by	conv2d
variable_scope	followed_by	get_variable
conv2d	followed_by	bias_add
get_variable	has_arg0	biases
conv2d	call	variable_scope
conv2d	call	conv2d
get_variable	followed_by	reshape
reshape	call	bias_add
conv2d	followed_by	get_variable
conv2d	call	reshape
celebA.gen.wgan_utils.conv2d_basic	call	bias_add
conv2d	followed_by	conv2d
conv2d	call	get_variable
sqrt	followed_by	sqrt
sqrt	followed_by	expand_dims
expand_dims	followed_by	transpose
conv2d_transpose	has_padding	SAME
tflib.ops.deconv2d.Deconv2D	call	expand_dims
bias_add	followed_by	transpose
uniform	followed_by	uniform
shape	followed_by	stack
param	followed_by	zeros
tflib.ops.deconv2d.Deconv2D	call	name_scope
param	followed_by	name_scope
transpose	has_name	NCHW_to_NHWC
zeros	followed_by	bias_add
zeros	has_dtype	float32
tflib.ops.deconv2d.Deconv2D	call	zeros
sqrt	followed_by	param
transpose	followed_by	shape
tflib.ops.deconv2d.Deconv2D	call	param
name_scope	has_arg0	weightnorm
reduce_sum	call	square
param	call	Variable
param	followed_by	sqrt
tflib.ops.deconv2d.Deconv2D	call	shape
tflib.ops.deconv2d.Deconv2D	call	bias_add
name_scope	followed_by	sqrt
expand_dims	has_arg0	1
uniform	followed_by	param
sqrt	call	reduce_sum
tflib.ops.deconv2d.Deconv2D	call	stack
stack	followed_by	conv2d_transpose
tflib.ops.deconv2d.Deconv2D	call	sqrt
sqrt	call	square
tflib.ops.deconv2d.Deconv2D	call	uniform
tflib.ops.deconv2d.Deconv2D	call	transpose
conv2d_transpose	followed_by	param
sqrt	followed_by	uniform
tflib.ops.deconv2d.Deconv2D	call	conv2d_transpose
transpose	has_name	NHWC_to_NCHW
project	call	reduce_sum
pad	has_arg0	CONSTANT
pad	call	get_padding_prp
reduce_sum	has_axis	2
tf.RegisterGradient(rnd_name)	followed_by	get_default_graph
pad	followed_by	range
commons.measure.PadRotateProject.measure	call	rotate
pad	call	pad
concat	has_name	x_measured
commons.measure.PadRotateProject.measure	call	project
tf.RegisterGradient(rnd_name)	call	RegisterGradient
rotate	call	reshape
commons.measure.PadRotateProject.measure	call	concat
rotate	followed_by	project
rotate	call	tf_image_rotate
py_func	call	tf.RegisterGradient(rnd_name)
get_padding_prp	followed_by	pad
tf_image_rotate	followed_by	reshape
tf_image_rotate	call	py_func
reduce_sum	followed_by	reshape
name_scope	has_arg0	image_rotate
py_func	call	py_func
name_scope	followed_by	py_func
project	followed_by	concat
project	call	reshape
commons.measure.PadRotateProject.measure	call	range
range	followed_by	rotate
get_default_graph	followed_by	py_func
commons.measure.PadRotateProject.measure	call	pad
tf_image_rotate	call	name_scope
py_func	call	get_default_graph
get_ckpt_path	call	get_checkpoint_state
mnist.inf.basic_utils.try_restore	call	get_ckpt_path
wiener_deconv	call	real
amb_measure.BlurAddNoise.unmeasure_np	call	wiener_deconv
wiener_deconv	call	zeros_like
wiener_deconv	call	conj
range	followed_by	real
conj	followed_by	zeros_like
get_gaussian_filter	followed_by	conj
wiener_deconv	call	minimum
range	followed_by	range
get_gaussian_filter	call	exp
real	followed_by	minimum
wiener_deconv	call	get_gaussian_filter
zeros_like	followed_by	range
minimum	call	maximum
wiener_deconv	call	range
celebA.gen.wgan_utils.maybe_download_and_extract	call	split
split	has_arg0	/
zeros	followed_by	zeros
range	has_arg0	16
GradientDescentOptimizer	followed_by	MomentumOptimizer
get_trainable_vars	call	get_collection
loss_gradient_penalty	call	sqrt
zeros	followed_by	min
main	call	get_phs_cond
reduce_mean	followed_by	loss_gradient_penalty
main	call	print_hparams
set_up_dir	followed_by	set_up_dir
get_inception_data	call	get_inception_score
get_mode_dir	followed_by	get_model_dir
get_optimizer	call	AdamOptimizer
maximum	call	cast
train	call	run
get_task_dir	followed_by	get_mode_dir
save_inception_data	call	get_inception_data
random_uniform	followed_by	gradients
scalar	has_arg0	g_loss
loss_gradient_penalty	call	range
sample_z_val	followed_by	range
reduce_mean	call	sigmoid_cross_entropy_with_logits
save_samples	followed_by	save_inception_data
RMSPropOptimizer	followed_by	AdamOptimizer
Saver	followed_by	run
get_samples	call	run
get_inception_data	followed_by	save_to_pickle
minimum	followed_by	save_images
.main	call	main
loss_gradient_penalty	call	gradients
sample_y_val	call	ceil
loss_gradient_penalty	call	reduce_mean
run	followed_by	get_samples
get_optimizer	call	MomentumOptimizer
sample_cond	call	ceil
sample_cond	call	range
get_inception_score	call	exp
main	call	setup_dirs
train	call	FileWriter
model_fn_cond	call	get_lossy
merge	followed_by	FileWriter
get_ckpt_path	call	get_checkpoint_state
main	call	get_mdevice
maximum	followed_by	get_optimizer
save_images	followed_by	minimum
RealValIterator.__init__	followed_by	RealValIterator.__init__
sqrt	call	reduce_sum
log	followed_by	log
main	call	RealValIterator.__init__
get_samples	call	sample_z_val
get_loss	followed_by	get_train_ops
train	call	save_samples
Saver	has_max_to_keep	hparams.max_checkpoints
loss_gradient_penalty	followed_by	reduce_mean
scalar	followed_by	merge
run	followed_by	run
sample_cond	call	zeros
sample_z_val	call	uniform
get_loss	call	loss_gradient_penalty
get_trainable_vars	followed_by	get_trainable_vars
get_samples	call	sample_y_val
sqrt	followed_by	reduce_mean
get_optimizer	call	GradientDescentOptimizer
placeholder	has_name	y_ph
get_expt_dir	call	get_model_dir
model_fn_cond	followed_by	train
get_samples	followed_by	save_samples
sample_y_val	followed_by	sample_cond
get_hparams	followed_by	main
save_inception_data	call	get_samples
save_hparams	followed_by	get_mdevice
AdamOptimizer	followed_by	AdagradOptimizer
main	call	model_fn_cond
get_loss	call	loss_wasserstein
get_expt_dir	call	get_mode_dir
loss_wasserstein	followed_by	loss_wasserstein
sample_y_val	call	zeros
mean	has_axis	0
sigmoid_cross_entropy_with_logits	call	zeros_like
tile	followed_by	zeros
model_fn_cond	call	get_loss
save_inception_data	call	save_to_pickle
range	followed_by	zeros
range	followed_by	sqrt
get_phs_uncond	call	placeholder
train	call	get_samples
get_loss	call	reduce_mean
range	followed_by	random_uniform
Session	followed_by	scalar
get_mdevice	call	BlurAddNoise.__init__
get_train_ops	call	maximum
main	call	model_fn_uncond
train	call	save_inception_data
get_inception_score	call	log
scalar	has_arg0	d_loss
range	followed_by	get_samples
get_mdevice	followed_by	RealValIterator.__init__
model_fn_uncond	followed_by	train
save_inception_data	followed_by	get_samples
log	followed_by	mean
placeholder	followed_by	placeholder
model_fn_uncond	call	get_lossy
get_mdevice	call	ExtractPatch.__init__
loss_auxcond	call	reduce_mean
main	call	train
train	call	merge
placeholder	has_name	x_ph
train	call	Session
save_samples	call	sqrt
get_loss	call	loss_vanilla
scalar	followed_by	scalar
train	followed_by	get_phs_cond
gradients	followed_by	range
maximum	has_arg0	0.0
setup_vals	call	get_expt_dir
model_fn_uncond	call	get_train_ops
get_lossy	followed_by	get_loss
train	call	range
sample_y_val	call	tile
ExtractPatch.__init__	call	__init__
get_expt_dir	call	get_task_dir
reduce_sum	call	square
min	followed_by	sample_z_val
save_images	followed_by	save_images
setup_dirs	followed_by	print_hparams
uniform	has_arg0	1
get_inception_data	call	mean
get_optimizer	call	AdagradOptimizer
save_inception_data	call	range
get_phs_cond	followed_by	model_fn_cond
range	has_arg0	1
loss_vanilla	followed_by	loss_wasserstein
sample_z_val	followed_by	run
reduce_mean	followed_by	reduce_mean
train	call	scalar
get_samples	call	sample_cond
save_images	call	merge
model_fn_cond	call	get_train_ops
main	call	setup_vals
try_restore	call	get_ckpt_path
zeros	has_arg0	(hparams.batch_size, hparams.y_dim)
loss_vanilla	call	reduce_mean
loss_gradient_penalty	followed_by	loss_auxcond
setup_dirs	call	set_up_dir
get_samples	followed_by	get_inception_data
sample_cond	call	min
get_inception_score	call	mean
uniform	followed_by	Adam
sample_cond	call	run
RealValIterator.__init__	followed_by	get_phs_uncond
get_train_ops	call	get_optimizer
train	call	Saver
sample_cond	call	sample_z_val
placeholder	has_name	z_ph
mean	followed_by	log
sample_cond	followed_by	sample_z_val
uniform	has_size	(hparams.batch_size, hparams.z_dim)
MomentumOptimizer	followed_by	RMSPropOptimizer
ceil	followed_by	range
main	call	get_phs_uncond
get_inception_score	followed_by	mean
run	followed_by	range
RMSPropOptimizer	has_decay	hparams.opt_param1
setup_vals	followed_by	setup_dirs
get_hparams	call	uniform
save_samples	call	minimum
run	followed_by	try_restore
AdamOptimizer	has_beta2	hparams.opt_param2
FileWriter	followed_by	Saver
try_restore	followed_by	range
get_phs_cond	call	placeholder
minimum	call	maximum
BlurAddNoise.__init__	call	__init__
loss_wasserstein	call	reduce_mean
loss_gradient_penalty	call	random_uniform
main	call	save_hparams
model_fn_uncond	call	get_loss
zeros	has_arg0	(num_samples, hparams.y_dim)
get_hparams	call	Adam
get_phs_uncond	followed_by	model_fn_uncond
get_train_ops	call	placeholder
.main	call	get_hparams
sqrt	followed_by	save_images
get_model_dir	followed_by	get_opt_dir
get_loss	call	loss_auxcond
get_trainable_vars	followed_by	placeholder
mean	followed_by	exp
save_samples	call	save_images
get_optimizer	followed_by	get_optimizer
placeholder	followed_by	maximum
print_hparams	followed_by	save_hparams
ExtractPatch.__init__	followed_by	BlurAddNoise.__init__
range	followed_by	sample_z_val
train	call	sample_z_val
loss_wasserstein	followed_by	loss_gradient_penalty
random_uniform	has_maxval	1.0
get_optimizer	call	RMSPropOptimizer
get_expt_dir	call	get_opt_dir
get_train_ops	call	get_trainable_vars
train	call	try_restore
sigmoid_cross_entropy_with_logits	call	ones_like
zeros	has_arg0	(h * size[0], w * size[1], 3)
merge	call	zeros
ceil	followed_by	tile
range	followed_by	run
get_metrics	followed_by	get_df
get_metrics	call	load_if_pickled
read_hparams	followed_by	get_metrics
main	call	read_hparams
.aggregator_mnist	call	main
get_df	followed_by	save_to_pickle
main	call	get_metrics
read_hparams	call	load
main	call	get_df
load_if_pickled	call	load
main	call	save_to_pickle
get_df	call	get_all_values
main	call	get_pkl_filepaths
get_pkl_filepaths	followed_by	read_hparams
commons.measure.DropPatch.sample_theta	call	patch_mask
patch_mask	call	range
ones	followed_by	range
patch_mask	call	ones
ExponentialMovingAverage	followed_by	cond
commons.ops.batch_norm.__call__	call	batch_norm
batch_norm	call	variable_scope
moments	has_name	moments
batch_norm	call	batch_normalization
batch_norm	call	cond
get_variable	followed_by	moments
moments	followed_by	ExponentialMovingAverage
get_variable	followed_by	get_variable
variable_scope	followed_by	get_variable
batch_norm	call	ExponentialMovingAverage
cond	followed_by	batch_normalization
batch_norm	call	moments
batch_norm	call	get_variable
commons.measure.PadRotateProjectDevice.__init__	call	__init__
infer	call	weight_variable
infer	call	bias_variable
main	call	placeholder
argmax	followed_by	argmax
reshape	followed_by	relu
Saver	has_max_to_keep	hparams.max_checkpoints
infer	call	matmul
main	call	infer
placeholder	followed_by	placeholder
name_scope	has_arg0	reshape
get_trainable_vars	call	get_collection
max_pool_2x2	call	max_pool
infer	call	reshape
relu	followed_by	name_scope
bias_variable	followed_by	matmul
main	call	reduce_mean
infer	call	relu
main	call	equal
dropout	followed_by	name_scope
equal	call	argmax
name_scope	has_arg0	conv2
name_scope	has_arg0	pool2
infer	call	softmax
Saver	followed_by	run
try_restore	followed_by	get_trainable_vars
.mnist.inf.train	call	main
reshape	followed_by	name_scope
name_scope	has_arg0	pool1
infer	call	max_pool_2x2
reduce_mean	followed_by	equal
range	followed_by	run
infer	call	variable_scope
matmul	followed_by	softmax
equal	followed_by	reduce_mean
name_scope	has_arg0	fc1
name_scope	has_arg0	dropout
main	call	run
variable_scope	followed_by	name_scope
main	call	get_hparams
main	call	try_restore
placeholder	followed_by	dropout
reduce_mean	call	cast
infer	call	dropout
get_trainable_vars	followed_by	range
get_ckpt_path	call	get_checkpoint_state
name_scope	followed_by	placeholder
max_pool	has_padding	SAME
main	call	Saver
name_scope	followed_by	max_pool_2x2
truncated_normal	has_stddev	0.1
bias_variable	call	get_variable
bias_variable	followed_by	relu
bias_variable	followed_by	reshape
name_scope	has_arg0	fc2
max_pool_2x2	followed_by	name_scope
relu	call	matmul
weight_variable	call	get_variable
main	call	Session
main	call	range
argmax	has_arg0	1
infer	call	name_scope
weight_variable	followed_by	bias_variable
infer	call	placeholder
try_restore	call	get_ckpt_path
relu	call	conv2d
name_scope	followed_by	weight_variable
infer	followed_by	reduce_mean
reduce_mean	followed_by	Session
reduce_mean	call	softmax_cross_entropy_with_logits
get_hparams	followed_by	placeholder
run	followed_by	run
main	call	get_trainable_vars
name_scope	has_arg0	conv1
name_scope	followed_by	reshape
truncated_normal	followed_by	get_variable
bias_variable	call	constant
Session	followed_by	Saver
weight_variable	call	truncated_normal
placeholder	followed_by	infer
constant	has_arg0	0.1
run	followed_by	try_restore
constant	followed_by	get_variable
get_gaussian_filter	followed_by	reshape
blur_np	call	reshape
amb_measure.BlurAddNoise.measure_np	call	blur_np
blur_np	call	constant
reshape	followed_by	constant
blur_np	call	get_gaussian_filter
get_gaussian_filter	call	exp
get_image	call	imread
transform	call	center_crop
round	followed_by	round
celebA.gen.utils.RealValIterator.next	call	get_image
get_image	call	transform
imread	followed_by	transform
center_crop	call	round
range	followed_by	conv2d
get_variable	has_arg0	biases
blur	call	get_gaussian_filter
blur	call	reshape
conv2d	followed_by	concat
reshape	call	bias_add
conv2d	call	variable_scope
get_variable	has_arg0	w
amb_measure.BlurAddNoise.measure	call	blur
conv2d	followed_by	get_variable
blur	call	concat
conv2d	call	conv2d
conv2d	call	reshape
variable_scope	followed_by	get_variable
conv2d	followed_by	conv2d
blur	followed_by	add
reshape	followed_by	range
conv2d	call	get_variable
get_gaussian_filter	call	exp
blur	call	range
blur	call	conv2d
get_gaussian_filter	followed_by	reshape
get_variable	followed_by	conv2d
concat	has_axis	3
add	has_name	x_measured
amb_measure.BlurAddNoise.measure	call	add
get_variable	followed_by	reshape
concat	has_axis	0
commons.measure.ExtractPatch.measure	call	range
reshape	followed_by	concat
concat	followed_by	get_padding_ep
pad	has_arg0	CONSTANT
commons.measure.ExtractPatch.measure	call	concat
range	followed_by	reshape
pad	has_name	x_measured
get_padding_ep	followed_by	pad
commons.measure.ExtractPatch.measure	call	reshape
commons.measure.ExtractPatch.measure	call	get_padding_ep
commons.measure.ExtractPatch.measure	call	pad
