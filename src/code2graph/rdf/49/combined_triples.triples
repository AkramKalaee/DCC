.gan_cifar_resnet	call	constant
shuffle	followed_by	zeros
mnist_generator	call	shuffle
sample	call	normal
reduce_mean	call	cast
print_hparams	followed_by	save_hparams
BlurAddNoise.__init__	call	__init__
ResidualBlock	call	nonlinearity
AdamOptimizer	followed_by	params_with_name
flat_to_NCHW	call	reshape
add_n	followed_by	constant
Generator	followed_by	amb_get_lossy
.gan_cifar_resnet	call	inf_train_gen
load	call	cifar_generator
sqrt	call	reduce_sum
name_scope	followed_by	conv2d
reshape	followed_by	OptimizedResBlockDisc1
NHWC_to_NCHW	call	transpose
nonlinearity	followed_by	Conv2D
reshape	followed_by	random_uniform
amb_measure_unmeasure_np	call	flat_to_NCHW
unpickle	call	load
Layernorm	call	zeros
.gan_cifar_resnet	call	plot
uniform	followed_by	uniform
moments	followed_by	param
add_n	followed_by	add_n
amb_measure_unmeasure_np	followed_by	range
conv2d	call	reshape
embedding_lookup	followed_by	batch_normalization
zeros	has_dtype	float32
ones	followed_by	param
nonlinearity	followed_by	reduce_mean
random_uniform	followed_by	split
reshape	followed_by	transpose
get_mdevice	followed_by	range
normal	has_arg1	1.0
amb_setup	call	get_hparams
Layernorm	call	moments
uniform	followed_by	sqrt
Saver	has_max_to_keep	AMB_HPARAMS.max_checkpoints
generate_image	call	reshape
constant	has_arg0	0.0
Linear	call	bias_add
Batchnorm	call	batch_normalization
cast	call	equal
OptimizedResBlockDisc1	followed_by	ResidualBlock
Linear	call	matmul
save_images	call	reshape
placeholder	followed_by	split
Linear	call	reshape
Saver	followed_by	try_restore
Generator	call	nonlinearity
load	call	load
.gan_cifar_resnet	call	amb_setup
Generator	call	random_normal
amb_get_lossy	call	flat_to_NCHW
_fused_batch_norm_training	followed_by	cond
constant	followed_by	constant
cond	followed_by	moments
.gan_cifar_resnet	call	maximum
to_int32	call	argmax
sqrt	followed_by	param
reshape	has_arg0	(X.shape[0], int(np.sqrt(X.shape[1])), int(np.sqrt(X.shape[1])))
.gan_cifar_resnet	call	reshape
param	call	Variable
ones	has_arg0	(filter_size, filter_size, input_dim, output_dim)
sample	followed_by	param
get_variable	has_arg0	w
reshape	call	cast
transpose	has_arg0	0
AdamOptimizer	has_beta2	0.9
get_hparams	followed_by	setup_vals
transpose	has_arg2	3
Normalize	call	Batchnorm
.gan_cifar_resnet	call	reduce_mean
Conv2D	call	name_scope
.gan_cifar_resnet	call	run
load	followed_by	run
Generator	call	reshape
generate_image	call	run
normal	followed_by	svd
reshape	has_arg0	(batch_size, 3072)
random_uniform	has_maxval	1.0
.gan_cifar_resnet	call	amb_measure_unmeasure_np
Generator	call	Normalize
Linear	followed_by	reshape
Conv2D	followed_by	tanh
conv2d	call	variable_scope
.gan_cifar_resnet	call	add_n
reduce_mean	followed_by	add_n
amb_get_lossy	followed_by	reshape
sample	call	svd
reshape	followed_by	matmul
_fused_batch_norm_training	call	fused_batch_norm
amb_setup	followed_by	get_mdevice
Conv2D	call	conv2d
reshape	followed_by	bias_add
Layernorm	followed_by	Batchnorm
get_inception_score	call	get_inception_score
Layernorm	call	param
Layernorm	call	reshape
flat_to_NCHW	followed_by	NCHW_to_flat
.gan_cifar_resnet	call	Session
set_up_dir	followed_by	set_up_dir
amb_measure_unmeasure_np	call	NCHW_to_flat
generate_image	followed_by	flush
reshape	followed_by	Linear
.gan_cifar_resnet	call	Saver
ones	followed_by	reshape
save_images	call	merge
conv2d	followed_by	get_variable
run	followed_by	Saver
ones	followed_by	embedding_lookup
conv2d	call	get_variable
get_variable	has_arg0	biases
.gan_cifar_resnet	call	generate_image
normal	has_arg0	0.0
random_normal	followed_by	Linear
Conv2D	call	param
conv2d	followed_by	conv2d
get_expt_dir	call	get_mode_dir
bias_add	has_data_format	NCHW
NCHW_to_NHWC	call	transpose
zeros	has_arg0	(output_dim,)
zeros	has_dtype	int32
.gan_cifar_resnet	call	range
Discriminator	call	Linear
param	followed_by	name_scope
Conv2D	call	sqrt
plot	followed_by	flush
flush	followed_by	tick
Generator	followed_by	load
sqrt	followed_by	reshape
save_x_lossy	call	run
params_with_name	followed_by	constant
inf_train_gen	followed_by	range
merge	call	zeros
transpose	followed_by	zeros
get_inception_score	call	run
.gan_cifar_resnet	call	params_with_name
sample	call	reshape
Conv2D	followed_by	Conv2D
NCHW_to_NHWC	followed_by	flat_to_NCHW
Batchnorm	call	expand_dims
range	followed_by	print_model_settings
Generator	call	Linear
flatten	followed_by	sqrt
NCHW_to_flat	followed_by	NHWC_to_NCHW
Conv2D	call	ones
Conv2D	call	bias_add
bias_add	call	zeros
cifar_generator	followed_by	cifar_generator
Linear	followed_by	Linear
cond	followed_by	cond
name_scope	has_arg0	filter_mask
placeholder	followed_by	placeholder
get_ckpt_path	call	get_checkpoint_state
setup_vals	followed_by	setup_dirs
Batchnorm	followed_by	Batchnorm
zeros	has_arg0	(h * size[0], w * size[1], 3)
ResidualBlock	call	Normalize
uniform	followed_by	param
.gan_cifar_resnet	call	save_x_lossy
range	followed_by	amb_measure_unmeasure_np
reshape	followed_by	reshape
get_inception_score	followed_by	plot
Batchnorm	call	embedding_lookup
save_x_lossy	call	range
save_x_lossy	call	save_images
batch_normalization	has_arg0	1e-05
reshape	call	sqrt
expand_dims	has_arg0	3
svd	followed_by	reshape
Linear	call	param
argmax	has_dimension	1
amb_get_lossy	call	NCHW_to_NHWC
reshape	has_arg0	(100, 3, 32, 32)
.gan_cifar_resnet	call	split
Generator	call	Conv2D
device	followed_by	cast
.gan_cifar_resnet	call	cast
name_scope	followed_by	sqrt
plot	followed_by	plot
plot	followed_by	save_x_lossy
Generator	call	tanh
reshape	call	shape
matmul	followed_by	reshape
param	followed_by	ones
amb_setup	call	setup_dirs
make_generator	followed_by	make_generator
shuffle	followed_by	shuffle
zeros	followed_by	zeros
mnist_generator	call	zeros
flush	call	sort
print_model_settings	followed_by	amb_setup
try_restore	followed_by	load
run	followed_by	get_inception_score
Linear	call	sqrt
amb_get_lossy	followed_by	device
Batchnorm	call	cond
get_inception_score	followed_by	get_inception_score
load	followed_by	inf_train_gen
device	followed_by	Generator
cast	call	random_uniform
Discriminator	call	reduce_mean
name_scope	followed_by	ones
.gan_cifar_resnet	call	AdamOptimizer
OptimizedResBlockDisc1	call	nonlinearity
mean	followed_by	sort
Discriminator	call	nonlinearity
sqrt	followed_by	matmul
load	call	make_generator
nonlinearity	call	relu
concat	followed_by	random_uniform
Generator	call	ResidualBlock
.gan_cifar_resnet	call	load
random_uniform	followed_by	gradients
Discriminator	call	ResidualBlock
generate_image	call	save_images
amb_setup	call	save_hparams
range	followed_by	range
load	followed_by	load
plot	followed_by	mean
save_images	call	zeros
.gan_cifar_resnet	call	mean
reshape	followed_by	ResidualBlock
run	followed_by	run
amb_get_lossy	followed_by	Discriminator
tick	followed_by	get_inception_score
zeros	followed_by	param
cifar_generator	call	unpickle
Normalize	call	Layernorm
ones	followed_by	batch_normalization
embedding_lookup	followed_by	embedding_lookup
ResidualBlock	followed_by	Normalize
.gan_cifar_resnet	call	device
Discriminator	call	OptimizedResBlockDisc1
Discriminator	followed_by	reduce_mean
Layernorm	call	ones
setup_dirs	followed_by	print_hparams
Batchnorm	call	param
name_scope	has_arg0	weightnorm
amb_get_lossy	call	NCHW_to_flat
range	followed_by	Session
ResidualBlock	followed_by	ResidualBlock
.gan_cifar_resnet	call	print_model_settings
reshape	has_arg0	(batch_size, 3, 32, 32)
.gan_cifar_resnet	call	random_uniform
save_images	call	transpose
equal	call	to_int32
get_variable	followed_by	conv2d
nonlinearity	followed_by	Normalize
reduce_mean	followed_by	Linear
.gan_cifar_resnet	call	gradients
mnist_generator	followed_by	mnist_generator
param	followed_by	sqrt
concat	followed_by	Discriminator
split	followed_by	device
get_inception_score	call	range
reduce_mean	call	sparse_softmax_cross_entropy_with_logits
.gan_cifar_resnet	call	tick
.gan_cifar_resnet	call	try_restore
run	followed_by	save_images
Generator	followed_by	cast
.gan_cifar_resnet	call	concat
setup_vals	call	get_expt_dir
save_images	followed_by	reshape
conv2d	followed_by	param
get_variable	followed_by	reshape
reduce_mean	followed_by	device
maximum	followed_by	device
save_x_lossy	call	reshape
reshape	has_arg0	(64, 3, 32, 32)
save_images	call	sqrt
reshape	call	bias_add
sqrt	followed_by	reduce_mean
reduce_sum	call	square
amb_get_lossy	call	NHWC_to_NCHW
device	followed_by	concat
get_mdevice	call	BlurAddNoise.__init__
tanh	followed_by	reshape
save_x_lossy	followed_by	range
.gan_cifar_resnet	call	amb_get_lossy
.gan_cifar_resnet	call	flush
sqrt	followed_by	sample
conv2d	call	conv2d
get_task_dir	followed_by	get_mode_dir
get_inception_score	followed_by	List
Layernorm	call	batch_normalization
load	followed_by	mnist_generator
.gan_cifar_resnet	call	sqrt
zeros	has_arg0	(h * nh, w * nw, 3)
ones	has_dtype	float32
expand_dims	followed_by	param
maximum	has_arg0	0.0
Batchnorm	call	moments
.gan_cifar_resnet	call	Discriminator
.gan_cifar_resnet	call	Generator
constant	followed_by	Generator
Batchnorm	call	zeros
sqrt	call	square
concat	followed_by	concat
name_scope	followed_by	uniform
constant	followed_by	params_with_name
transpose	has_arg1	2
mean	followed_by	generate_image
param	followed_by	zeros
amb_measure_unmeasure_np	call	NHWC_to_NCHW
Linear	call	uniform
ResidualBlock	followed_by	nonlinearity
variable_scope	followed_by	get_variable
params_with_name	followed_by	maximum
sqrt	followed_by	sqrt
zeros	has_arg0	(h * nh, w * nw)
gradients	followed_by	sqrt
reshape	followed_by	batch_normalization
Linear	call	name_scope
AdamOptimizer	followed_by	AdamOptimizer
save_images	followed_by	save_images
Session	followed_by	placeholder
Normalize	followed_by	nonlinearity
save_images	call	flatten
split	has_axis	0
sqrt	followed_by	uniform
ones	followed_by	_fused_batch_norm_training
fused_batch_norm	has_data_format	NCHW
cast	followed_by	Generator
.gan_cifar_resnet	call	get_mdevice
ones	followed_by	sqrt
Batchnorm	call	_fused_batch_norm_training
amb_setup	call	setup_vals
get_expt_dir	call	get_task_dir
transpose	has_arg3	1
sqrt	followed_by	name_scope
try_restore	call	get_ckpt_path
.gan_cifar_resnet	call	placeholder
reduce_mean	followed_by	reduce_mean
Linear	call	sample
concat	has_axis	0
amb_measure_unmeasure_np	call	NCHW_to_NHWC
split	followed_by	amb_get_lossy
run	followed_by	plot
load	call	mnist_generator
maximum	call	cast
range	followed_by	run
run	call	initialize_all_variables
Conv2D	call	zeros
zeros	followed_by	bias_add
NCHW_to_flat	call	reshape
plot	followed_by	get_inception_score
.gan_cifar_resnet	call	get_inception_score
run	followed_by	range
add_n	followed_by	AdamOptimizer
Conv2D	call	uniform
setup_dirs	call	set_up_dir
get_inception_score	call	List
Batchnorm	call	ones
Discriminator	call	reshape
flush	call	mean
amb_setup	call	print_hparams
commons.measure.DropDevice.__init__	call	__init__
Linear	followed_by	reshape
Linear	call	param
Conv2D	call	ones
mnist.gen.gan_def.discriminator_wgangp	call	variable_scope
get_variable	followed_by	conv2d
bias_add	has_data_format	NCHW
normal	has_arg1	1.0
zeros	has_arg0	(output_dim,)
name_scope	followed_by	uniform
sqrt	followed_by	param
Conv2D	followed_by	LeakyReLU
conv2d	call	variable_scope
Linear	call	bias_add
Linear	call	matmul
reshape	followed_by	Linear
bias_add	call	zeros
Conv2D	call	bias_add
sqrt	followed_by	matmul
sample	call	svd
matmul	followed_by	reshape
name_scope	followed_by	ones
get_variable	has_arg0	biases
NHWC_to_NCHW	followed_by	Conv2D
conv2d	followed_by	get_variable
conv2d	followed_by	param
reduce_sum	call	square
mnist.gen.gan_def.discriminator_wgangp	call	Conv2D
param	call	Variable
ones	has_arg0	(filter_size, filter_size, input_dim, output_dim)
sample	call	reshape
LeakyReLU	followed_by	reshape
sqrt	followed_by	uniform
sqrt	call	reduce_sum
name_scope	has_arg0	filter_mask
conv2d	call	get_variable
Linear	call	reshape
transpose	has_name	NHWC_to_NCHW
variable_scope	followed_by	get_variable
Conv2D	call	param
uniform	followed_by	param
sqrt	followed_by	sample
ones	has_dtype	float32
param	followed_by	zeros
mnist.gen.gan_def.discriminator_wgangp	call	Linear
Linear	call	name_scope
zeros	has_dtype	float32
param	followed_by	sqrt
sqrt	followed_by	name_scope
variable_scope	followed_by	NHWC_to_NCHW
sqrt	call	square
name_scope	followed_by	sqrt
zeros	followed_by	bias_add
conv2d	call	conv2d
Conv2D	call	zeros
reshape	call	bias_add
Conv2D	call	conv2d
get_variable	has_arg0	w
Conv2D	call	sqrt
uniform	followed_by	uniform
uniform	followed_by	sqrt
mnist.gen.gan_def.discriminator_wgangp	call	NHWC_to_NCHW
Conv2D	call	uniform
Conv2D	call	name_scope
ones	followed_by	sqrt
LeakyReLU	call	maximum
Linear	call	sqrt
Linear	call	sample
mnist.gen.gan_def.discriminator_wgangp	call	reshape
name_scope	has_arg0	weightnorm
sqrt	followed_by	sqrt
conv2d	followed_by	conv2d
LeakyReLU	followed_by	Conv2D
param	followed_by	name_scope
sample	call	normal
conv2d	call	reshape
get_variable	followed_by	reshape
sample	followed_by	param
svd	followed_by	reshape
Linear	call	uniform
normal	has_arg0	0.0
normal	followed_by	svd
reshape	call	shape
NHWC_to_NCHW	call	transpose
reshape	followed_by	matmul
reshape	followed_by	bias_add
name_scope	followed_by	conv2d
mnist.gen.gan_def.discriminator_wgangp	call	LeakyReLU
project	followed_by	concat
pad	call	pad
tf.RegisterGradient(rnd_name)	call	RegisterGradient
commons.measure.PadRotateProjectWithTheta.measure	call	concat
concat	followed_by	concat
reshape	followed_by	concat
rotate	call	tf_image_rotate
name_scope	has_arg0	image_rotate
pad	has_arg0	CONSTANT
commons.measure.PadRotateProjectWithTheta.measure	call	pad
concat	has_arg0	1
reduce_sum	followed_by	reshape
commons.measure.PadRotateProjectWithTheta.measure	call	project
tf.RegisterGradient(rnd_name)	followed_by	get_default_graph
project	call	reshape
pad	call	get_padding_prp
pad	followed_by	range
reduce_sum	has_axis	2
get_default_graph	followed_by	py_func
rotate	call	reshape
tf_image_rotate	call	name_scope
commons.measure.PadRotateProjectWithTheta.measure	call	range
tf_image_rotate	call	py_func
py_func	call	py_func
tf_image_rotate	followed_by	reshape
project	call	reduce_sum
concat	call	concat
get_padding_prp	followed_by	pad
range	followed_by	rotate
rotate	followed_by	project
concat	call	reshape
name_scope	followed_by	py_func
py_func	call	get_default_graph
commons.measure.PadRotateProjectWithTheta.measure	call	rotate
py_func	call	tf.RegisterGradient(rnd_name)
get_variable	followed_by	get_variable
get_variable	has_arg0	bias
mnist.gen.gan_def.discriminator_fc_cond	call	variable_scope
lrelu	followed_by	concat
linear	call	variable_scope
get_variable	followed_by	matmul
linear	call	get_variable
get_variable	has_arg0	Matrix
variable_scope	followed_by	get_variable
variable_scope	followed_by	concat
batch_norm.__init__	followed_by	linear
concat	followed_by	batch_norm.__init__
mnist.gen.gan_def.discriminator_fc_cond	call	batch_norm.__init__
mnist.gen.gan_def.discriminator_fc_cond	call	concat
matmul	followed_by	matmul
concat	has_arg0	1
mnist.gen.gan_def.discriminator_fc_cond	call	lrelu
batch_norm.__init__	call	variable_scope
lrelu	call	maximum
mnist.gen.gan_def.discriminator_fc_cond	call	linear
concat	followed_by	linear
linear	followed_by	lrelu
linear	call	matmul
maximum	call	cast
get_trainable_vars	call	get_collection
get_trainable_vars	followed_by	placeholder
get_optimizer	call	AdamOptimizer
commons.utils.get_train_ops	call	get_trainable_vars
get_optimizer	call	RMSPropOptimizer
get_optimizer	call	GradientDescentOptimizer
commons.utils.get_train_ops	call	placeholder
get_optimizer	followed_by	get_optimizer
GradientDescentOptimizer	followed_by	MomentumOptimizer
AdamOptimizer	has_beta2	hparams.opt_param2
commons.utils.get_train_ops	call	maximum
placeholder	followed_by	maximum
RMSPropOptimizer	has_decay	hparams.opt_param1
get_trainable_vars	followed_by	get_trainable_vars
MomentumOptimizer	followed_by	RMSPropOptimizer
commons.utils.get_train_ops	call	get_optimizer
get_optimizer	call	MomentumOptimizer
maximum	followed_by	get_optimizer
get_optimizer	call	AdagradOptimizer
AdamOptimizer	followed_by	AdagradOptimizer
RMSPropOptimizer	followed_by	AdamOptimizer
maximum	has_arg0	0.0
amb_measure.DropDevice.unmeasure_np	call	unmeasure_func
unmeasure_func	call	zeros_like
get_gaussian_filter	call	exp
unmeasure_func	call	range
range	followed_by	unmeasure_func
amb_measure.DropDevice.unmeasure_np	call	range
amb_measure.DropDevice.unmeasure_np	call	get_gaussian_filter
amb_measure.DropDevice.unmeasure_np	call	zeros_like
get_gaussian_filter	followed_by	zeros_like
zeros_like	followed_by	range
matmul	followed_by	matmul
conv_cond_concat	followed_by	batch_norm.__init__
lrelu	followed_by	reshape
conv_cond_concat	call	concat
mnist.gen.gan_def.discriminator_dcgan	call	linear
lrelu	followed_by	conv2d
get_variable	followed_by	matmul
mnist.gen.gan_def.discriminator_dcgan	call	concat
reshape	call	bias_add
concat	followed_by	linear
mnist.gen.gan_def.discriminator_dcgan	call	batch_norm.__init__
conv2d	followed_by	lrelu
lrelu	followed_by	concat
batch_norm.__init__	call	variable_scope
batch_norm.__init__	followed_by	conv2d
variable_scope	followed_by	reshape
conv2d	followed_by	conv2d
get_variable	has_arg0	bias
get_variable	has_arg0	w
lrelu	call	maximum
conv2d	call	reshape
conv2d	call	conv2d
conv_cond_concat	followed_by	lrelu
variable_scope	followed_by	get_variable
conv2d	followed_by	get_variable
conv2d	followed_by	conv_cond_concat
get_variable	followed_by	get_variable
concat	has_arg0	3
batch_norm.__init__	followed_by	linear
get_variable	has_arg0	biases
concat	followed_by	batch_norm.__init__
get_variable	followed_by	reshape
linear	followed_by	lrelu
get_variable	followed_by	conv2d
mnist.gen.gan_def.discriminator_dcgan	call	lrelu
concat	has_arg0	1
mnist.gen.gan_def.discriminator_dcgan	call	reshape
linear	call	get_variable
linear	call	variable_scope
linear	call	matmul
mnist.gen.gan_def.discriminator_dcgan	call	conv2d
reshape	followed_by	conv_cond_concat
get_variable	has_arg0	Matrix
reshape	followed_by	concat
mnist.gen.gan_def.discriminator_dcgan	call	variable_scope
conv2d	call	get_variable
mnist.gen.gan_def.discriminator_dcgan	call	conv_cond_concat
conv2d	call	variable_scope
concat	call	ones
get_image	call	transform
round	followed_by	round
transform	call	center_crop
center_crop	call	round
celebA.gen.utils.RealValIterator.next	call	get_image
get_image	call	imread
imread	followed_by	transform
amb_measure.DropMaskType1.sample_theta	call	uniform
amb_measure.DropMaskType1.sample_theta	call	ones
amb_measure.DropMaskType1.sample_theta	call	get_noise_shape
uniform	followed_by	uniform
uniform	followed_by	ones
get_noise_shape	followed_by	uniform
ones	has_shape	self.batch_dims
blur	call	get_gaussian_filter
variable_scope	followed_by	get_variable
blur	call	reshape
conv2d	followed_by	concat
get_variable	has_arg0	w
get_variable	followed_by	conv2d
conv2d	call	variable_scope
conv2d	call	get_variable
reshape	followed_by	range
range	followed_by	conv2d
blur	call	conv2d
conv2d	call	reshape
get_gaussian_filter	call	exp
blur	call	range
reshape	call	bias_add
get_gaussian_filter	followed_by	reshape
conv2d	followed_by	conv2d
blur	followed_by	add
concat	has_axis	3
conv2d	call	conv2d
amb_measure.BlurAddNoise.measure	call	add
conv2d	followed_by	get_variable
blur	call	concat
amb_measure.BlurAddNoise.measure	call	blur
add	has_name	x_measured
get_variable	has_arg0	biases
get_variable	followed_by	reshape
blur_np	call	reshape
get_gaussian_filter	call	exp
get_gaussian_filter	followed_by	reshape
reshape	followed_by	constant
amb_measure.BlurAddNoise.measure_np	call	blur_np
blur_np	call	constant
blur_np	call	get_gaussian_filter
get_variable	followed_by	matmul
mnist.gen.gan_def.discriminator_fc	call	linear
batch_norm.__init__	call	variable_scope
mnist.gen.gan_def.discriminator_fc	call	lrelu
matmul	followed_by	matmul
get_variable	has_arg0	bias
get_variable	has_arg0	Matrix
mnist.gen.gan_def.discriminator_fc	call	variable_scope
batch_norm.__init__	followed_by	linear
linear	followed_by	lrelu
linear	call	variable_scope
linear	call	get_variable
mnist.gen.gan_def.discriminator_fc	call	batch_norm.__init__
linear	call	matmul
variable_scope	followed_by	get_variable
variable_scope	followed_by	batch_norm.__init__
lrelu	followed_by	linear
lrelu	call	maximum
get_variable	followed_by	get_variable
lrelu	followed_by	batch_norm.__init__
mnist.gen.gan_def.generator_wgangp	call	NCHW_to_NHWC
Linear	call	uniform
conv2d_transpose	followed_by	param
reshape	followed_by	Deconv2D
sqrt	followed_by	sample
expand_dims	followed_by	transpose
sqrt	followed_by	sqrt
transpose	followed_by	shape
reshape	followed_by	bias_add
Deconv2D	call	zeros
relu	followed_by	Deconv2D
normal	has_arg0	0.0
Deconv2D	call	sqrt
param	followed_by	sqrt
bias_add	followed_by	transpose
matmul	followed_by	reshape
NCHW_to_NHWC	followed_by	reshape
Deconv2D	call	shape
zeros	has_arg0	(output_dim,)
Linear	call	bias_add
param	call	Variable
Deconv2D	call	param
conv2d_transpose	has_padding	SAME
shape	followed_by	stack
Deconv2D	call	expand_dims
Linear	call	name_scope
reshape	call	shape
relu	followed_by	reshape
reshape	followed_by	matmul
Deconv2D	followed_by	NCHW_to_NHWC
sample	call	normal
mnist.gen.gan_def.generator_wgangp	call	reshape
name_scope	followed_by	uniform
Linear	call	sqrt
Deconv2D	call	transpose
sqrt	call	square
Linear	call	sample
uniform	followed_by	sqrt
name_scope	has_arg0	weightnorm
Deconv2D	call	name_scope
bias_add	call	zeros
zeros	followed_by	bias_add
Linear	followed_by	relu
mnist.gen.gan_def.generator_wgangp	call	Deconv2D
normal	has_arg1	1.0
Linear	call	reshape
zeros	has_dtype	float32
param	followed_by	zeros
Deconv2D	call	uniform
sqrt	followed_by	uniform
mnist.gen.gan_def.generator_wgangp	call	variable_scope
sqrt	call	reduce_sum
Deconv2D	call	conv2d_transpose
sqrt	followed_by	matmul
NCHW_to_NHWC	call	transpose
mnist.gen.gan_def.generator_wgangp	call	Linear
transpose	has_name	NCHW_to_NHWC
uniform	followed_by	param
sample	followed_by	param
expand_dims	has_arg0	1
Linear	call	param
sqrt	followed_by	param
sample	call	svd
Deconv2D	call	bias_add
mnist.gen.gan_def.generator_wgangp	call	relu
stack	followed_by	conv2d_transpose
Deconv2D	call	stack
name_scope	followed_by	sqrt
reduce_sum	call	square
sqrt	followed_by	expand_dims
variable_scope	followed_by	Linear
sample	call	reshape
svd	followed_by	reshape
uniform	followed_by	uniform
normal	followed_by	svd
transpose	has_name	NHWC_to_NCHW
Deconv2D	followed_by	relu
Linear	call	matmul
param	followed_by	name_scope
patch_mask	call	range
commons.measure.KeepPatch.sample_theta	call	patch_mask
patch_mask	call	ones
ones	followed_by	range
reduce_mean	call	sigmoid_cross_entropy_with_logits
setup_vals	call	get_expt_dir
sample_z_val	followed_by	range
sigmoid_cross_entropy_with_logits	call	ones_like
ExtractPatch.__init__	call	__init__
placeholder	followed_by	placeholder
get_inception_data	call	get_inception_score
train	call	Session
main	call	train
get_loss	call	loss_auxcond
train	call	save_samples
main	call	setup_vals
get_ckpt_path	call	get_checkpoint_state
save_images	followed_by	minimum
loss_gradient_penalty	call	range
random_uniform	followed_by	gradients
sample_y_val	call	tile
loss_wasserstein	call	reduce_mean
main	call	RealValIterator.__init__
sample_cond	call	sample_z_val
main	call	get_phs_cond
log	followed_by	mean
model_fn_cond	followed_by	train
get_phs_uncond	followed_by	model_fn_uncond
Saver	followed_by	run
train	call	run
BlurAddNoise.__init__	call	__init__
get_hparams	call	uniform
loss_gradient_penalty	followed_by	loss_auxcond
range	followed_by	run
sample_cond	call	run
model_fn_cond	call	get_loss
save_inception_data	call	get_samples
run	followed_by	range
get_mode_dir	followed_by	get_model_dir
get_expt_dir	call	get_task_dir
uniform	has_arg0	1
sample_z_val	followed_by	run
run	followed_by	get_samples
loss_gradient_penalty	followed_by	reduce_mean
uniform	has_size	(hparams.batch_size, hparams.z_dim)
train	call	save_inception_data
range	followed_by	random_uniform
merge	call	zeros
zeros	followed_by	zeros
range	followed_by	sqrt
model_fn_uncond	followed_by	train
random_uniform	has_maxval	1.0
uniform	followed_by	Adam
main	call	get_phs_uncond
loss_gradient_penalty	call	sqrt
Session	followed_by	scalar
sample_cond	followed_by	sample_z_val
save_inception_data	call	get_inception_data
mean	followed_by	exp
loss_gradient_penalty	call	random_uniform
loss_gradient_penalty	call	reduce_mean
get_samples	call	sample_cond
.main	call	get_hparams
min	followed_by	sample_z_val
train	call	try_restore
get_samples	call	run
get_inception_data	call	mean
get_samples	followed_by	get_inception_data
set_up_dir	followed_by	set_up_dir
get_lossy	followed_by	get_loss
sample_cond	call	range
get_model_dir	followed_by	get_opt_dir
Saver	has_max_to_keep	hparams.max_checkpoints
get_loss	call	reduce_mean
get_hparams	followed_by	main
get_loss	call	loss_gradient_penalty
loss_gradient_penalty	call	gradients
get_expt_dir	call	get_mode_dir
get_mdevice	call	BlurAddNoise.__init__
zeros	has_arg0	(hparams.batch_size, hparams.y_dim)
sqrt	followed_by	save_images
RealValIterator.__init__	followed_by	RealValIterator.__init__
scalar	has_arg0	g_loss
setup_dirs	call	set_up_dir
placeholder	has_name	y_ph
minimum	call	maximum
save_inception_data	call	range
main	call	save_hparams
save_images	call	merge
get_samples	call	sample_z_val
get_loss	call	loss_wasserstein
placeholder	has_name	x_ph
get_phs_uncond	call	placeholder
run	followed_by	run
save_samples	call	minimum
placeholder	has_name	z_ph
get_mdevice	call	ExtractPatch.__init__
sample_z_val	call	uniform
sqrt	call	reduce_sum
get_inception_score	call	mean
train	call	FileWriter
range	followed_by	sample_z_val
zeros	followed_by	min
save_samples	call	sqrt
zeros	has_arg0	(h * size[0], w * size[1], 3)
mean	followed_by	log
ExtractPatch.__init__	followed_by	BlurAddNoise.__init__
scalar	has_arg0	d_loss
sigmoid_cross_entropy_with_logits	call	zeros_like
model_fn_cond	call	get_lossy
save_images	followed_by	save_images
sqrt	followed_by	reduce_mean
main	call	print_hparams
get_task_dir	followed_by	get_mode_dir
get_inception_score	call	exp
main	call	model_fn_uncond
loss_auxcond	call	reduce_mean
train	call	sample_z_val
train	call	get_samples
get_phs_cond	followed_by	model_fn_cond
loss_wasserstein	followed_by	loss_gradient_penalty
get_samples	call	sample_y_val
setup_vals	followed_by	setup_dirs
get_phs_cond	call	placeholder
loss_wasserstein	followed_by	loss_wasserstein
main	call	setup_dirs
reduce_mean	followed_by	loss_gradient_penalty
range	followed_by	get_samples
minimum	followed_by	save_images
reduce_mean	followed_by	reduce_mean
save_inception_data	followed_by	get_samples
get_inception_score	followed_by	mean
model_fn_uncond	call	get_loss
range	has_arg0	1
get_mdevice	followed_by	RealValIterator.__init__
tile	followed_by	zeros
train	followed_by	get_phs_cond
mean	has_axis	0
sample_y_val	followed_by	sample_cond
sample_cond	call	ceil
run	followed_by	try_restore
merge	followed_by	FileWriter
get_loss	call	loss_vanilla
reduce_sum	call	square
train	call	merge
try_restore	followed_by	range
range	followed_by	zeros
model_fn_uncond	call	get_lossy
sample_cond	call	zeros
ceil	followed_by	tile
main	call	model_fn_cond
try_restore	call	get_ckpt_path
train	call	range
print_hparams	followed_by	save_hparams
loss_vanilla	call	reduce_mean
save_samples	call	save_images
main	call	get_mdevice
scalar	followed_by	merge
get_expt_dir	call	get_opt_dir
train	call	Saver
RealValIterator.__init__	followed_by	get_phs_uncond
get_hparams	call	Adam
sample_y_val	call	ceil
sample_cond	call	min
gradients	followed_by	range
scalar	followed_by	scalar
zeros	has_arg0	(num_samples, hparams.y_dim)
save_samples	followed_by	save_inception_data
train	call	scalar
ceil	followed_by	range
get_expt_dir	call	get_model_dir
get_inception_score	call	log
sample_y_val	call	zeros
get_samples	followed_by	save_samples
range	has_arg0	16
loss_vanilla	followed_by	loss_wasserstein
FileWriter	followed_by	Saver
setup_dirs	followed_by	print_hparams
log	followed_by	log
save_hparams	followed_by	get_mdevice
.main	call	main
split	has_arg0	/
celebA.gen.wgan_utils.maybe_download_and_extract	call	split
batch_norm	call	moments
ExponentialMovingAverage	followed_by	cond
batch_norm	call	cond
get_variable	followed_by	get_variable
moments	has_name	moments
batch_norm	call	get_variable
get_variable	followed_by	moments
batch_norm	call	batch_normalization
cond	followed_by	batch_normalization
commons.ops.batch_norm.__call__	call	batch_norm
batch_norm	call	ExponentialMovingAverage
batch_norm	call	variable_scope
moments	followed_by	ExponentialMovingAverage
variable_scope	followed_by	get_variable
Variable	followed_by	get_variable
celebA.gen.wgan_utils.weight_variable_xavier_initialized	call	weight_variable
weight_variable	call	Variable
truncated_normal	followed_by	Variable
celebA.gen.wgan_utils.weight_variable_xavier_initialized	call	sqrt
sqrt	followed_by	weight_variable
weight_variable	call	get_variable
weight_variable	call	truncated_normal
create_scripts	call	get_filename
get_filename	call	get_short_name
get_useful_lines	followed_by	split
create_scripts	call	write_script
parse_grid_spec	call	split
get_filename	followed_by	write_script
parse_grid_spec	call	get_useful_lines
get_script_text	call	find_overlap_idx
create_scripts	call	get_script_text
main	call	create_scripts
main	call	parse_grid_spec
get_short_name	call	split
split	has_arg0	-
.create_scripts	call	main
parse_grid_spec	followed_by	create_scripts
get_script_text	followed_by	get_filename
conv2d_transpose	followed_by	get_variable
reshape	followed_by	conv_cond_concat
mnist.gen.gan_def.generator_dcgan	call	concat
relu	followed_by	conv_cond_concat
batch_norm.__init__	followed_by	deconv2d
deconv2d	call	variable_scope
conv_cond_concat	call	concat
deconv2d	call	reshape
reshape	call	bias_add
deconv2d	followed_by	relu
mnist.gen.gan_def.generator_dcgan	call	deconv2d
get_variable	followed_by	reshape
mnist.gen.gan_def.generator_dcgan	call	reshape
conv_cond_concat	followed_by	batch_norm.__init__
concat	followed_by	batch_norm.__init__
linear	followed_by	relu
concat	has_arg0	3
deconv2d	call	conv2d_transpose
get_variable	has_arg0	w
variable_scope	followed_by	get_variable
mnist.gen.gan_def.generator_dcgan	call	variable_scope
conv_cond_concat	followed_by	deconv2d
get_variable	has_arg0	Matrix
get_variable	followed_by	conv2d_transpose
variable_scope	followed_by	reshape
reshape	followed_by	concat
get_variable	followed_by	get_variable
relu	followed_by	reshape
deconv2d	call	get_variable
get_variable	followed_by	matmul
batch_norm.__init__	followed_by	linear
relu	followed_by	concat
mnist.gen.gan_def.generator_dcgan	call	conv_cond_concat
concat	has_arg0	1
batch_norm.__init__	call	variable_scope
linear	call	variable_scope
linear	call	matmul
linear	call	get_variable
mnist.gen.gan_def.generator_dcgan	call	batch_norm.__init__
mnist.gen.gan_def.generator_dcgan	call	linear
matmul	followed_by	matmul
get_variable	has_arg0	biases
get_variable	has_arg0	bias
concat	call	ones
mnist.gen.gan_def.generator_dcgan	call	relu
constant	has_arg0	0.1
weight_variable	followed_by	bias_variable
InferenceNetwork.__init__	call	infer
InferenceNetwork.__init__	call	Session
matmul	followed_by	softmax
.mnist.inf.test_inf_net	call	main
weight_variable	call	truncated_normal
placeholder	followed_by	dropout
placeholder	followed_by	equal
argmax	has_arg0	1
infer	call	name_scope
reduce_mean	call	cast
main	call	reduce_mean
reduce_mean	followed_by	reshape
bias_variable	followed_by	matmul
relu	call	matmul
InferenceNetwork.__init__	call	global_variables
max_pool_2x2	followed_by	name_scope
bias_variable	followed_by	reshape
name_scope	has_arg0	dropout
main	call	InferenceNetwork.__init__
name_scope	followed_by	reshape
infer	call	reshape
weight_variable	call	get_variable
Session	followed_by	placeholder
main	call	reshape
dropout	followed_by	name_scope
name_scope	has_arg0	fc1
argmax	followed_by	argmax
infer	call	max_pool_2x2
infer	call	bias_variable
infer	call	matmul
global_variables	followed_by	Saver
latest_checkpoint	has_arg0	./src/mnist/inf/ckpt/bs64_lr0.0001/
name_scope	has_arg0	conv1
max_pool	has_padding	SAME
infer	call	softmax
name_scope	followed_by	weight_variable
bias_variable	call	constant
infer	call	placeholder
bias_variable	call	get_variable
inf_restore_vars	followed_by	global_variables
main	call	equal
infer	call	variable_scope
name_scope	has_arg0	fc2
equal	followed_by	reduce_mean
placeholder	followed_by	infer
placeholder	has_name	x_ph
InferenceNetwork.__init__	followed_by	placeholder
Saver	followed_by	latest_checkpoint
name_scope	followed_by	placeholder
infer	call	relu
bias_variable	followed_by	relu
infer	call	dropout
infer	call	weight_variable
equal	call	argmax
name_scope	has_arg0	reshape
variable_scope	followed_by	name_scope
InferenceNetwork.__init__	call	inf_restore_vars
infer	followed_by	inf_restore_vars
name_scope	has_arg0	pool1
InferenceNetwork.__init__	call	placeholder
truncated_normal	followed_by	get_variable
relu	followed_by	name_scope
name_scope	followed_by	max_pool_2x2
reshape	followed_by	name_scope
constant	followed_by	get_variable
reshape	followed_by	relu
truncated_normal	has_stddev	0.1
InferenceNetwork.__init__	call	Saver
InferenceNetwork.__init__	call	latest_checkpoint
relu	call	conv2d
name_scope	has_arg0	conv2
name_scope	has_arg0	pool2
main	call	placeholder
max_pool_2x2	call	max_pool
sqrt	followed_by	uniform
stack	followed_by	conv2d_transpose
param	followed_by	sqrt
mnist.gen.wganlib.deconv2d.Deconv2D	call	bias_add
mnist.gen.wganlib.deconv2d.Deconv2D	call	expand_dims
param	followed_by	name_scope
mnist.gen.wganlib.deconv2d.Deconv2D	call	stack
uniform	followed_by	uniform
conv2d_transpose	has_padding	SAME
expand_dims	followed_by	transpose
zeros	has_dtype	float32
sqrt	followed_by	expand_dims
zeros	followed_by	bias_add
sqrt	call	square
reduce_sum	call	square
mnist.gen.wganlib.deconv2d.Deconv2D	call	transpose
transpose	has_name	NHWC_to_NCHW
mnist.gen.wganlib.deconv2d.Deconv2D	call	sqrt
mnist.gen.wganlib.deconv2d.Deconv2D	call	name_scope
transpose	has_name	NCHW_to_NHWC
bias_add	followed_by	transpose
expand_dims	has_arg0	1
sqrt	followed_by	param
mnist.gen.wganlib.deconv2d.Deconv2D	call	conv2d_transpose
mnist.gen.wganlib.deconv2d.Deconv2D	call	shape
mnist.gen.wganlib.deconv2d.Deconv2D	call	uniform
param	call	Variable
shape	followed_by	stack
transpose	followed_by	shape
conv2d_transpose	followed_by	param
name_scope	has_arg0	weightnorm
param	followed_by	zeros
sqrt	followed_by	sqrt
mnist.gen.wganlib.deconv2d.Deconv2D	call	zeros
sqrt	call	reduce_sum
mnist.gen.wganlib.deconv2d.Deconv2D	call	param
name_scope	followed_by	sqrt
uniform	followed_by	param
commons.measure.DropDevice.unmeasure_np	call	zeros_like
commons.measure.DropDevice.unmeasure_np	call	range
commons.measure.DropDevice.unmeasure_np	call	get_blur_func
get_inpaint_func_tv	followed_by	get_blur_func
get_blur_func	followed_by	zeros_like
get_inpaint_func_opencv	followed_by	get_inpaint_func_opencv
zeros_like	followed_by	range
get_inpaint_func_opencv	followed_by	get_inpaint_func_tv
commons.measure.DropDevice.unmeasure_np	call	get_inpaint_func_tv
commons.measure.DropDevice.unmeasure_np	call	get_inpaint_func_opencv
main	call	get_metrics
main	call	save_to_pickle
get_df	followed_by	save_to_pickle
load_if_pickled	call	load
get_pkl_filepaths	followed_by	read_hparams
main	call	get_df
.aggregator_cifar	call	main
read_hparams	followed_by	get_metrics
main	call	get_pkl_filepaths
main	call	read_hparams
get_metrics	call	load_if_pickled
get_metrics	followed_by	get_df
read_hparams	call	load
conj	followed_by	zeros_like
real	followed_by	minimum
minimum	call	maximum
get_gaussian_filter	call	exp
range	followed_by	range
wiener_deconv	call	zeros_like
wiener_deconv	call	real
wiener_deconv	call	minimum
range	followed_by	real
commons.measure.BlurAddNoise.unmeasure_np	call	wiener_deconv
get_gaussian_filter	followed_by	conj
zeros_like	followed_by	range
wiener_deconv	call	get_gaussian_filter
wiener_deconv	call	range
wiener_deconv	call	conj
pad	followed_by	range
name_scope	has_arg0	image_rotate
commons.measure.PadRotateProject.measure	call	rotate
py_func	call	tf.RegisterGradient(rnd_name)
tf_image_rotate	followed_by	reshape
commons.measure.PadRotateProject.measure	call	project
concat	has_name	x_measured
name_scope	followed_by	py_func
tf_image_rotate	call	py_func
tf.RegisterGradient(rnd_name)	call	RegisterGradient
pad	has_arg0	CONSTANT
tf_image_rotate	call	name_scope
tf.RegisterGradient(rnd_name)	followed_by	get_default_graph
get_padding_prp	followed_by	pad
py_func	call	py_func
rotate	call	tf_image_rotate
project	call	reshape
commons.measure.PadRotateProject.measure	call	concat
commons.measure.PadRotateProject.measure	call	pad
project	followed_by	concat
py_func	call	get_default_graph
pad	call	get_padding_prp
commons.measure.PadRotateProject.measure	call	range
rotate	call	reshape
get_default_graph	followed_by	py_func
project	call	reduce_sum
reduce_sum	followed_by	reshape
rotate	followed_by	project
pad	call	pad
range	followed_by	rotate
reduce_sum	has_axis	2
blur_np	call	constant
get_gaussian_filter	call	exp
blur_np	call	get_gaussian_filter
commons.measure.BlurAddNoise.measure_np	call	blur_np
reshape	followed_by	constant
get_gaussian_filter	followed_by	reshape
blur_np	call	reshape
name_scope	followed_by	max_pool_2x2
truncated_normal	followed_by	get_variable
weight_variable	followed_by	bias_variable
equal	followed_by	reduce_mean
main	call	try_restore
infer	call	relu
infer	call	dropout
main	call	Session
reduce_mean	followed_by	Session
range	followed_by	run
name_scope	has_arg0	conv1
max_pool_2x2	followed_by	name_scope
constant	has_arg0	0.1
infer	call	name_scope
main	call	reduce_mean
main	call	placeholder
infer	call	variable_scope
try_restore	followed_by	get_trainable_vars
name_scope	followed_by	weight_variable
name_scope	has_arg0	pool2
bias_variable	followed_by	relu
relu	call	conv2d
bias_variable	call	constant
equal	call	argmax
constant	followed_by	get_variable
relu	followed_by	name_scope
name_scope	followed_by	reshape
infer	call	placeholder
placeholder	followed_by	placeholder
argmax	has_arg0	1
reduce_mean	call	softmax_cross_entropy_with_logits
reshape	followed_by	name_scope
name_scope	has_arg0	conv2
bias_variable	call	get_variable
run	followed_by	try_restore
infer	call	matmul
placeholder	followed_by	infer
name_scope	has_arg0	dropout
name_scope	followed_by	placeholder
run	followed_by	run
bias_variable	followed_by	matmul
Saver	has_max_to_keep	hparams.max_checkpoints
infer	call	weight_variable
infer	call	softmax
name_scope	has_arg0	pool1
name_scope	has_arg0	fc2
main	call	get_trainable_vars
relu	call	matmul
max_pool_2x2	call	max_pool
get_trainable_vars	followed_by	range
truncated_normal	has_stddev	0.1
main	call	run
Session	followed_by	Saver
main	call	get_hparams
name_scope	has_arg0	fc1
try_restore	call	get_ckpt_path
.mnist.inf.train	call	main
placeholder	followed_by	dropout
main	call	Saver
infer	followed_by	reduce_mean
main	call	infer
Saver	followed_by	run
infer	call	max_pool_2x2
get_ckpt_path	call	get_checkpoint_state
name_scope	has_arg0	reshape
reduce_mean	call	cast
variable_scope	followed_by	name_scope
weight_variable	call	truncated_normal
argmax	followed_by	argmax
get_hparams	followed_by	placeholder
max_pool	has_padding	SAME
reshape	followed_by	relu
dropout	followed_by	name_scope
infer	call	reshape
get_trainable_vars	call	get_collection
main	call	equal
reduce_mean	followed_by	equal
weight_variable	call	get_variable
matmul	followed_by	softmax
main	call	range
bias_variable	followed_by	reshape
infer	call	bias_variable
sample_theta	call	uniform
get_noise_shape	followed_by	uniform
commons.measure.DropRowCol.sample_theta	call	sample_theta
sample_theta	call	ones
sample_theta	call	get_noise_shape
sample_theta	followed_by	sample_theta
uniform	followed_by	ones
uniform	followed_by	uniform
ones	has_shape	self.batch_dims
ones	followed_by	range
patch_mask	call	range
patch_mask	call	ones
commons.measure.DropPatch.sample_theta	call	patch_mask
blur	call	concat
get_variable	followed_by	reshape
commons.measure.BlurAddNoise.measure	call	add
get_variable	followed_by	conv2d
range	followed_by	conv2d
concat	has_axis	3
variable_scope	followed_by	get_variable
add	has_name	x_measured
blur	call	range
conv2d	followed_by	concat
conv2d	followed_by	conv2d
commons.measure.BlurAddNoise.measure	call	blur
blur	call	get_gaussian_filter
get_gaussian_filter	call	exp
blur	call	reshape
reshape	followed_by	range
get_variable	has_arg0	w
conv2d	call	get_variable
conv2d	call	reshape
conv2d	call	conv2d
get_gaussian_filter	followed_by	reshape
conv2d	followed_by	get_variable
blur	call	conv2d
conv2d	call	variable_scope
blur	followed_by	add
get_variable	has_arg0	biases
reshape	call	bias_add
sqrt	call	reduce_sum
loss_gradient_penalty	call	gradients
loss_wasserstein	call	reduce_mean
get_loss	call	loss_wasserstein
loss_gradient_penalty	call	sqrt
get_loss	call	loss_vanilla
reduce_mean	followed_by	loss_gradient_penalty
get_loss	call	loss_auxcond
loss_auxcond	call	reduce_mean
commons.arch.model_fn_auxcond	call	get_lossy
sqrt	followed_by	reduce_mean
loss_gradient_penalty	followed_by	loss_auxcond
loss_wasserstein	followed_by	loss_wasserstein
range	followed_by	sqrt
range	followed_by	random_uniform
reduce_mean	followed_by	reduce_mean
loss_gradient_penalty	call	reduce_mean
loss_vanilla	call	reduce_mean
sigmoid_cross_entropy_with_logits	call	zeros_like
get_loss	call	reduce_mean
sigmoid_cross_entropy_with_logits	call	ones_like
loss_wasserstein	followed_by	loss_gradient_penalty
random_uniform	has_maxval	1.0
get_lossy	followed_by	get_loss
loss_vanilla	followed_by	loss_wasserstein
reduce_mean	call	sigmoid_cross_entropy_with_logits
loss_gradient_penalty	call	range
loss_gradient_penalty	followed_by	reduce_mean
commons.arch.model_fn_auxcond	call	get_loss
random_uniform	followed_by	gradients
range	has_arg0	1
gradients	followed_by	range
loss_gradient_penalty	call	random_uniform
reduce_sum	call	square
get_loss	call	loss_gradient_penalty
commons.measure.PadRotateProjectDevice.__init__	call	__init__
expand_dims	followed_by	bias_add
name_scope	has_arg0	filter_mask
ones	has_arg0	(filter_size, input_dim, output_dim)
name_scope	followed_by	sqrt
tflib.ops.conv1d.Conv1D	call	bias_add
conv1d	followed_by	param
param	call	Variable
tflib.ops.conv1d.Conv1D	call	uniform
tflib.ops.conv1d.Conv1D	call	conv1d
conv1d	has_data_format	NCHW
tflib.ops.conv1d.Conv1D	call	sqrt
param	followed_by	zeros
bias_add	has_data_format	NCHW
bias_add	followed_by	squeeze
uniform	followed_by	param
tflib.ops.conv1d.Conv1D	call	squeeze
name_scope	has_arg0	weightnorm
sqrt	followed_by	sqrt
sqrt	followed_by	uniform
param	followed_by	sqrt
param	followed_by	name_scope
zeros	followed_by	expand_dims
ones	followed_by	sqrt
tflib.ops.conv1d.Conv1D	call	expand_dims
sqrt	followed_by	name_scope
expand_dims	has_arg0	3
zeros	has_dtype	float32
sqrt	call	square
tflib.ops.conv1d.Conv1D	call	param
sqrt	call	reduce_sum
tflib.ops.conv1d.Conv1D	call	ones
ones	has_dtype	float32
tflib.ops.conv1d.Conv1D	call	name_scope
name_scope	followed_by	conv1d
sqrt	followed_by	param
tflib.ops.conv1d.Conv1D	call	zeros
reduce_sum	call	square
name_scope	followed_by	ones
amb_measure.DropDevice.__init__	call	__init__
get_ckpt_path	call	get_checkpoint_state
commons.basic_utils.try_restore	call	get_ckpt_path
conv2d	call	conv2d
conv2d	followed_by	get_variable
reshape	call	bias_add
conv2d	call	variable_scope
get_variable	followed_by	conv2d
get_variable	has_arg0	biases
conv2d	call	get_variable
get_variable	has_arg0	w
variable_scope	followed_by	get_variable
conv2d	followed_by	conv2d
conv2d	followed_by	bias_add
get_variable	followed_by	reshape
celebA.gen.wgan_utils.conv2d_basic	call	conv2d
conv2d	call	reshape
celebA.gen.wgan_utils.conv2d_basic	call	bias_add
.aggregator_mnist	call	main
main	call	get_df
load_if_pickled	call	load
get_metrics	call	load_if_pickled
get_df	followed_by	save_to_pickle
main	call	read_hparams
read_hparams	call	load
get_pkl_filepaths	followed_by	read_hparams
main	call	get_metrics
get_df	call	get_all_values
read_hparams	followed_by	get_metrics
main	call	save_to_pickle
main	call	get_pkl_filepaths
get_metrics	followed_by	get_df
mnist.inf.utils.setup	call	set_up_dir
get_expt_dir	followed_by	set_up_dir
mnist.inf.utils.setup	call	get_expt_dir
.tflib.small_imagenet	call	load
make_generator	followed_by	make_generator
load	call	make_generator
wiener_deconv	call	zeros_like
wiener_deconv	call	real
amb_measure.BlurAddNoise.unmeasure_np	call	wiener_deconv
wiener_deconv	call	range
range	followed_by	range
minimum	call	maximum
zeros_like	followed_by	range
wiener_deconv	call	get_gaussian_filter
range	followed_by	real
wiener_deconv	call	minimum
get_gaussian_filter	call	exp
conj	followed_by	zeros_like
real	followed_by	minimum
wiener_deconv	call	conj
get_gaussian_filter	followed_by	conj
reshape	followed_by	concat
commons.measure.ExtractPatch.measure	call	concat
pad	has_arg0	CONSTANT
get_padding_ep	followed_by	pad
commons.measure.ExtractPatch.measure	call	range
concat	has_axis	0
pad	has_name	x_measured
commons.measure.ExtractPatch.measure	call	get_padding_ep
concat	followed_by	get_padding_ep
range	followed_by	reshape
commons.measure.ExtractPatch.measure	call	pad
commons.measure.ExtractPatch.measure	call	reshape
