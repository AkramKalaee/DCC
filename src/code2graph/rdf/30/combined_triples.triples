phi	call	reduce_sum
log_prior	call	reduce_sum
Model.__init__	call	get_klqp_loss
log_likelihood_factor	followed_by	log_prior
optimize_adam	call	AdamOptimizer
reduce_mean	followed_by	sqrt
train	call	run_single_step
log_likelihood_factor	call	log
reduce_sum	call	reshape
exp	followed_by	sign
get_klqp_loss	call	stop_gradient
get_variable	has_dtype	tf.float32
log_prob	call	log
get_klqp_loss	followed_by	scalar
get_error_and_ll	call	reduce_mean
phi	call	cast
stop_gradient	followed_by	log
get_variable	has_arg0	log_variance
reduce_mean	call	reduce_mean
Trainer.__init__	call	FileWriter
log_likelihood_factor	call	predict
get_error_and_ll	call	exp
scalar	followed_by	scalar
main	call	ConfigProto
reduce_logsumexp	call	log
Trainer.__init__	call	optimize_adam
run_single_step	followed_by	log_step_message
predict	call	matmul
exponential_decay	has_name	decaying_learning_rate
stop_gradient	followed_by	reduce_sum
get_klqp_loss	call	log_likelihood_factor
Variable	has_arg0	0
Model.__init__	call	get_error_and_ll
mean	followed_by	mean
get_parameters_q	call	exp
reduce_logsumexp	has_axis	1
Model.__init__	call	proposal_q.__init__
scalar	has_arg0	kl_loss
get_error_and_ll	call	draw_samples
exp	followed_by	reduce_sum
Trainer.__init__	call	Saver
mean	followed_by	squeeze
get_klqp_loss	call	log_prob
get_klqp_loss	call	log_prior
main	call	Trainer.__init__
stop_gradient	followed_by	stop_gradient
sign	followed_by	cast
greater	has_arg0	0.5
log_prob	call	stop_gradient
Trainer.__init__	call	merge_all
draw_samples	followed_by	log_likelihood_factor
log_prob	call	reduce_sum
predict	call	relu
get_error_and_ll	call	predict
log_step_message	followed_by	get_error_and_ll
get_klqp_loss	call	phi
phi	call	sign
Trainer.__init__	call	Variable
reshape	followed_by	reshape
load_uci_dataset	followed_by	Trainer.__init__
phi	call	reduce_max
draw_samples	followed_by	predict
matmul	followed_by	relu
run_single_step	call	get_feed_dict
Trainer.__init__	call	exponential_decay
Trainer.__init__	call	latest_checkpoint
get_variable	followed_by	get_parameters_q
proposal_q.__init__	call	variable_scope
Trainer.__init__	call	Model.__init__
proposal_q.__init__	followed_by	get_klqp_loss
sqrt	call	reduce_mean
log	followed_by	expand_dims
Saver	followed_by	FileWriter
train	call	log_step_message
expand_dims	followed_by	reduce_mean
main	call	Session
exp	followed_by	draw_samples
get_error_and_ll	followed_by	scalar
main	call	load_uci_dataset
main	call	train
ConfigProto	followed_by	Session
get_variable	followed_by	get_variable
get_error_and_ll	followed_by	get_feed_dict
reshape	has_arg0	(-1, nh)
main	call	device
reduce_mean	has_axis	0
get_klqp_loss	call	exp
train	call	get_feed_dict
reshape	call	reduce_sum
variable_scope	followed_by	get_variable
random_normal	followed_by	sqrt
Session	followed_by	device
phi	call	exp
reduce_sum	followed_by	reduce_max
train	call	shuffle
reshape	has_arg0	(1, -1)
reshape	has_arg0	(-1, k)
reduce_sum	has_axis	1
scalar	has_arg0	batch_rmse
draw_samples	call	random_normal
reshape	followed_by	matmul
reduce_mean	call	reduce_logsumexp
load_uci_dataset	call	squeeze
device	followed_by	load_uci_dataset
merge_all	followed_by	Saver
expand_dims	followed_by	expand_dims
expand_dims	has_arg0	0
Variable	has_name	global_step
shuffle	followed_by	min
expand_dims	has_arg0	1
ConfigProto	call	GPUOptions
get_variable	call	constant
min	followed_by	run_single_step
exponential_decay	followed_by	merge_all
mean	has_arg0	0
scalar	has_arg0	batch_ll
Trainer.__init__	followed_by	train
placeholder	followed_by	placeholder
log_prior	followed_by	log_prob
train	call	get_error_and_ll
optimize_adam	followed_by	latest_checkpoint
log_likelihood_factor	call	expand_dims
sign	call	expand_dims
log_prior	call	log
reshape	has_arg0	(1, k * nh)
phi	followed_by	stop_gradient
load_uci_dataset	call	mean
draw_samples	call	sqrt
FileWriter	followed_by	optimize_adam
cast	call	greater
get_klqp_loss	call	reduce_sum
Variable	followed_by	exponential_decay
predict	followed_by	log
cast	followed_by	reduce_sum
reshape	has_arg0	(k * nh, d)
reduce_mean	has_arg0	1
relu	followed_by	reshape
get_klqp_loss	call	draw_samples
get_error_and_ll	call	log
Model.__init__	followed_by	Variable
scalar	followed_by	get_error_and_ll
predict	call	reshape
.bnn_trainer	call	main
squeeze	followed_by	squeeze
train	call	min
proposal_q.__init__	call	get_parameters_q
log_likelihood_factor	call	reduce_mean
reduce_max	followed_by	exp
get_variable	has_arg0	mean
get_error_and_ll	call	expand_dims
proposal_q.__init__	call	get_variable
log	followed_by	reduce_sum
placeholder	followed_by	proposal_q.__init__
Saver	has_max_to_keep	1
log_prob	followed_by	phi
Model.__init__	call	placeholder
get_error_and_ll	call	sqrt
Model.__init__	call	scalar
get_variable	has_arg0	log_v_noise
variable_scope	has_arg0	p_target
main	call	set_random_seed
main	call	device
main	call	Mixture
run_single_step	followed_by	evaluate_step
evaluate_step	call	sample_step
reduce_sum	has_axis	2
ones	followed_by	GaussianMixture.__init__
variable_scope	followed_by	get_variable
log	followed_by	squeeze
gumbel_softmax_sample	call	sample_gumbel
get_variable	has_arg0	log_var
gumbel_softmax	followed_by	ones
equal	call	reduce_max
Model.__init__	call	scalar
get_variable	followed_by	GaussianMixture.__init__
gumbel_softmax	call	gumbel_softmax_sample
sample	call	sample
sample	followed_by	log_prob
Variable	has_arg0	0
stop_gradient	followed_by	_sum_log_exp
log_prob	call	reduce_sum
log_prob	call	squeeze
device	followed_by	_simulate_mixture_target
expand_dims	has_arg0	1
Trainer.__init__	call	optimize_adagrad
shape	followed_by	cast
random_uniform	followed_by	log
ones	followed_by	reduce_sum
.trainer	call	main
Saver	has_max_to_keep	1
eval_run	call	model_mean_and_variance
log	followed_by	reduce_sum
Model.__init__	call	get_variable
comm_func_eval	call	ex
expand_dims	call	log
expand_dims	call	exp
model_mean_and_variance	call	range
Model.__init__	call	GaussianMixture.__init__
gumbel_softmax	call	stop_gradient
_simulate_mixture_target	call	get_variable
GaussianMixture.__init__	call	exp
range	has_arg0	0
mean	followed_by	mean
GaussianMixture.__init__	call	reduce_sum
sample	call	reduce_sum
mean	has_axis	0
train	call	range
GaussianMixture.__init__	call	log
GaussianMixture.__init__	call	ones
gumbel_softmax_sample	followed_by	shape
log	followed_by	gumbel_softmax
gumbel_softmax	call	cast
Trainer.__init__	call	exponential_decay
ex	call	mean
random_normal	followed_by	sqrt
evaluate_step	followed_by	sample_step
sample	call	dynamic_stitch
eval_run	followed_by	eval_run
train	call	evaluate_step
get_variable	followed_by	get_variable
sample_step	followed_by	eval_run
main	call	ConfigProto
GaussianMixture.__init__	call	Categorical
cast	followed_by	stop_gradient
_sum_log_exp	call	expand_dims
exp	followed_by	softmax
Model.__init__	followed_by	Variable
Variable	has_name	global_step
Model.__init__	call	get_f_div_loss
sqrt	followed_by	dynamic_stitch
Trainer.__init__	call	Model.__init__
expand_dims	call	reduce_max
log_prob	call	_sum_log_exp
stop_gradient	followed_by	reduce_sum
RMSPropOptimizer	has_decay	0.9
device	has_arg0	/cpu:0
reduce_sum	has_axis	0
GaussianMixture.__init__	call	softmax
phi	call	reduce_max
main	call	_simulate_mixture_target
reduce_sum	followed_by	reduce_sum
softmax	followed_by	log
sample_step	call	sample
reduce_sum	followed_by	random_normal
model_mean_and_variance	followed_by	mean
reduce_sum	call	expand_dims
cast	call	equal
random_uniform	has_maxval	1
range	followed_by	run_single_step
Model.__init__	call	variable_scope
greater	has_arg0	0.5
main	call	Trainer.__init__
phi	call	exp
scalar	has_arg0	loss
sample_gumbel	call	log
exsqr	call	mean
main	call	Session
reduce_sum	followed_by	Categorical
phi	call	sign
reduce_max	followed_by	exp
range	has_arg0	1
gumbel_softmax	call	shape
train	call	run_single_step
GaussianMixture.__init__	followed_by	get_f_div_loss
sqrt	followed_by	sample
_sum_log_exp	call	log
_simulate_mixture_target	call	zeros
dynamic_partition	followed_by	range
dynamic_partition	has_num_partitions	self.n_components
expand_dims	has_arg0	2
_simulate_mixture_target	call	variable_scope
sample	call	sqrt
Trainer.__init__	call	FileWriter
expand_dims	followed_by	expand_dims
sample_gumbel	call	random_uniform
get_variable	has_arg0	weights
log_prob	followed_by	phi
sample_step	followed_by	comm_func_eval
Trainer.__init__	call	latest_checkpoint
train	call	eval_run
exponential_decay	has_name	decaying_learning_rate
expand_dims	followed_by	reduce_sum
get_f_div_loss	call	stop_gradient
Trainer.__init__	call	merge_all
sample	call	dynamic_partition
get_f_div_loss	call	reduce_sum
Saver	followed_by	FileWriter
reduce_sum	followed_by	range
log_prob	call	log
get_variable	followed_by	zeros
Mixture	followed_by	ConfigProto
ConfigProto	followed_by	Session
List	followed_by	stop_gradient
reshape	call	range
log_prob	call	exp
get_f_div_loss	call	sample
log_prob	followed_by	log_prob
FileWriter	followed_by	optimize_adagrad
optimize_adagrad	followed_by	latest_checkpoint
Trainer.__init__	followed_by	train
sample	call	random_normal
GaussianMixture.__init__	call	gumbel_softmax
optimize_adagrad	call	RMSPropOptimizer
zeros	has_arg0	(n_components, dim)
log_prob	call	List
exp	followed_by	sign
sample	call	size
get_variable	call	ones
range	followed_by	range
sign	call	expand_dims
eval_run	call	mean
sign	followed_by	cast
get_variable	has_dtype	tf.float32
sample	followed_by	sample
main	call	train
reshape	followed_by	dynamic_partition
ex	followed_by	exsqr
Categorical	has_probs	self._weights
set_random_seed	followed_by	Trainer.__init__
sample	call	range
stop_gradient	followed_by	stop_gradient
reduce_max	has_arg0	1
log	call	log
cast	call	greater
get_f_div_loss	followed_by	scalar
reduce_max	has_arg0	0
sample	call	reshape
ConfigProto	call	GPUOptions
train	call	sample_step
Trainer.__init__	call	Variable
zeros	followed_by	ones
reduce_sum	followed_by	expand_dims
_simulate_mixture_target	followed_by	set_random_seed
model_mean_and_variance	call	reduce_sum
Session	followed_by	device
reduce_sum	has_axis	1
_sum_log_exp	call	reduce_sum
gumbel_softmax_sample	call	softmax
comm_func_eval	call	exsqr
_sum_log_exp	followed_by	exp
model_mean_and_variance	followed_by	model_mean_and_variance
Trainer.__init__	call	Saver
cast	followed_by	reduce_sum
range	followed_by	size
phi	call	cast
phi	followed_by	stop_gradient
reduce_sum	followed_by	reduce_max
evaluate_step	call	comm_func_eval
phi	call	reduce_sum
size	followed_by	random_normal
_simulate_mixture_target	call	ones
reduce_sum	followed_by	log
sample	followed_by	reshape
get_f_div_loss	call	phi
get_f_div_loss	call	log_prob
merge_all	followed_by	Saver
ones	has_dtype	tf.float32
sample_gumbel	followed_by	softmax
softmax	has_arg0	1
Variable	followed_by	exponential_decay
expand_dims	has_arg0	0
exp	followed_by	reduce_sum
_simulate_mixture_target	call	GaussianMixture.__init__
exponential_decay	followed_by	merge_all
log_prob	call	stop_gradient
get_variable	has_arg0	mu
models.MultiVariateGaussian.log_prob	call	List
stop_gradient	followed_by	log
reduce_sum	followed_by	logZ
reduce_sum	has_axis	1
models.MultiVariateGaussian.log_prob	call	reduce_sum
logZ	call	log
logZ	call	stop_gradient
stop_gradient	followed_by	stop_gradient
List	followed_by	reduce_sum
models.MultiVariateGaussian.log_prob	call	logZ
models.MultiVariateGaussian.log_prob	call	stop_gradient
stop_gradient	followed_by	List
matmul	call	transpose
expand_dims	followed_by	expand_dims
models.GaussianMixture.log_gradient	call	matmul
reduce_sum	has_axis	1
expand_dims	has_arg0	1
expand_dims	followed_by	reduce_sum
posterior	call	_sum_log_exp
matmul	followed_by	squeeze
_sum_log_exp	call	log
models.GaussianMixture.log_gradient	call	List
_sum_log_exp	followed_by	exp
reduce_sum	has_axis	2
_sum_log_exp	call	expand_dims
reduce_sum	followed_by	log
log	followed_by	reduce_sum
posterior	call	reduce_sum
models.GaussianMixture.log_gradient	call	expand_dims
reduce_sum	followed_by	expand_dims
expand_dims	call	log
models.GaussianMixture.log_gradient	call	squeeze
_sum_log_exp	call	reduce_sum
expand_dims	call	reduce_max
models.GaussianMixture.log_gradient	call	posterior
expand_dims	call	transpose
squeeze	has_axis	1
expand_dims	has_arg0	0
expand_dims	followed_by	posterior
reduce_max	has_arg0	0
matmul	call	expand_dims
posterior	call	exp
exp	followed_by	reduce_sum
posterior	followed_by	matmul
expand_dims	followed_by	transpose
expand_dims	call	exp
List	followed_by	expand_dims
