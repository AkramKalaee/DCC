concat	followed_by	variable_scope
.main	call	train
name_scope	has_arg0	Discriminator_Train
variable_scope	followed_by	dropout
generator	call	Conv
placeholder	followed_by	get_or_create_global_step
Conv	followed_by	variable_scope
constant	has_name	filter
name_scope	has_arg0	GeneratorLoss
variable_scope	followed_by	Conv
train	followed_by	test
reduce_prod	followed_by	trainable_variables
reduce_mean	followed_by	mean_squared_error
DropOut	call	dropout
BatchNorm	followed_by	Conv
inference	call	get_or_create_global_step
build_vgg	call	feature_map
Conv	call	get_variable
max_pool	followed_by	conv_layer
variable_scope	followed_by	BatchNorm
train	call	reduce_sum
TransposeConv	call	conv2d_transpose
conv_layer	followed_by	conv_layer
log	followed_by	log
variable_scope	followed_by	maximum
variable_scope	followed_by	get_variable
TransitionUp	followed_by	concat
discriminator	call	sigmoid
reduce_sum	call	trainable_variables
range	followed_by	TransitionUp
expand_dims	followed_by	validate
scalar	has_arg0	GAN Loss
max_pool	followed_by	max_pool
variable_scope	followed_by	relu
zeros	followed_by	zeros
range	followed_by	DenseBlock
image	followed_by	image
Layer	call	DropOut
AvgPool	call	avg_pool
BatchNorm	call	variable_scope
inference	call	build_model
Conv	followed_by	sigmoid
reduce_mean	call	log
variable_scope	followed_by	placeholder
discriminator	call	Conv
validate	call	expand_dims
scalar	followed_by	image
test	call	Session
.main	call	inference
DenseBlock	call	concat
TransitionDown	call	DropOut
scalar	followed_by	scalar
TransitionUp	call	variable_scope
DropOut	followed_by	AvgPool
merge	followed_by	merge
build_model	call	variable_scope
build_model	call	image
Layer	call	variable_scope
control_dependencies	followed_by	name_scope
name_scope	followed_by	trainable_variables
get_conv_filter	call	constant
variable_scope	followed_by	discriminator
test	followed_by	inference
bias_add	followed_by	relu
TransposeConv	call	shape
image	has_arg0	Input
trainable_variables	followed_by	trainable_variables
test	call	latest_checkpoint
validate	call	range
reduce_prod	call	shape
build_vgg	call	resize_images
get_variable	followed_by	pad
train	call	build_model
mean_squared_error	followed_by	name_scope
name_scope	followed_by	Saver
range	has_arg0	1
DenseBlock	call	Layer
get_variable	followed_by	conv2d_transpose
variable_scope	has_arg0	Composite
variable_scope	followed_by	shape
TransposeConv	call	get_variable
variable_scope	has_arg0	TransposeConv
variable_scope	has_arg0	Conv
.main	call	test
train	call	zeros
Conv	call	conv2d
reduce_sum	call	reduce_prod
variable_scope	has_arg0	Generator
reduce_mean	call	abs
build_model	call	generator
conv_layer	followed_by	max_pool
generator	call	variable_scope
reshape	has_arg0	(1, 256, 256, 3)
variable_scope	followed_by	generator
TransposeConv	call	variable_scope
get_bias	followed_by	bias_add
discriminator	call	BatchNorm
scalar	has_arg0	Discriminator Loss
variable_scope	followed_by	build_vgg
placeholder	followed_by	placeholder
image	has_max_outputs	1
build_model	call	Saver
concat	has_axis	3
Session	followed_by	latest_checkpoint
zeros	has_arg0	(val_image_count, 256, 256, 3)
generator	call	range
reduce_sum	followed_by	range
train	call	expand_dims
train	call	get_or_create_global_step
build_model	call	get_collection
name_scope	has_arg0	Real_Discriminator
name_scope	followed_by	get_collection
zeros	followed_by	Session
build_vgg	call	Vgg19.__init__
range	followed_by	range
image	has_arg0	Target
conv_layer	call	relu
DropOut	call	variable_scope
TransitionDown	call	Conv
name_scope	followed_by	variable_scope
DenseBlock	call	range
ReLU	call	variable_scope
Layer	call	BatchNorm
FileWriter	followed_by	reduce_sum
expand_dims	followed_by	expand_dims
inference	call	Session
stack	followed_by	get_variable
concat	followed_by	conv_layer
Conv	call	variable_scope
Conv	call	pad
avg_pool	followed_by	avg_pool
build_model	call	get_or_create_global_step
DenseBlock	followed_by	TransitionDown
constant	has_name	biases
train	call	validate
expand_dims	has_axis	0
DenseBlock	followed_by	variable_scope
resize_images	followed_by	feature_map
name_scope	has_arg0	Summary
feature_map	call	concat
AdamOptimizer	has_beta1	0.5
variable_scope	has_arg0	OutputConv
range	followed_by	variable_scope
feature_map	call	max_pool
scalar	has_arg0	Generator Loss
shape	followed_by	stack
variable_scope	has_arg0	InputConv
DenseBlock	followed_by	range
get_variable	has_arg0	Filter
validate	call	reshape
variable_scope	has_arg0	Discriminator
variable_scope	followed_by	avg_pool
image	followed_by	merge
avg_pool	call	avg_pool
train	call	FileWriter
feature_map	call	conv_layer
LeakyReLU	call	maximum
build_model	call	placeholder
inference	call	expand_dims
discriminator	followed_by	name_scope
train	call	Session
concat	followed_by	DenseBlock
build_model	call	mean_squared_error
reduce_mean	followed_by	name_scope
LeakyReLU	followed_by	Conv
Model	followed_by	train
name_scope	has_arg0	DiscriminatorLoss
range	followed_by	expand_dims
variable_scope	followed_by	range
AvgPool	call	variable_scope
build_model	call	trainable_variables
get_collection	followed_by	control_dependencies
name_scope	has_arg0	Fake_Discriminator
get_or_create_global_step	followed_by	variable_scope
build_vgg	followed_by	name_scope
variable_scope	has_arg0	Final_Layer
name_scope	has_arg0	Optimizer
TransitionDown	call	variable_scope
conv_layer	call	get_conv_filter
variable_scope	has_arg0	LeakyReLU
train	call	latest_checkpoint
TransitionUp	call	TransposeConv
reduce_sum	followed_by	reduce_sum
name_scope	has_arg0	Real_VGG
ReLU	call	relu
name_scope	has_arg0	Variables
TransitionDown	call	BatchNorm
name_scope	has_arg0	Save
placeholder	has_dtype	tf.bool
variable_scope	has_arg0	AvgPool
conv_layer	call	variable_scope
train	followed_by	GAN.__init__
GAN.__init__	followed_by	train
generator	call	DenseBlock
BatchNorm	followed_by	LeakyReLU
name_scope	has_arg0	Generator_Train
name_scope	followed_by	scalar
split	followed_by	concat
get_bias	call	constant
generator	call	TransitionUp
TransitionDown	call	AvgPool
discriminator	call	concat
.main	call	GAN.__init__
build_model	call	reduce_mean
build_model	call	discriminator
build_model	call	name_scope
Layer	followed_by	concat
get_or_create_global_step	followed_by	expand_dims
inference	call	latest_checkpoint
train	call	range
variable_scope	followed_by	TransposeConv
variable_scope	followed_by	get_conv_filter
generator	followed_by	name_scope
feature_map	call	split
.main	call	Model
name_scope	followed_by	AdamOptimizer
LeakyReLU	call	variable_scope
concat	has_name	Concat
ReLU	followed_by	Conv
conv2d	followed_by	get_bias
merge	followed_by	name_scope
Saver	has_max_to_keep	3
build_model	call	build_vgg
test	call	build_model
build_model	call	AdamOptimizer
test	call	expand_dims
pad	followed_by	conv2d
test	call	get_or_create_global_step
Conv	followed_by	DropOut
variable_scope	has_arg0	Placeholders
variable_scope	followed_by	Layer
conv_layer	call	bias_add
variable_scope	has_arg0	ReLU
discriminator	call	LeakyReLU
trainable_variables	followed_by	name_scope
latest_checkpoint	followed_by	get_or_create_global_step
generator	call	concat
name_scope	has_arg0	Fake_VGG
name_scope	followed_by	reduce_mean
build_model	call	merge
expand_dims	followed_by	reshape
conv2d	has_padding	SAME
Saver	followed_by	name_scope
AdamOptimizer	followed_by	name_scope
generator	call	TransitionDown
reduce_mean	followed_by	reduce_mean
get_conv_filter	followed_by	conv2d
Layer	call	Conv
max_pool	call	max_pool
conv_layer	call	conv2d
range	has_arg1	6
scalar	has_arg0	VGG Loss
build_model	call	control_dependencies
placeholder	has_dtype	tf.float32
Conv	followed_by	range
build_model	call	scalar
image	has_arg0	Output
DenseBlock	call	variable_scope
build_model	followed_by	Session
TransposeConv	call	stack
conv_layer	call	get_bias
scalar	has_arg0	L1 Loss
get_or_create_global_step	followed_by	FileWriter
variable_scope	has_arg0	VGG
FileWriter	call	get_default_graph
BatchNorm	followed_by	ReLU
discriminator	call	variable_scope
zeros	has_arg0	(total_image_count, 256, 256, 3)
pad	has_mode	CONSTANT
Vgg19.__init__	followed_by	resize_images
TransitionDown	followed_by	DenseBlock
conv2d_transpose	has_padding	SAME
Layer	call	ReLU
build_model	followed_by	zeros
max_pool	call	max_pool
max_pool	followed_by	max_pool
variable_scope	has_arg0	MaxPool
operations.MaxPool	call	variable_scope
variable_scope	followed_by	max_pool
operations.MaxPool	call	max_pool
utils.MaxPool	call	max_pool
max_pool	call	max_pool
max_pool	followed_by	max_pool
conv	call	pad
Vgg19.__init__	followed_by	resize_images
split	followed_by	concat
variable_scope	has_arg0	Discriminator
tiramisu	call	concat
name_scope	has_arg0	Summary
lrelu	followed_by	conv
moments	followed_by	batch_normalization
latest_checkpoint	followed_by	range
build	call	tiramisu
Conv	call	conv2d
get_variable	has_arg0	Bias
max_pool	followed_by	max_pool
name_scope	followed_by	scalar
range	followed_by	expand_dims
batchnorm	followed_by	lrelu
resize_images	followed_by	feature_map
conv_layer	call	get_conv_filter
avg_pool	call	avg_pool
expand_dims	has_axis	0
DenseBlock	followed_by	range
identity	followed_by	get_variable
merge	followed_by	merge
name_scope	has_arg0	Variables
name_scope	has_arg0	Fake_Discriminator
build	call	scalar
concat	has_name	Concat
TransitionDown	call	Conv
test	call	build
name_scope	has_arg0	Real_VGG
image	has_arg0	Output
range	followed_by	DenseBlock
max_pool	call	max_pool
Conv	followed_by	Conv
build	call	image
variable_scope	has_arg0	Composite
reduce_mean	call	log
get_bias	followed_by	bias_add
conv	call	get_variable
DenseBlock	call	Layer
TransitionUp	call	deconv
variable_scope	followed_by	range
discriminator	followed_by	name_scope
build_vgg	followed_by	name_scope
image	followed_by	image
tiramisu	call	variable_scope
TransitionDown	call	variable_scope
build	followed_by	Session
get_conv_filter	followed_by	conv2d
name_scope	has_arg0	GeneratorLoss
Conv	followed_by	DropOut
variable_scope	has_arg0	Final_Layer
tiramisu	call	TransitionUp
conv_layer	call	bias_add
name_scope	followed_by	Saver
AdamOptimizer	followed_by	name_scope
tiramisu	call	range
batchnorm	call	batch_normalization
variable_scope	followed_by	avg_pool
deconv	call	shape
get_variable	followed_by	conv2d_transpose
batchnorm	followed_by	Relu
load	has_arg0	B_test.npy
conv_layer	call	get_bias
batchnorm	call	identity
build_vgg	call	feature_map
conv2d_transpose	has_padding	SAME
test	call	range
DenseBlock	followed_by	TransitionDown
conv_layer	call	variable_scope
Layer	call	Relu
feature_map	call	conv_layer
get_or_create_global_step	followed_by	variable_scope
variable_scope	followed_by	Conv
variable_scope	has_arg0	Placeholders
get_variable	has_arg0	offset
discriminator	call	conv
variable_scope	has_arg0	Conv
shape	followed_by	stack
test	call	ssim
conv2d	followed_by	get_bias
.replicate	call	test
tiramisu	call	Conv
GAN.__init__	followed_by	test
conv	call	variable_scope
.replicate	call	GAN.__init__
placeholder	followed_by	placeholder
DropOut	call	variable_scope
reduce_mean	followed_by	reduce_mean
scalar	followed_by	scalar
build	call	reduce_mean
variable_scope	followed_by	build_vgg
DenseBlock	call	concat
DenseBlock	followed_by	variable_scope
name_scope	followed_by	AdamOptimizer
name_scope	has_arg0	Fake_VGG
merge	followed_by	name_scope
scalar	has_arg0	VGG Loss
build	call	name_scope
lrelu	call	maximum
pad	has_mode	CONSTANT
avg_pool	followed_by	avg_pool
DenseBlock	call	range
deconv	call	get_variable
build	call	variable_scope
bias_add	followed_by	relu
mean_squared_error	followed_by	name_scope
build	call	AdamOptimizer
expand_dims	followed_by	ssim
scalar	has_arg0	Generator Loss
conv_layer	call	conv2d
name_scope	has_arg0	Real_Discriminator
batchnorm	call	variable_scope
name_scope	followed_by	maximum
variable_scope	followed_by	discriminator
conv2d	has_padding	SAME
name_scope	has_arg0	Optimizer
name_scope	followed_by	variable_scope
image	has_max_outputs	1
build	call	discriminator
variable_scope	followed_by	batchnorm
get_bias	call	constant
scalar	has_arg0	Discriminator Loss
DropOut	followed_by	DropOut
name_scope	followed_by	name_scope
variable_scope	has_arg0	AvgPool
load	has_arg0	A_test.npy
conv	followed_by	variable_scope
Conv	call	pad
variable_scope	followed_by	shape
discriminator	call	concat
get_variable	followed_by	conv2d
Layer	call	batchnorm
test	call	expand_dims
name_scope	followed_by	trainable_variables
load	followed_by	build
image	followed_by	merge
trainable_variables	followed_by	name_scope
conv	call	conv2d
lrelu	call	name_scope
concat	has_axis	3
TransitionDown	call	DropOut
name_scope	has_arg0	LeakyRelu
feature_map	call	concat
conv_layer	call	relu
variable_scope	followed_by	get_variable
conv2d	has_padding	VALID
build	call	merge
name_scope	has_arg0	Generator_Train
range	has_arg0	1
Conv	followed_by	range
TransitionDown	call	AvgPool
deconv	call	variable_scope
range	followed_by	variable_scope
Layer	followed_by	concat
build	call	placeholder
conv	followed_by	sigmoid
name_scope	has_arg0	DiscriminatorLoss
scalar	has_arg0	GAN Loss
test	call	latest_checkpoint
Saver	has_max_to_keep	10
variable_scope	followed_by	placeholder
tiramisu	call	DenseBlock
get_variable	followed_by	get_variable
DropOut	call	dropout
test	call	Session
Layer	call	DropOut
DropOut	followed_by	AvgPool
reduce_mean	call	abs
variable_scope	followed_by	identity
test	call	load
TransitionDown	call	batchnorm
Conv	call	get_variable
reduce_mean	followed_by	mean_squared_error
build	call	mean_squared_error
variable_scope	has_arg0	BatchNorm
variable_scope	followed_by	dropout
discriminator	call	variable_scope
variable_scope	followed_by	deconv
variable_scope	followed_by	Layer
build_vgg	call	resize_images
batchnorm	followed_by	Conv
range	has_arg1	6
build	call	trainable_variables
variable_scope	has_arg0	VGG
AvgPool	call	avg_pool
discriminator	call	sigmoid
batchnorm	call	get_variable
Saver	followed_by	name_scope
TransitionDown	followed_by	DenseBlock
Layer	call	Conv
Session	followed_by	latest_checkpoint
deconv	call	conv2d_transpose
build_vgg	call	Vgg19.__init__
concat	followed_by	conv_layer
placeholder	followed_by	get_or_create_global_step
log	followed_by	log
scalar	has_arg0	L1 Loss
constant	has_name	filter
variable_scope	followed_by	tiramisu
variable_scope	has_arg0	Generator
variable_scope	followed_by	conv
name_scope	followed_by	reduce_mean
Relu	call	relu
get_conv_filter	call	constant
placeholder	has_dtype	tf.float32
image	has_arg0	Input
Conv	call	variable_scope
reduce_mean	followed_by	name_scope
load	followed_by	load
feature_map	call	split
range	followed_by	TransitionUp
Layer	call	variable_scope
name_scope	has_arg0	Save
image	has_arg0	Target
pad	followed_by	conv2d
trainable_variables	followed_by	trainable_variables
batchnorm	call	moments
concat	followed_by	DenseBlock
build	call	build_vgg
deconv	call	stack
max_pool	followed_by	conv_layer
get_variable	has_arg0	Filter
build	call	Saver
variable_scope	has_arg0	OutputConv
TransitionUp	call	variable_scope
TransitionUp	followed_by	concat
scalar	followed_by	image
tiramisu	followed_by	name_scope
AdamOptimizer	has_beta1	0.5
DenseBlock	call	variable_scope
build	call	get_or_create_global_step
variable_scope	has_arg0	DeConv
AvgPool	call	variable_scope
constant	has_name	biases
discriminator	call	lrelu
variable_scope	followed_by	get_conv_filter
stack	followed_by	get_variable
concat	followed_by	variable_scope
conv_layer	followed_by	max_pool
discriminator	call	batchnorm
AvgPool	followed_by	AvgPool
get_variable	followed_by	pad
get_variable	followed_by	moments
conv_layer	followed_by	conv_layer
tiramisu	call	TransitionDown
variable_scope	has_arg0	InputConv
feature_map	call	max_pool
get_variable	has_arg0	scale
name_scope	has_arg0	Discriminator_Train
Relu	followed_by	Conv
