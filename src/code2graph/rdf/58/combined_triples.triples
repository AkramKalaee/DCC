max_pool	followed_by	max_pool
max_pool	call	max_pool
utils.MaxPool	call	max_pool
DenseBlock	followed_by	range
generator	call	variable_scope
test	call	get_or_create_global_step
test	followed_by	inference
Conv	call	variable_scope
build_model	call	get_collection
.main	call	test
ReLU	call	variable_scope
trainable_variables	followed_by	trainable_variables
image	has_arg0	Input
train	call	FileWriter
generator	call	concat
build_model	followed_by	zeros
name_scope	followed_by	scalar
TransitionUp	call	TransposeConv
build_vgg	call	resize_images
get_or_create_global_step	followed_by	expand_dims
TransitionDown	call	Conv
inference	call	get_or_create_global_step
generator	call	Conv
name_scope	has_arg0	Save
variable_scope	followed_by	dropout
variable_scope	followed_by	relu
conv_layer	call	bias_add
split	followed_by	concat
name_scope	followed_by	trainable_variables
max_pool	followed_by	conv_layer
TransposeConv	call	shape
variable_scope	followed_by	get_variable
build_model	call	Saver
bias_add	followed_by	relu
train	followed_by	GAN.__init__
zeros	has_arg0	(val_image_count, 256, 256, 3)
variable_scope	has_arg0	Final_Layer
build_model	call	AdamOptimizer
name_scope	followed_by	variable_scope
build_model	call	discriminator
TransitionDown	call	DropOut
Layer	call	variable_scope
ReLU	followed_by	Conv
range	has_arg0	1
reduce_sum	followed_by	range
inference	call	latest_checkpoint
LeakyReLU	call	maximum
discriminator	call	LeakyReLU
generator	call	TransitionUp
reduce_mean	followed_by	mean_squared_error
AdamOptimizer	has_beta1	0.5
train	call	latest_checkpoint
variable_scope	followed_by	TransposeConv
constant	has_name	biases
reduce_mean	call	abs
expand_dims	followed_by	validate
zeros	followed_by	Session
placeholder	has_dtype	tf.bool
Layer	call	ReLU
Conv	call	get_variable
name_scope	has_arg0	Fake_Discriminator
name_scope	has_arg0	DiscriminatorLoss
scalar	has_arg0	VGG Loss
train	call	expand_dims
discriminator	call	concat
name_scope	has_arg0	Fake_VGG
DenseBlock	followed_by	TransitionDown
avg_pool	followed_by	avg_pool
feature_map	call	conv_layer
TransposeConv	call	stack
build_vgg	call	feature_map
discriminator	call	variable_scope
max_pool	call	max_pool
LeakyReLU	call	variable_scope
BatchNorm	followed_by	LeakyReLU
LeakyReLU	followed_by	Conv
name_scope	followed_by	AdamOptimizer
shape	followed_by	stack
avg_pool	call	avg_pool
TransposeConv	call	variable_scope
resize_images	followed_by	feature_map
build_model	call	reduce_mean
validate	call	expand_dims
DropOut	call	dropout
variable_scope	followed_by	discriminator
build_model	call	get_or_create_global_step
variable_scope	has_arg0	AvgPool
image	has_arg0	Output
generator	call	range
build_model	call	generator
variable_scope	has_arg0	ReLU
name_scope	has_arg0	Optimizer
image	followed_by	image
TransitionDown	call	variable_scope
train	followed_by	test
Conv	followed_by	range
conv_layer	call	get_bias
conv2d	followed_by	get_bias
reduce_prod	call	shape
conv_layer	followed_by	conv_layer
test	call	latest_checkpoint
variable_scope	has_arg0	InputConv
test	call	build_model
build_model	call	mean_squared_error
TransposeConv	call	get_variable
variable_scope	followed_by	Conv
build_model	call	scalar
get_variable	followed_by	pad
scalar	has_arg0	Generator Loss
get_conv_filter	call	constant
train	call	build_model
name_scope	has_arg0	Discriminator_Train
DenseBlock	call	Layer
test	call	expand_dims
variable_scope	has_arg0	OutputConv
scalar	has_arg0	L1 Loss
Vgg19.__init__	followed_by	resize_images
GAN.__init__	followed_by	train
generator	call	DenseBlock
DenseBlock	call	range
variable_scope	followed_by	Layer
pad	has_mode	CONSTANT
get_bias	call	constant
Model	followed_by	train
variable_scope	has_arg0	Conv
DropOut	followed_by	AvgPool
feature_map	call	max_pool
get_or_create_global_step	followed_by	FileWriter
reduce_prod	followed_by	trainable_variables
inference	call	Session
name_scope	followed_by	reduce_mean
variable_scope	has_arg0	VGG
merge	followed_by	merge
generator	call	TransitionDown
name_scope	has_arg0	Real_VGG
discriminator	call	sigmoid
generator	followed_by	name_scope
build_model	call	variable_scope
conv_layer	followed_by	max_pool
build_model	call	trainable_variables
get_or_create_global_step	followed_by	variable_scope
stack	followed_by	get_variable
reduce_mean	followed_by	reduce_mean
reduce_sum	call	reduce_prod
Conv	followed_by	DropOut
TransitionUp	followed_by	concat
build_model	followed_by	Session
variable_scope	has_arg0	TransposeConv
concat	followed_by	conv_layer
.main	call	inference
build_vgg	call	Vgg19.__init__
train	call	range
range	followed_by	variable_scope
inference	call	build_model
max_pool	followed_by	max_pool
latest_checkpoint	followed_by	get_or_create_global_step
placeholder	followed_by	placeholder
build_model	call	build_vgg
FileWriter	call	get_default_graph
range	followed_by	TransitionUp
variable_scope	followed_by	get_conv_filter
discriminator	call	Conv
build_model	call	merge
train	call	validate
variable_scope	has_arg0	Discriminator
Layer	call	Conv
concat	has_name	Concat
build_model	call	image
train	call	Session
variable_scope	has_arg0	Composite
expand_dims	followed_by	expand_dims
reduce_mean	call	log
scalar	followed_by	scalar
test	call	Session
Conv	call	pad
discriminator	call	BatchNorm
scalar	has_arg0	GAN Loss
name_scope	followed_by	get_collection
validate	call	range
constant	has_name	filter
build_vgg	followed_by	name_scope
image	has_max_outputs	1
ReLU	call	relu
TransitionDown	call	AvgPool
validate	call	reshape
conv_layer	call	variable_scope
Saver	followed_by	name_scope
image	has_arg0	Target
variable_scope	followed_by	avg_pool
inference	call	expand_dims
variable_scope	followed_by	generator
reduce_sum	followed_by	reduce_sum
.main	call	Model
get_bias	followed_by	bias_add
range	followed_by	range
Conv	followed_by	sigmoid
mean_squared_error	followed_by	name_scope
build_model	call	placeholder
Layer	call	DropOut
Layer	followed_by	concat
variable_scope	followed_by	range
Conv	followed_by	variable_scope
name_scope	followed_by	Saver
DenseBlock	call	variable_scope
BatchNorm	call	variable_scope
feature_map	call	concat
name_scope	has_arg0	Real_Discriminator
DenseBlock	call	concat
variable_scope	has_arg0	Placeholders
get_conv_filter	followed_by	conv2d
conv2d	has_padding	SAME
merge	followed_by	name_scope
BatchNorm	followed_by	ReLU
conv_layer	call	relu
.main	call	train
Layer	call	BatchNorm
name_scope	has_arg0	Generator_Train
variable_scope	followed_by	placeholder
TransitionDown	call	BatchNorm
Session	followed_by	latest_checkpoint
DropOut	call	variable_scope
train	call	reduce_sum
Saver	has_max_to_keep	3
Conv	call	conv2d
scalar	has_arg0	Discriminator Loss
trainable_variables	followed_by	name_scope
concat	followed_by	DenseBlock
image	followed_by	merge
train	call	zeros
variable_scope	has_arg0	LeakyReLU
.main	call	GAN.__init__
control_dependencies	followed_by	name_scope
get_variable	followed_by	conv2d_transpose
AvgPool	call	avg_pool
variable_scope	followed_by	shape
DenseBlock	followed_by	variable_scope
reduce_mean	followed_by	name_scope
range	followed_by	DenseBlock
expand_dims	has_axis	0
name_scope	has_arg0	Summary
conv2d_transpose	has_padding	SAME
TransitionUp	call	variable_scope
train	call	get_or_create_global_step
AvgPool	call	variable_scope
range	followed_by	expand_dims
placeholder	has_dtype	tf.float32
variable_scope	followed_by	BatchNorm
get_variable	has_arg0	Filter
discriminator	followed_by	name_scope
name_scope	has_arg0	GeneratorLoss
variable_scope	followed_by	maximum
get_collection	followed_by	control_dependencies
build_model	call	name_scope
zeros	followed_by	zeros
feature_map	call	split
variable_scope	followed_by	build_vgg
range	has_arg1	6
scalar	followed_by	image
pad	followed_by	conv2d
log	followed_by	log
TransposeConv	call	conv2d_transpose
name_scope	has_arg0	Variables
FileWriter	followed_by	reduce_sum
concat	has_axis	3
expand_dims	followed_by	reshape
variable_scope	has_arg0	Generator
AdamOptimizer	followed_by	name_scope
placeholder	followed_by	get_or_create_global_step
concat	followed_by	variable_scope
TransitionDown	followed_by	DenseBlock
reshape	has_arg0	(1, 256, 256, 3)
conv_layer	call	get_conv_filter
build_model	call	control_dependencies
zeros	has_arg0	(total_image_count, 256, 256, 3)
BatchNorm	followed_by	Conv
conv_layer	call	conv2d
reduce_sum	call	trainable_variables
max_pool	followed_by	max_pool
operations.MaxPool	call	variable_scope
variable_scope	followed_by	max_pool
operations.MaxPool	call	max_pool
variable_scope	has_arg0	MaxPool
max_pool	call	max_pool
build	call	discriminator
conv_layer	call	get_bias
.replicate	call	GAN.__init__
load	followed_by	load
batchnorm	call	get_variable
Layer	followed_by	concat
avg_pool	call	avg_pool
DenseBlock	call	variable_scope
concat	has_name	Concat
DropOut	call	variable_scope
conv_layer	call	variable_scope
scalar	has_arg0	L1 Loss
name_scope	has_arg0	Fake_Discriminator
variable_scope	has_arg0	Final_Layer
image	has_arg0	Input
load	has_arg0	B_test.npy
variable_scope	has_arg0	Placeholders
build_vgg	followed_by	name_scope
deconv	call	stack
conv	call	variable_scope
image	has_arg0	Output
TransitionDown	call	batchnorm
DenseBlock	call	Layer
load	followed_by	build
tiramisu	call	concat
Saver	has_max_to_keep	10
trainable_variables	followed_by	name_scope
scalar	has_arg0	GAN Loss
name_scope	has_arg0	Real_Discriminator
get_variable	has_arg0	Bias
name_scope	followed_by	reduce_mean
TransitionUp	call	deconv
Vgg19.__init__	followed_by	resize_images
scalar	followed_by	scalar
get_variable	followed_by	pad
name_scope	followed_by	Saver
batchnorm	call	identity
conv2d	has_padding	VALID
variable_scope	followed_by	placeholder
reduce_mean	call	abs
build	call	build_vgg
name_scope	has_arg0	Discriminator_Train
build	call	AdamOptimizer
variable_scope	followed_by	tiramisu
get_variable	followed_by	get_variable
conv_layer	call	bias_add
name_scope	has_arg0	Optimizer
DropOut	followed_by	AvgPool
range	has_arg1	6
AdamOptimizer	has_beta1	0.5
TransitionDown	call	AvgPool
get_variable	followed_by	conv2d
TransitionUp	call	variable_scope
name_scope	has_arg0	Save
conv2d	has_padding	SAME
variable_scope	followed_by	get_conv_filter
concat	followed_by	variable_scope
AdamOptimizer	followed_by	name_scope
Layer	call	Conv
deconv	call	variable_scope
test	call	ssim
concat	followed_by	DenseBlock
conv_layer	followed_by	conv_layer
variable_scope	followed_by	Conv
reduce_mean	followed_by	name_scope
scalar	has_arg0	Discriminator Loss
Saver	followed_by	name_scope
stack	followed_by	get_variable
discriminator	call	lrelu
AvgPool	call	variable_scope
variable_scope	followed_by	shape
feature_map	call	conv_layer
variable_scope	followed_by	get_variable
Conv	call	pad
get_variable	followed_by	moments
name_scope	followed_by	maximum
variable_scope	has_arg0	Discriminator
variable_scope	followed_by	discriminator
pad	has_mode	CONSTANT
resize_images	followed_by	feature_map
name_scope	has_arg0	GeneratorLoss
Relu	followed_by	Conv
max_pool	call	max_pool
name_scope	has_arg0	Summary
test	call	Session
discriminator	call	variable_scope
reduce_mean	followed_by	reduce_mean
placeholder	followed_by	get_or_create_global_step
build	call	merge
Conv	call	conv2d
discriminator	call	batchnorm
variable_scope	has_arg0	Composite
test	call	latest_checkpoint
tiramisu	call	TransitionDown
tiramisu	call	Conv
lrelu	call	name_scope
batchnorm	followed_by	Relu
name_scope	has_arg0	DiscriminatorLoss
reduce_mean	call	log
scalar	followed_by	image
variable_scope	followed_by	batchnorm
variable_scope	followed_by	Layer
Layer	call	batchnorm
scalar	has_arg0	Generator Loss
build	call	get_or_create_global_step
moments	followed_by	batch_normalization
build	call	placeholder
max_pool	followed_by	max_pool
DenseBlock	followed_by	range
conv	followed_by	sigmoid
variable_scope	has_arg0	Generator
placeholder	has_dtype	tf.float32
Layer	call	DropOut
variable_scope	has_arg0	InputConv
Conv	call	variable_scope
variable_scope	has_arg0	VGG
build	call	scalar
image	followed_by	image
log	followed_by	log
name_scope	has_arg0	Generator_Train
TransitionDown	followed_by	DenseBlock
get_variable	has_arg0	scale
name_scope	followed_by	scalar
discriminator	call	concat
placeholder	followed_by	placeholder
name_scope	has_arg0	Variables
conv2d	followed_by	get_bias
load	has_arg0	A_test.npy
batchnorm	followed_by	lrelu
name_scope	followed_by	variable_scope
Conv	followed_by	Conv
deconv	call	conv2d_transpose
discriminator	call	sigmoid
max_pool	followed_by	conv_layer
batchnorm	call	batch_normalization
concat	has_axis	3
tiramisu	call	TransitionUp
latest_checkpoint	followed_by	range
tiramisu	followed_by	name_scope
variable_scope	followed_by	avg_pool
AvgPool	followed_by	AvgPool
DropOut	call	dropout
TransitionDown	call	DropOut
avg_pool	followed_by	avg_pool
feature_map	call	split
build	call	variable_scope
variable_scope	has_arg0	BatchNorm
variable_scope	followed_by	identity
expand_dims	followed_by	ssim
TransitionDown	call	variable_scope
conv	followed_by	variable_scope
Conv	call	get_variable
get_variable	has_arg0	offset
DenseBlock	call	range
Layer	call	Relu
mean_squared_error	followed_by	name_scope
test	call	expand_dims
merge	followed_by	name_scope
lrelu	call	maximum
discriminator	followed_by	name_scope
get_bias	followed_by	bias_add
TransitionUp	followed_by	concat
deconv	call	get_variable
conv_layer	followed_by	max_pool
Conv	followed_by	DropOut
build	call	image
identity	followed_by	get_variable
batchnorm	call	moments
test	call	build
Conv	followed_by	range
concat	followed_by	conv_layer
DenseBlock	followed_by	variable_scope
Relu	call	relu
conv	call	conv2d
pad	followed_by	conv2d
variable_scope	has_arg0	AvgPool
variable_scope	followed_by	dropout
range	followed_by	variable_scope
DropOut	followed_by	DropOut
conv_layer	call	conv2d
shape	followed_by	stack
test	call	load
range	followed_by	DenseBlock
lrelu	followed_by	conv
get_conv_filter	call	constant
.replicate	call	test
get_bias	call	constant
image	has_arg0	Target
image	followed_by	merge
scalar	has_arg0	VGG Loss
conv	call	pad
build_vgg	call	feature_map
GAN.__init__	followed_by	test
batchnorm	followed_by	Conv
range	followed_by	TransitionUp
deconv	call	shape
variable_scope	followed_by	conv
variable_scope	followed_by	deconv
name_scope	has_arg0	Fake_VGG
split	followed_by	concat
tiramisu	call	range
Session	followed_by	latest_checkpoint
range	has_arg0	1
conv2d_transpose	has_padding	SAME
build_vgg	call	resize_images
get_variable	followed_by	conv2d_transpose
name_scope	has_arg0	LeakyRelu
build	call	name_scope
feature_map	call	max_pool
expand_dims	has_axis	0
Layer	call	variable_scope
DenseBlock	followed_by	TransitionDown
variable_scope	followed_by	build_vgg
get_or_create_global_step	followed_by	variable_scope
build	call	tiramisu
build_vgg	call	Vgg19.__init__
test	call	range
conv_layer	call	get_conv_filter
batchnorm	call	variable_scope
name_scope	has_arg0	Real_VGG
get_conv_filter	followed_by	conv2d
constant	has_name	filter
build	call	mean_squared_error
trainable_variables	followed_by	trainable_variables
name_scope	followed_by	AdamOptimizer
DenseBlock	call	concat
build	call	Saver
build	followed_by	Session
feature_map	call	concat
name_scope	followed_by	trainable_variables
variable_scope	has_arg0	OutputConv
variable_scope	followed_by	range
bias_add	followed_by	relu
conv	call	get_variable
build	call	reduce_mean
conv_layer	call	relu
reduce_mean	followed_by	mean_squared_error
range	followed_by	expand_dims
variable_scope	has_arg0	Conv
discriminator	call	conv
AvgPool	call	avg_pool
tiramisu	call	variable_scope
merge	followed_by	merge
get_variable	has_arg0	Filter
image	has_max_outputs	1
tiramisu	call	DenseBlock
name_scope	followed_by	name_scope
TransitionDown	call	Conv
variable_scope	has_arg0	DeConv
build	call	trainable_variables
constant	has_name	biases
