attention modules connecting encoder and decoders have been widely applied in the ﬁeld of object recognition, image captioning, visual question answering and neural machine translation, and signiﬁcantly improves the performance.