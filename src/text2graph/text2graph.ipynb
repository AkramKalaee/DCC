{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "import plac\n",
    "\n",
    "model_dir = './Models/'\n",
    "test_dir = './Data/TestData/'\n",
    "output_dir = './Output/'\n",
    "\n",
    "nlp = spacy.load(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the abstracts\n",
    "\n",
    "Read the abstracts that are located at the `/Data/TestData/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finally, we can use <e1>recurjac to evaluate</e1> the <e2>robustness</e2> of neural networks, by giving a certified lower bound within which no adversarial examples can be found.\n",
      "\n",
      "\n",
      "\n",
      "finally, we can use <e1>recurjac to evaluate</e1> the <e2>robustness</e2> of neural networks, by giving a certified lower bound within which no adversarial examples can be found.\n",
      "\n",
      "\n",
      "\n",
      "to formally answer this question and bound the behavior of neural networks, a critical step is to compute the uniform bounds of the <e1>jacobian matrix</e1> bfpxq/bx for \n",
      "all x within a <e2>certain region</e2>.\n",
      "\n",
      "\n",
      "\n",
      "to formally answer this question and bound the behavior of neural networks, a critical step is to compute the uniform bounds of the <e1>jacobian matrix</e1> bfpxq/bx for \n",
      "all x within a <e2>certain region</e2>.\n",
      "\n",
      "\n",
      "\n",
      "to formally answer this question and bound the behavior of neural networks, a critical step is to compute the uniform bounds of the <e1>jacobian matrix</e1> bfpxq/bx for \n",
      "all x within a <e2>certain region</e2>.\n",
      "\n",
      "\n",
      "\n",
      "to formally answer this question and bound the behavior of neural networks, a critical step is to compute the uniform bounds of the <e1>jacobian matrix</e1> bfpxq/bx for \n",
      "all x within a <e2>certain region</e2>.\n",
      "\n",
      "\n",
      "\n",
      "to formally answer this question and bound the behavior of neural networks, a critical step is to compute the uniform bounds of the <e1>jacobian matrix</e1> bfpxq/bx for \n",
      "all x within a <e2>certain region</e2>.\n",
      "\n",
      "\n",
      "\n",
      "in <e1>generative adversarial networks</e1> (<e2>gans</e2>) (goodfellow et al.\n",
      "\n",
      "\n",
      "\n",
      "in <e1>generative adversarial networks</e1> (<e2>gans</e2>) (goodfellow et al.\n",
      "\n",
      "\n",
      "\n",
      "in <e1>generative adversarial networks</e1> (<e2>gans</e2>) (goodfellow et al.\n",
      "\n",
      "\n",
      "\n",
      "in <e1>generative adversarial networks</e1> (<e2>gans</e2>) (goodfellow et al.\n",
      "\n",
      "\n",
      "\n",
      "in <e1>generative adversarial networks</e1> (<e2>gans</e2>) (goodfellow et al.\n",
      "\n",
      "\n",
      "\n",
      "in <e1>generative adversarial networks</e1> (<e2>gans</e2>) (goodfellow et al.\n",
      "\n",
      "\n",
      "\n",
      "in <e1>generative adversarial networks</e1> (<e2>gans</e2>) (goodfellow et al.\n",
      "\n",
      "\n",
      "\n",
      "in <e1>generative adversarial networks</e1> (<e2>gans</e2>) (goodfellow et al.\n",
      "\n",
      "\n",
      "\n",
      "computing bounds for <e1>jacobian</e1> (or gradient) \n",
      "is very challenging even for a simple relu network, and how to efficiently provide a tight bound is still an open problem for <e2>deep neural networks</e2>.\n",
      "\n",
      "\n",
      "\n",
      "previous attempts for computing\n",
      "<e1>jacobian</e1> bounds can be summarized into <e2>three categories</e2>.\n",
      "\n",
      "\n",
      "\n",
      "previous attempts for computing\n",
      "<e1>jacobian</e1> bounds can be summarized into <e2>three categories</e2>.\n",
      "\n",
      "\n",
      "\n",
      "previous attempts for computing\n",
      "<e1>jacobian</e1> bounds can be summarized into <e2>three categories</e2>.\n",
      "\n",
      "\n",
      "\n",
      "another line of work simply bounds the norm of <e1>jacobian matrix</e1> \n",
      "over <e2>the entire domain</e2> (i.e.\n",
      "\n",
      "\n",
      "\n",
      "global lipschitz constant) by the product of operator norms of the <e1>weight matrices</e1> (<e2>szegedy</e2> et al.\n",
      "\n",
      "\n",
      "\n",
      "global lipschitz constant) by the product of operator norms of the <e1>weight matrices</e1> (<e2>szegedy</e2> et al.\n",
      "\n",
      "\n",
      "\n",
      "global lipschitz constant) by the product of operator norms of the <e1>weight matrices</e1> (<e2>szegedy</e2> et al.\n",
      "\n",
      "\n",
      "\n",
      "global lipschitz constant) by the product of operator norms of the <e1>weight matrices</e1> (<e2>szegedy</e2> et al.\n",
      "\n",
      "\n",
      "\n",
      "global lipschitz constant) by the product of operator norms of the <e1>weight matrices</e1> (<e2>szegedy</e2> et al.\n",
      "\n",
      "\n",
      "\n",
      "global lipschitz constant) by the product of operator norms of the <e1>weight matrices</e1> (<e2>szegedy</e2> et al.\n",
      "\n",
      "\n",
      "\n",
      "global lipschitz constant) by the product of operator norms of the <e1>weight matrices</e1> (<e2>szegedy</e2> et al.\n",
      "\n",
      "\n",
      "\n",
      "global lipschitz constant) by the product of operator norms of the <e1>weight matrices</e1> (<e2>szegedy</e2> et al.\n",
      "\n",
      "\n",
      "\n",
      "global lipschitz constant) by the product of operator norms of the <e1>weight matrices</e1> (<e2>szegedy</e2> et al.\n",
      "\n",
      "\n",
      "\n",
      "global lipschitz constant) by the product of operator norms of the <e1>weight matrices</e1> (<e2>szegedy</e2> et al.\n",
      "\n",
      "\n",
      "\n",
      "global lipschitz constant) by the product of operator norms of the <e1>weight matrices</e1> (<e2>szegedy</e2> et al.\n",
      "\n",
      "\n",
      "\n",
      "we can then absorb these fixed \n",
      "neurons into the previous layers' <e1>weight matrix</e1>, which results in bounding <e2>jacobian matrix</e2> for another shallower network.\n",
      "\n",
      "\n",
      "\n",
      "we can then absorb these fixed \n",
      "neurons into the previous layers' <e1>weight matrix</e1>, which results in bounding <e2>jacobian matrix</e2> for another shallower network.\n",
      "\n",
      "\n",
      "\n",
      "we can then absorb these fixed \n",
      "neurons into the previous layers' <e1>weight matrix</e1>, which results in bounding <e2>jacobian matrix</e2> for another shallower network.\n",
      "\n",
      "\n",
      "\n",
      "we can then absorb these fixed \n",
      "neurons into the previous layers' <e1>weight matrix</e1>, which results in bounding <e2>jacobian matrix</e2> for another shallower network.\n",
      "\n",
      "\n",
      "\n",
      "we can then absorb these fixed \n",
      "neurons into the previous layers' <e1>weight matrix</e1>, which results in bounding <e2>jacobian matrix</e2> for another shallower network.\n",
      "\n",
      "\n",
      "\n",
      "we can then absorb these fixed \n",
      "neurons into the previous layers' <e1>weight matrix</e1>, which results in bounding <e2>jacobian matrix</e2> for another shallower network.\n",
      "\n",
      "\n",
      "\n",
      "we can then absorb these fixed \n",
      "neurons into the previous layers' <e1>weight matrix</e1>, which results in bounding <e2>jacobian matrix</e2> for another shallower network.\n",
      "\n",
      "\n",
      "\n",
      "finally, we can use <e1>recurjac to evaluate</e1> the <e2>robustness</e2> of neural networks, by giving a certified lower bound within which no adversarial examples can be found.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "abstracts = []\n",
    "sentences = []\n",
    "ent_tagged_text = []\n",
    "\n",
    "def tag_entity_text(sentence,text, replacementText):\n",
    "    newString1 = \"\"\n",
    "    for (t,r) in zip(text,replacementText):\n",
    "        newString1 = sentence.replace(t,r)\n",
    "        sentence = newString1\n",
    "    return sentence\n",
    "\n",
    "with open('./Data/TestData/test_p31_intro.txt') as file:\n",
    "    lines = file.readlines()\n",
    "    abstxt = ''.join(str(line) for line in lines)\n",
    "    abstxt = abstxt.lower()\n",
    "    abstracts.append(abstxt)\n",
    "    \n",
    "\n",
    "# tokenize the abstracts into a sentence\n",
    "for abstract in abstracts:\n",
    "    sents = nltk.sent_tokenize(abstract)\n",
    "    for sent in sents:\n",
    "        sentences.append(sent)\n",
    "\n",
    "        \n",
    "text = []\n",
    "replacementText = []\n",
    "semeval_tagged = []\n",
    "for sentence in sentences:\n",
    "#     print(sentence + \" : : \")\n",
    "    ner_tagged = nlp(sentence)\n",
    "    tagged_entities = ner_tagged.ents\n",
    "    tuple_length = len(tagged_entities)\n",
    "    if(tuple_length == 2):\n",
    "        text = []\n",
    "        replacementText = []\n",
    "        for (i,ent) in enumerate(tagged_entities):\n",
    "#             print(str(i) + ent.text)\n",
    "            text.append(ent.text)\n",
    "            replacementText.append('<e' + str(i+1) + '>' + ent.text + '</e' + str(i+1) + '>')\n",
    "            semevalify = tag_entity_text(sentence,text,replacementText)\n",
    "    semeval_tagged.append(semevalify)\n",
    "            \n",
    "\n",
    "for sentence in semeval_tagged:\n",
    "    print(sentence)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ent in nlp(sentence).ents:\n",
    "#         labels = ent.label_\n",
    "#         print(\"%s %s %d %d\\n\" % (ent.label_.encode(\"utf-8\"), ent.text.encode(\"utf-8\"), ent.start_char, ent.end_char))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call the saved Relationship classification module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/amar/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.20.2 when using version 0.20.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Compare\n",
      "1: Conjunction\n",
      "2: Feature-of\n",
      "3: Part-of\n",
      "4: Used-for\n",
      "5: isA\n"
     ]
    }
   ],
   "source": [
    "from models import KerasTextClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "clf = KerasTextClassifier()\n",
    "clf.load(\"/home/amar/git/DCC/src/text2graph/model\")\n",
    "\n",
    "\n",
    "# Create a label dictionary\n",
    "\n",
    "label_dict = {}\n",
    "for i,c in enumerate(list(clf.encoder.classes_)):\n",
    "    print(str(i) + \": \" + c)\n",
    "    label_dict[i] = c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(semeval_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finally, we can use <e1>recurjac to evaluate</e1> the <e2>robustness</e2> of neural networks, by giving a certified lower bound within which no adversarial examples can be found.:\n",
      "Used-for\n",
      "\n",
      "finally, we can use <e1>recurjac to evaluate</e1> the <e2>robustness</e2> of neural networks, by giving a certified lower bound within which no adversarial examples can be found.:\n",
      "Used-for\n",
      "\n",
      "to formally answer this question and bound the behavior of neural networks, a critical step is to compute the uniform bounds of the <e1>jacobian matrix</e1> bfpxq/bx for \n",
      "all x within a <e2>certain region</e2>.:\n",
      "Conjunction\n",
      "\n",
      "to formally answer this question and bound the behavior of neural networks, a critical step is to compute the uniform bounds of the <e1>jacobian matrix</e1> bfpxq/bx for \n",
      "all x within a <e2>certain region</e2>.:\n",
      "Conjunction\n",
      "\n",
      "to formally answer this question and bound the behavior of neural networks, a critical step is to compute the uniform bounds of the <e1>jacobian matrix</e1> bfpxq/bx for \n",
      "all x within a <e2>certain region</e2>.:\n",
      "Conjunction\n",
      "\n",
      "to formally answer this question and bound the behavior of neural networks, a critical step is to compute the uniform bounds of the <e1>jacobian matrix</e1> bfpxq/bx for \n",
      "all x within a <e2>certain region</e2>.:\n",
      "Conjunction\n",
      "\n",
      "to formally answer this question and bound the behavior of neural networks, a critical step is to compute the uniform bounds of the <e1>jacobian matrix</e1> bfpxq/bx for \n",
      "all x within a <e2>certain region</e2>.:\n",
      "Conjunction\n",
      "\n",
      "in <e1>generative adversarial networks</e1> (<e2>gans</e2>) (goodfellow et al.:\n",
      "Used-for\n",
      "\n",
      "in <e1>generative adversarial networks</e1> (<e2>gans</e2>) (goodfellow et al.:\n",
      "Used-for\n",
      "\n",
      "in <e1>generative adversarial networks</e1> (<e2>gans</e2>) (goodfellow et al.:\n",
      "Used-for\n",
      "\n",
      "in <e1>generative adversarial networks</e1> (<e2>gans</e2>) (goodfellow et al.:\n",
      "Used-for\n",
      "\n",
      "in <e1>generative adversarial networks</e1> (<e2>gans</e2>) (goodfellow et al.:\n",
      "Used-for\n",
      "\n",
      "in <e1>generative adversarial networks</e1> (<e2>gans</e2>) (goodfellow et al.:\n",
      "Used-for\n",
      "\n",
      "in <e1>generative adversarial networks</e1> (<e2>gans</e2>) (goodfellow et al.:\n",
      "Used-for\n",
      "\n",
      "in <e1>generative adversarial networks</e1> (<e2>gans</e2>) (goodfellow et al.:\n",
      "Used-for\n",
      "\n",
      "computing bounds for <e1>jacobian</e1> (or gradient) \n",
      "is very challenging even for a simple relu network, and how to efficiently provide a tight bound is still an open problem for <e2>deep neural networks</e2>.:\n",
      "Used-for\n",
      "\n",
      "previous attempts for computing\n",
      "<e1>jacobian</e1> bounds can be summarized into <e2>three categories</e2>.:\n",
      "Used-for\n",
      "\n",
      "previous attempts for computing\n",
      "<e1>jacobian</e1> bounds can be summarized into <e2>three categories</e2>.:\n",
      "Used-for\n",
      "\n",
      "previous attempts for computing\n",
      "<e1>jacobian</e1> bounds can be summarized into <e2>three categories</e2>.:\n",
      "Used-for\n",
      "\n",
      "another line of work simply bounds the norm of <e1>jacobian matrix</e1> \n",
      "over <e2>the entire domain</e2> (i.e.:\n",
      "Compare\n",
      "\n",
      "global lipschitz constant) by the product of operator norms of the <e1>weight matrices</e1> (<e2>szegedy</e2> et al.:\n",
      "Compare\n",
      "\n",
      "global lipschitz constant) by the product of operator norms of the <e1>weight matrices</e1> (<e2>szegedy</e2> et al.:\n",
      "Compare\n",
      "\n",
      "global lipschitz constant) by the product of operator norms of the <e1>weight matrices</e1> (<e2>szegedy</e2> et al.:\n",
      "Compare\n",
      "\n",
      "global lipschitz constant) by the product of operator norms of the <e1>weight matrices</e1> (<e2>szegedy</e2> et al.:\n",
      "Compare\n",
      "\n",
      "global lipschitz constant) by the product of operator norms of the <e1>weight matrices</e1> (<e2>szegedy</e2> et al.:\n",
      "Compare\n",
      "\n",
      "global lipschitz constant) by the product of operator norms of the <e1>weight matrices</e1> (<e2>szegedy</e2> et al.:\n",
      "Compare\n",
      "\n",
      "global lipschitz constant) by the product of operator norms of the <e1>weight matrices</e1> (<e2>szegedy</e2> et al.:\n",
      "Compare\n",
      "\n",
      "global lipschitz constant) by the product of operator norms of the <e1>weight matrices</e1> (<e2>szegedy</e2> et al.:\n",
      "Compare\n",
      "\n",
      "global lipschitz constant) by the product of operator norms of the <e1>weight matrices</e1> (<e2>szegedy</e2> et al.:\n",
      "Compare\n",
      "\n",
      "global lipschitz constant) by the product of operator norms of the <e1>weight matrices</e1> (<e2>szegedy</e2> et al.:\n",
      "Compare\n",
      "\n",
      "global lipschitz constant) by the product of operator norms of the <e1>weight matrices</e1> (<e2>szegedy</e2> et al.:\n",
      "Compare\n",
      "\n",
      "we can then absorb these fixed \n",
      "neurons into the previous layers' <e1>weight matrix</e1>, which results in bounding <e2>jacobian matrix</e2> for another shallower network.:\n",
      "Used-for\n",
      "\n",
      "we can then absorb these fixed \n",
      "neurons into the previous layers' <e1>weight matrix</e1>, which results in bounding <e2>jacobian matrix</e2> for another shallower network.:\n",
      "Used-for\n",
      "\n",
      "we can then absorb these fixed \n",
      "neurons into the previous layers' <e1>weight matrix</e1>, which results in bounding <e2>jacobian matrix</e2> for another shallower network.:\n",
      "Used-for\n",
      "\n",
      "we can then absorb these fixed \n",
      "neurons into the previous layers' <e1>weight matrix</e1>, which results in bounding <e2>jacobian matrix</e2> for another shallower network.:\n",
      "Used-for\n",
      "\n",
      "we can then absorb these fixed \n",
      "neurons into the previous layers' <e1>weight matrix</e1>, which results in bounding <e2>jacobian matrix</e2> for another shallower network.:\n",
      "Used-for\n",
      "\n",
      "we can then absorb these fixed \n",
      "neurons into the previous layers' <e1>weight matrix</e1>, which results in bounding <e2>jacobian matrix</e2> for another shallower network.:\n",
      "Used-for\n",
      "\n",
      "we can then absorb these fixed \n",
      "neurons into the previous layers' <e1>weight matrix</e1>, which results in bounding <e2>jacobian matrix</e2> for another shallower network.:\n",
      "Used-for\n",
      "\n",
      "finally, we can use <e1>recurjac to evaluate</e1> the <e2>robustness</e2> of neural networks, by giving a certified lower bound within which no adversarial examples can be found.:\n",
      "Used-for\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Show predictions side by side\n",
    "for i,sentence in enumerate(semeval_tagged):\n",
    "    print(sentence + \":\\n\" +  label_dict.get(y_pred[i]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
